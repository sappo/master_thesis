# Evaluierung der Qualtiät und Effektivität

## Berechnung der Metriken für Real-time ER

Während im statischen Entity Resolution, die Metriken (vgl. @sec:measurements)
am Ende des Vorgang einmalig berechnet werden können, ist das im dynamischen
Falle nicht möglich, da es theoretisch kein Ende gibt. Das bedeutet die Metriken
müssen inkrementell mit jeder Anfrage erhoben werden.

## Experimenteller Aufbau

![Aufteilung der Datensätze in Validierungsmenge, Trainingsmenge und Testmenge.
Tupel in den Mengen sind durch Punkte markiert und Duplikate durch eine Line
zwischen zwei Tupeln. Die farbigen Linen zeigen, wie die jeweilige Untermenge
gebildet wird. ](./images/testsets.svg){#fig:testsets}

* Datensätze (ferbl, ncvoter, restaurant, shopping, publications)
    * Detailsaufbau

Für die Durchführung der Evaluierung wurden die Datensätze in vier disjunkte
Teildatensätze gesplittet. Diese Aufteilung ist in @fit:testsets dargestellt.

* Gütemaße, wann und wie werden die Maße ermittelt

## Freie Parameter {#sec:free_params}

Auf der Validierungsmenge wurden robuste Parameter für die freien Parameter für
die Evaluierung gewählt. Robust bedeutet, dass diese nicht optimal für jeden
Datensatz sind, sondern gute Ergebnisse für alle Datensätze liefern und
gleichzeitig verhindern, dass die Entity Resolution katastrophal versagt.

* Labelgenerator (untere und obere Schwelle): Die ersten freien Paramter finden
  Anwendung falls keine GT zur Verfügung steht und der Label Generator diese
  selbstständig erzeugt. Die unter Schwelle $lt$ legt fest, bis zu welchem
  Ähnlichkeitswert Paare als Non-Matches betrachtet werden und die obere
  Schwelle $ut$ legt fest, ab welchem Ähnlichkeitswert Paare als Matches
  betrachtet werden, dabei gilt stets $lt \leq ut$. In einem Experiment wurden
  $lt$ und $ut$ in 0.1 Schritten betrachtet und so alle Konfigurationen, auf dem
  NCVoter-Datensatz, ausprobiert, dabei wurde kein Klassifikator verwendet. Zur
  Auswertung wurden Pairs Completeness, Pairs Quality und gefilterte Ground
  Truth analysiert. Anhand der Pairs Completeness und Pairs Qualtity kann
  betrachtet werden, wie gut ein Blocking Verfahren auf der generierte Ground
  Truth funktioniert. Die gefilterte Ground Truth hingegen zeigt, wie viele
  Ground Truth Paare für den Fusion-Lerner zur Verfügung stehen. Die
  [@tbl:recall; @tbl:fp; @tbl:fn] betrachten nacheinander die Pairs
  Completeness, die gefilterten Matches und die gefilterten Non-Matches. Die
  Pairs Quality ist uninteressant, da deren Werte relativ konstant bei 0.1, mit
  einer Varianz von 0.03, liegen. In @tbl:recall ist gut zu sehen, dass die
  Pairs Quality zwischen einer $ut$ von 0.1 und 0.4 immer eine gute Pairs
  Qualtity von 95 % erzeugt. Der Blick auf das erlernte Blocking Schema zeigt,
  dass diese auch immer dasselbe ist. Dies trifft auch noch teilweise für
  $ut=0.5$ zu, allderdings nur für $lt \leq 0.3$. Für alle $ut > 0.5$ varrieren
  die Blocking Schema, wobei unabhängig von $lt$ keines über 17 % Pairs
  Completeness kommt. Deshalb werden in den [@tbl:fp; @tbl:fn] lediglich
  $ut$-Werte kleiner 0.6 betrachtet. Die maximal Matches, die der Label
  Generator erzeugen kann, liegen bei 10 % der Gesamtmenge und betragen 551k.
  Die tatsächlichen Matches betragen 50k. Bei den Non-Matches ist das Limit 25 %
  und damit 1,3 mio. In @tbl:fp ist zu sehen, das für $ut \leq 0.4$ die
  Ausgangsmenge der Matches auf das Maximum beschränkt wurde. Da jeweils die
  Matches mit der höchsten Ähnlichkeit genutzt werden, sind diese Mengen
  identisch, weshalb auch die gefilterte Menge von 300k Datensätzen, aufgrund
  desselben Blocking Schema, identisch sind. Für $ut=0.5$ ist die Ausgangsmenge
  kleiner als das Maximum. Die gefilterte Menge beträgt in diesem Fall 288k. In
  jedem Fall sind nach dem Filtern genügend Matches vorhanden, um einen
  Klassifikator zu trainieren, auch wenn diese 6-Mal soviele Matches beinhaltet,
  wie die tatsächlichen Matches. In @tbl:fn werden die Anzahl der Non-Matches
  dargestellt. Für $lt=0.1$ sind insgesamt nur 8k Paare erzeugt worden, weil das
  TF/IDF Blocking die meisten der sehr unähnlichen Paare ausschließt. Nach dem
  Filtern durch das Blocking Schema sind keine Non-Matches mehr vorhanden, da
  das Blocking Schema verhindert, dass diese offensichtlichen Non-Matches
  zusammen gruppiert werden. Für $lt=0.2$ gibt es ein ähnliches Bild. Zwar ist
  die Anzahl der Ausgangsmenge mit 655k deutlich höher dennoch werden lediglich
  66 Paare zusammen gruppiert. Interessanter wird es erst ab $lt=0.3$. Hier wird
  erstmal das Maximum der Ausgangsmenge mit 1377k erreicht. Die gefilterten
  Non-Matches betragen 2430, was im Vergleich zu den Matches immer noch sehr
  wenig ist, aber durchaus genügt, um einen Klassifikator zu trainieren. Mit
  $lt=0.4$ erhöht sich diese Anzahl nochmals um das 5-fache, allerdings weicht
  hier mit $ut=0.5$ die Pairs Completeness das erste Mal von 95 % ab. Daraus
  folgt, dass sich im Bereich 0.3 - 0.5 eine essentielle Anzahl an Machtes
  befinden, die mit $lt=0.4$ fälschlicherweise als Non-Matches klassifiziert
  werden und mit $ut=0.5$ von den Matches ausgeschlossen sind. Folglich wird ein
  Blocking Schema gelernt, eine schlechte Pairs Quality liefert. Anhand dieser
  Werte wird $lt$ mit 0.3 festgelegt, da ab hier genügend Paare für den
  Klassifikator zur Verfügung stehen und gleichzeitig die Wahrscheinlichkeit
  noch gering ist ein Match fälschlicherweise mitaufzunehmen. Die $ut$ wird
  ebenfalls auf 0.3 festgelegt. Zwar scheinen die Werte für $ut=0.4$ auch noch
  stabil zu sein, aber um möglichst robust zu sein, wird dieser Bereich als
  Puffer genutzt.

|  PC | 0.1  | 0.2  | 0.3  | 0.4  | 0.5  | 0.6  | 0.7  | 0.8  | 0.9  | 1.0  |
|----:+------+------+------+------+------+------+------+------+------+------|
| 0.1 | 0.95 | 0.95 | 0.95 | 0.95 | 0.95 | 0.15 | 0.15 | 0.15 | 0.15 | 0.13 |
| 0.2 |      | 0.95 | 0.95 | 0.95 | 0.95 | 0.15 | 0.15 | 0.15 | 0.15 | 0.13 |
| 0.3 |      |      | 0.95 | 0.95 | 0.95 | 0.15 | 0.15 | 0.16 | 0.13 | 0.13 |
| 0.4 |      |      |      | 0.95 | 0.15 | 0.16 | 0.16 | 0.16 | 0.14 | 0.14 |
| 0.5 |      |      |      |      | 0.16 | 0.16 | 0.13 | 0.14 | 0.14 | 0.06 |
| 0.6 |      |      |      |      |      | 0.13 | 0.14 | 0.14 | 0.16 | 0.06 |
| 0.7 |      |      |      |      |      |      | 0.14 | 0.10 | 0.16 | 0.06 |
| 0.8 |      |      |      |      |      |      |      | 0.10 | 0.16 | 0.06 |
| 0.9 |      |      |      |      |      |      |      |      | 0.14 | 0.06 |
| 1.0 |      |      |      |      |      |      |      |      |      | 0.06 |

: Pairs Completeness {#tbl:recall}

| Matches | 0.1       | 0.2       | 0.3       | 0.4       | 0.5       |
|--------:+-----------+-----------+-----------+-----------+-----------|
|     0.1 | 551k/300k | 551k/300k | 551k/300k | 551k/300k | 443k/288k |
|     0.2 |           | 551k/300k | 551k/300k | 551k/300k | 443k/288k |
|     0.3 |           |           | 551k/300k | 551k/300k | 443k/288k |
|     0.4 |           |           |           | 551k/300k | 443k/287k |
|     0.5 |           |           |           |           | 443k/273k |

: Filtered Matches {#tbl:fp}

| Non-Matches | 0.1  | 0.2     | 0.3        | 0.4         | 0.5        |
|------------:+------+---------+------------+-------------+------------|
|         0.1 | 8k/0 | 8k/0    | 8k/0       | 8k/0        | 8k/0       |
|         0.2 |      | 655k/66 | 655k/66    | 655k/66     | 655k/66    |
|         0.3 |      |         | 1377k/2430 | 1377k/2430  | 1377k/2430 |
|         0.4 |      |         |            | 1377k/13916 | 1377k/11k  |
|         0.5 |      |         |            |             | 1377k/8k   |

: Filtered Non-Matches {#tbl:fn}


Validierungsmenge (average precision?)

* Fenstergröße, Labelgenerator
* max positive/negatvie Paare, Labelgenerator
* Block Size Filter, Labelgenerator
* "Stop Token Filter" -> 100, Blocking Scheme
* Anzahl/Größe der Konjunktionen, Blocking Scheme
* Search, Crossval, Metric ,Fusion-Lerner

### Geeignete Prädikate

* Einfluss der Prädikate (commonToken, excactMatch, q-Qram, suffixe, prefixe),
  Blocking Scheme

* Stringähnlichkeiten (Levenshtein, Damerau, Jaro, Ratio), SimLearner
* MDySimII vs MDySimIII

* Schwelle des Klassifikators (`predict_proba`) verschieben. (ROC vs average
  precision)

=> Ziel: optimales System

\TODO{Zu Implementierung hinzufügen} Laut Kejriwal & Miranker
[@KM:Unsupervised:13] bieten Werte $>3$ keine wesentliche Verbesserung.

## Baseline vs GT partial vs GT full

Validierungsmenge

* Pair completeness/Reduction Ratio/Pairs Quality
* Presion/Recall/F-measure
* Memory usage
* Insert/Query Times

## Human Baseline

Train/Train

Train/Test

## Grund Truth vs No Ground Truth
