# Evaluierung

## Berechnung der Metriken für Real-time ER

Während im statischen Entity Resolution, die Metriken (vgl. @sec:measurements)
am Ende des Vorgang einmalig berechnet werden können, ist das im dynamischen
Falle nicht möglich, da es theoretisch kein Ende gibt. Das bedeutet die Metriken
müssen inkrementell mit jeder Anfrage erhoben werden.

## Experimenteller Aufbau

* Datensätze (ferbl, ncvoter, restaurant, shopping, publications)
    * Detailsaufbau
    * Splits (Validate, Train, Test)
* Gütemaße, wann und wie werden die Maße ermittelt

## Freie Parameter

Validierungsmenge (average precision?)

* Schwellen, Labelgenerator (falls keine GT)
* Fenstergröße, Labelgenerator
* Block Size Filter, Labelgenerator
* max positive/negatvie Paare, Labelgenerator
* "Stop Token Filter" -> 100, Blocking Scheme
* Anzahl/Größe der Konjunktionen, Blocking Scheme

### Geeignete Prädikate

* Einfluss der Prädikate (commonToken, excactMatch, q-Qram, suffixe, prefixe),
  Blocking Scheme

* Stringähnlichkeiten (Levenshtein, Damerau, Jaro, Ratio), SimLearner
* MDySimII vs MDySimIII

* Schwelle des Klassifikators (`predict_proba`) verschieben. (ROC vs average
  precision)

=> Ziel: optimales System

\TODO{Zu Implementierung hinzufügen} Laut Kejriwal & Miranker
[@KM:Unsupervised:13] bieten Werte $>3$ keine wesentliche Verbesserung.

## Baseline vs GT partial vs GT full

Validierungsmenge

* Pair completeness/Reduction Ratio/Pairs Quality
* Presion/Recall/F-measure
* Memory usage
* Insert/Query Times

## Human Baseline

Train/Train

Train/Test

## Grund Truth vs No Ground Truth
