# Evaluierung

## Experimenteller Aufbau

* Datensätze (ferbl, ncvoter, restaurant, shopping, publications)
    * Detailsaufbau
    * Splits (Validate, Train, Test)
* Gütemaße, wann und wie werden die Maße ermittelt

## Freie Parameter

Validierungsmenge (average precision?)

* Schwellen, Labelgenerator (falls keine GT)
* Fenstergröße, Labelgenerator
* max positive/negatvie Paare, Labelgenerator
* "Stop Token Filter" -> 100, Blocking Scheme
* Anzahl/Größe der Konjunktionen, Blocking Scheme
* Einfluss der Prädikate (commonToken, excactMatch, q-Qram, suffixe, prefixe),
  Blocking Scheme
* Stringähnlichkeiten (Levenshtein, Damerau, Jaro, Ratio), SimLearner
* MDySimII vs MDySimIII

* Schwelle des Klassifikators (`predict_proba`) verschieben. (ROC vs average
  precision)

=> Ziel: optimales System

## Baseline vs GT partial vs GT full

Validierungsmenge

* Pair completeness/Reduction Ratio/Pairs Quality
* Presion/Recall/F-measure
* Memory usage
* Insert/Query Times

## Human Baseline

Train/Train

Train/Test

## Grund Truth vs No Ground Truth
