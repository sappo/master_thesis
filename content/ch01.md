# Einleitung \label{chap:intro}

Heutzutage werden von vielen Unternehmen riesige Mengen von Daten gesammelt.
Diese Daten sind meist Abbildungen von Entitäten der realen Welt, wie z.B. von
Personen, Produkten oder Veröffentlichungen. Bei den meisten Abbildungen ist es
nicht möglich einzigartige Attribute abzuleiten, anhand derer zwei oder mehr
Abbildungen derselben Entitäten zugeordnet werden können. Zudem sind diese oft
unvollständig und sind dadurch mehrdeutig, beispielsweise durch
Rechtschreibfehler, fehlende oder vertauschte Attribute. Diese Mehrdeutigkeiten
aufzulösen ist, auch bei manuelle Betrachtung durch einen Menschen, nicht
trivial und darum oft zeitaufwändig. Beispiele für mehrdeutige Personendaten
sind unterschiedliche Schreibweisen von Nachnamen (`Maier` vs `Mayer`),
vertauschte Vor- und Nachnamen, deren die Zuordnung nicht eindeutig ist
(`Peter`, `Michel`, `Moritz`) oder ausländische Namen, wo die Schreibweise
unbekannt ist. Dabei verlassen sich die Unternehmen in ihren Geschäftsprozessen
auf diese Daten, deshalb hat die Qualität der Abbildungen maßgeblichen Einfluss
auf die Qualität eines Produktes oder einer Dienstleistung. In der Informatik
werden die Manifestationen der abgebildeten Objekte als Datensätze in
Datenbanken (o.ä.) bezeichnet. Zur Verbesserung der Qualität der gesammelten
Daten wird in der Praxis eine Datenbereinigung (engl. data cleaning)
durchgeführt. Ein wichtiger Aspekt der Datenbereinigung ist, alle Datensätze zu
finden welche derselben Entität entsprechen. Verfahren, die Abbildungen der
Entitäten finden und verlinken bzw. zusammenführen, werden üblicherweise Entity
Resolution, Duplicate Detection oder Record Linkage genannt. Beispiele, wo
mehrere Datensätze auf dieselbe Entität verweisen, sind Patientenakten in einer
Krankenhausdatenbank oder ein Wählerverzeichnis, in welches eine Person öfters
eingetragen ist. Für den Fall, dass diese Informationen nicht zusammengeführt
oder verlinkt werden können, folgen teils schlimme Konsequenzen. Beispielsweise
trifft ein Arzt, aufgrund unvollständiger Informationen, die falsche
Entscheidung zur Behandlung eines Patienten oder ein Wahlberechtigter gibt
mehrere Stimmen ab, was zu Wahlunstimmigkeiten führt. Weitere Einsatzbereiche
sind Betrugserkennung, Bonitätsprüfung und Inkasso, hierbei sind die
Konsequenzen finanzieller Art. Das Thema dieser Masterarbeit wird für den
Problembereich der UNIVERSUM Group in Frankfurt am Main untersucht. Die
UNIVERSUM Group bietet Online-Händlern an, die Einkäufe ihrer Kunden zu
versichern. Das bedeutet, dass nach Ablauf einer Zahlungsperiode, bei Ausbleiben
der Zahlung durch den Kunden, der Betrag durch die Versicherung gezahlt wird.
Die UNIVERSUM Group wird in diesem Fall zum Gläubiger der Forderung und wird im
Inkassoverfahren das Geld vom Kunden einfordern. Beim Inkassoverfahren müssen,
aufgrund gesetzlicher Bestimmungen mehrere Forderungen der selben natürlichen
Person zusammengefasst werden. Die meisten Forderungen fallen hierbei einmal
täglich mit dem Ablauf der Zahlungsfrist an. Dadurch können Entity Resolution
Verfahren eingesetzt werden, die periodisch (etwa jede Nacht) auf einem
statischen Datenbestand operieren, der sich während der Laufzeit der Entity
Resolution nicht verändert. Für jede Forderung im Datenbestand wird dadurch
geprüft, ob es einen übereinstimmenden Schuldner gibt. Hierbei spielt
hauptsächlich die Qualität eine entscheidende Rolle. Die Laufzeit ist lediglich
durch die Periode (= 1 Tag/Nacht) begrenzt. Für die Betrugserkennung bzw. die
Bonitätsprüfung sind diese Verfahren nicht geeignet, da diese Teil eines
Prüfprozesses sind, der während des Bestellabschlusses bei einem Onlinehändler
stattfindet. Hierbei wird die Entity Resolution auf Anfrage durchgeführt und
erst mit dem Ergebnis der Anfrage kann der Onlinehändler die Bestellung
abschließen. Dementsprechend spielt neben der Qualität auch die Laufzeit eine
wichtige Rolle, welche oft im Subsekundenbereich liegen muss, da die Entity
Resolution nur ein Teilprozess für Betrugserkennung und Bonitätsprüfung ist.
Technisch gesehen handelt es sich bei den meisten Onlinediensten um Event Stream
Processing (ESP) Systeme, welche einen Datenstrom von Anfragendatensätzen in
nahe Echtzeit bearbeiten müssen. Da ein solcher Datenstrom kein definiertes Ende
hat, werden Änderungen am Datenbestand zur Laufzeit vorgenommen. Das bedeutet,
dass der zu prüfende Datenbestand dynamisch ist und sich mit jeder Anfrage
verändern kann. Zum einen die Laufzeitanforderungen und zum anderen die
dynamischen Daten stellen Entity Resolution Verfahren hierbei vor eine
Herausforderung.

Unabhängig von den eingesetzten Verfahren gibt es bei Entity Resolution stets
die Schwierigkeit, die Parameter der Verfahren auf die Domäne der Daten
anzupassen. Beispielsweise unterscheidet sich die Struktur eines Datensatzes mit
Personendaten gravierend von dem einer Produktdatenbank, weshalb gute Parameter
einer Domäne oft nicht übertragbar sind. Die Anpassung der Konfiguration ist ein
aufwändiger Prozess, der selbst Domänexperten vor eine große Herausforderung
stellt, da die Anzahl der Parameter leicht in den zweistelligen Bereich wächst
und die Auswirkungen von Parametern auf Performanz und Güte schwer abzuschätzen
sind. Wünschenswert wäre deshalb ein System oder Framework, das
selbstkonfigurierend ist und folglich möglichst automatisiert die Parameter auf
die Datendomäne anpasst. Da das Ausstellen von Versicherungen der UNIVERSUM
Group ausschließlich durch deren Onlinedienst erfolgt, in welchem
Bonitätsprüfung und Betrugserkennung durchgeführt werden müssen, liegt der
Schwerpunkt auf Verfahren für Event Stream Processing Systeme. In Kapitel
\ref{chap:101} werden zunächst die Grundlagen für Entity Resolution Verfahren
erläutert und anschließend die genauen Anforderungen an Entity Resolution
Verfahren für ESP-Systeme erläutert. Im übrigen Kapitel \ref{chap:101} werden
ähnliche Arbeiten vorgestellt, die sich mit den diversen Teilbereichen der
Entity Resolution befassen. In Kapitel \ref{chap:analysis} werden die
vorgestellten Verfahren in Bezug auf die gestellten Anforderungen, sowie die
Konfigurierbarkeit ihrer Parameter, analysiert und bei Bedarf angepasst. Kapitel
\ref{chap:design} stellt auf Basis der Analyse ein System vor, dass sich selbst
konfigurieren kann, um Entity Resolution für ESP-Systeme durchzuführen. Danach
wird in Kapitel \ref{chap:evaluation} eine Evaluation dieses Systems
durchgeführt. Dabei werden die Laufzeitanforderungen, die Qualität und die
Effektivität der eingesetzten Verfahren überprüft und ausgewertet. Abschließend
wird in Kapitel \ref{chap:conclusion} ein Ausblick auf mögliche
Weiterentwicklungen gegeben.
