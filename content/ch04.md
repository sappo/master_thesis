# Selbstkonfigurierendes System

In Kapitel 2 und 3 betrachtete Verfahren und Algorithmen haben gemeinsam, dass
alle eine Reihe von Parametern haben, um die Algorithmen auf die Eingabedaten zu
optimieren. Beispielsweise verlangt der DySimII, aus @sec:dysimII, pro Attribute
einen Blockschlüssel und eine Ähnlichkeitsfunktion. Bei einem Datensatz mit fünf
Attributen, sind dies bereits 10 Parameter. Hinzu kommen Parameter für die
Ähnlichkeitsfunktionen, welche auf das Attribut optimiert werden. Bei einem
Attribut pro Ähnlichkeitsfunktion kommen nochmal 5 Parameter hinzu. Wird nun
lediglich ein einfacher Schwellenwertklassifikator mit einer Schwelle genutzt,
hat dieses ER-System bereits 16 Parameter. Diese Parameter manuell zu bestimmen,
ist auch mit einem cleveren Samplingverfahren sehr zeit- und kostenintensiv.
Besonders bei großen Datenmengen kann dieses Trial and Error Verfahren sehr
lange dauern, da das Ausprobieren mehrere Stunden, wenn nicht Tage dauern kann.
Noch schwieriger wird es, wenn keine Ground Truth Daten vorhanden sind. Denn
dann wird das Einstellen der Parameter zum Glückspiel.

In diesem Kapitel wird ein Design für ein selbstkonfigurierendes Entity
Resolution System für Anfrageströme vorgestellt. Das Ziel ist es, mit und ohne
Ground Truth, die Daten aller Parameter bestmöglichst auf die Eingabedatenmenge
zu optimieren, ohne das der Benutzer manuell Einstellungen tätigen muss. Die
einzigen erlaubten Parameter sind Laufzeitoptimierungen beim Erlernen der
Konfiguration des Systems. Damit kann der zeitliche Aufwand für große
Datenmengen auf Bedürfnisse des Benutzers angepasst werden, da eine besonders
gründliche Selbstkonfiguration durchaus einige Tage dauern kann.

## Engine

```{.plantuml #fig:engine
    caption="Engine des selbstkonfigurierenden Systems. Bestehend aus 8
    Komponenten. In Gelb sind der Ground Truth Generator, der Blocking Scheme
    Lerner, der Similarity Lerner und der Hyperparameter Optimierer, welche für
    das Erlernen der Konfiguration nötig sind. In Grün ist der Indexer, welcher
    aus anhand der gelernten Konfiguration gebaut wird und der Klassifikator.
    In Blau ist der Parser, um Daten einer Datenquelle zu laden und der
    Präprozessor, um die geladenen Daten für Entity Resolution zu manipulieren"}
@startuml
ditaa(--no-shadows, scale=5)
+-----------------------------------Engine--------------------------------------+
|+--------------+-------------------------+--------------------+---------------+|
||cBLU          |cYEL                     |cYEL                |cGRE           ||
|| Parser       | Label Generator         | Similarity Learner | Indexer       ||
||              |                         |                    |               ||
|+--------------+-------------------------+--------------------+---------------+|
||cBLU          |cYEL                     |cYEL                |cGRE           ||
|| Präprozessor | Blocking Scheme Learner | Hyperparameter-    | Klassifikator ||
||              |                         | Optimierer         |               ||
|+--------------+-------------------------+--------------------+---------------+|
\-------------------------------------------------------------------------------/
 +----+               +----+           +----+
 |cBLU| Preprocessing |cYEL| Fit-Phase |cGRE| Build-/Query-Phase
 +----+               +----+           +----+
@enduml
```

Die Engine ist das Herzstück des selbstkonfigurierenden Systems und besteht aus
einzelnen Komponenten, welche wie in einem Steckkastensystem ausgetauscht
werden. Die 8 Komponenten der Engine sind in @fig:engine dargestellt.

* **Parser**. Der Parser liest Datensätze aus einer Datenquelle.
* **Präprozessor**. Der Präprozessor vorverarbeitet jedes Attribut in einer
  Pipeline mit einer Reihe von Operationen.
* **Label Generator**. Der Label Generator erzeugt eine Ground Truth von Matches
  und passende Non-Matches.
* **Blocking Schema Lerner**. Der Blocking Schema Lerner erzeugt eine Blocking
  Schema in distributiver Normalform nach [@KM:Unsupervised:13].
* **Similarity Lerner**. Der Similarity Lerner bestimmt für jedes Attribut eine
  geeignete Ähnlichkeitsfunktion.
* **Hyperparameter-Optimierer**. Der Hyperparameter-Optimierer lernt die besten
  Parameter für den Klassifikator und trainiert das Klassifikationsmodell.
* **Indexer**. Der Indexer wendet ein Blocking Verfahren auf die Eingabedaten an
  und ermöglicht es diese anzufragen.
* **Klassifikator**. Der Klassifikator sortiert die Kandidatenmenge einer
  Indexanfrage in Matches und Non-Matches.

Die Interaktionen zwischen den Komponenten wird von der Engine gesteuert, indem
Daten von einer Komponente zur nächsten weitergereicht bzw. Rückgabewerte für
die nächste Komponente zunächst aufbereitet werden. Die Engine dient weiterhin
als die Schnittstelle für den Benutzer. Dabei kann der Benutzer die Engine in
drei Zustände versetzten (siehe @fig:engine_state). Eine neu erzeugte Engine ist
*unangepasst* und kann durch das Lernen der Konfiguration (engl. fitting) in den
Zustand *angepasst* wechseln. Alternativ kann eine bereits gelernte
Konfiguration geladen werden. Anhand dieser Konfiguration kann der Index gebaut
(engl. building) werden, wonach sich die Engine im Zustand *gebaut* befindet. In
diesem Zustand kann die Engine mit Datensätzen angefragt (engl. querying)
werden. Mit jeder Anfrage wächst der Datenbestand des Index. Liegen genügend
neue Daten vor, kann die Engine anhand der veränderten Datenmenge erneut eine
Konfiguration erlernen und wechselt anschließend zurück in den Zustand
*angepasst*. Die drei Phasen zum Wechseln der Zustände werden im Folgenden als
*Fit-Phase*, *Build-Phase* und *Query-Phase* bezeichnet.

```{.plantuml #fig:engine_state
    caption="Zustandsdiagramm der Engine. Lernen der Konfiguration versetzt die
    Engine von unangepasst nach angepasst. Wurde der Index gebaut, ist die Engine
    im Zustand gebaut und kann Anfrage entgegennehmen."}
[*] -> unangepasst

unangepasst -> angepasst : fitting
unangepasst -> angepasst : load config
angepasst -> gebaut : building
gebaut -> angepasst : re-fitting
gebaut -> gebaut : querying
```

### Vorverarbeitung

Die Vorverarbeitung der Daten ist in allen drei Phasen notwendig und macht die
Datensätze robuster gegenüber Missklassifikationen, während der Entity
Resolution. In @fig:preprocessing sind die beteiligten Komponenten Parser und
Präprozesser (@fig:engine in blau) mit ihren Aktivitäten visualisiert. Jede
Phase beginnt mit der Auswahl des korrekten Parsers durch die Engine.

```{.plantuml #fig:preprocessing
    caption="Aktivitätsdiagramm der Vorverarbeitung. Der Parser liest einen
    Datensatz, welcher vom Präprozessor transformieren wird. Der transformierte
    Datensatz wird von der Engine abgespeichert."}
|Engine|
start
:choose parser for Fit-,
Build- or Query-Phase;
|Parser|
:read dataset;
if (is Fit-Phase?) then (yes)
    :assign attribute datatypes;
endif
|Preprozessor|
:transform dataset;
|Engine|
:save transformed dataset;
:proceed with (Fit/Build/Query)-Phase;
```

**Parser**. Der Parser ist eine einfache Komponente, welche Datensätze aus einer
Datenquelle liest und eine Liste von Datensätzen, mit mindestens einem
Datensatz, zurückgibt. Je nach Phase kann die Datenquelle ein beliebiges Format
haben, weshalb für jede Phase ein eigener Parser bestimmt werden kann. Für
*Fit-* und *Build-Phase*, wo große Datenmengen bearbeitet werden, liest der
Parser beispielsweise aus einer CSV-Datei oder einer Datenbank. Währenddessen
in der *Query-Phase* nur einzelne oder kleine Datenmengen gelesen werden,
weshalb der Parser hier aus einer Message Queue (MQ) Datensätze erhalten könnte.
Während der *Fit-Phase* hat der Parser zudem dafür Sorge zu tragen, dass der
Engine die Attribute des Datensatzes, sowie deren Datentypen bekannt gemacht
werden.

**Präprozessor**. Der Präprozessor bzw. die Präprozessor-Pipeline besteht aus
einer Reihe von Funktionen, die nacheinander auf die Attribute aller Datensätze
angewandt werden, welche vom Parser zurückgegeben wurden. Je nach Datentyp des
Attributs wird dabei eine andere Pipeline verwendet. Der Präprozessor wird in
allen drei Phasen verwendet, um einen Datensatz für die Entity Resolution
vorzubereiten und robuster zu machen. Typische Funktionen sind die Konvertierung
in Kleinschreibweise und das Entfernen von Stopwörtern (z.B. *und*, *oder*). Je
nach Domäne der Daten kann der Benutzer weitere Funktionen in die Pipeline
einfügen, beispielsweise eine Überprüfung der postalischen Addresse. Neben
weiteren Funktionen kann der Benutzer auch die Reihenfolge der Funktionen
bestimmen. Beispielweise zunächst die Rechtspreibprüfung und anschließend die
Konvertierung in Kleinschreibweise, da durch die Rechtschreibprüfung diese
Konvertierung in teilen wieder aufgehoben wird.

Die Liste der transformierten Datensätze des Präprozessors wird abschließend
von der Engine gespeichert, bevor die Abarbeitung der eigentlichen Phase
beginnt.

### Fit-Phase

```{.plantuml #fig:fit_phase
    caption="Aktivitätsdiagramm der Fit-Phase. Die Engine kontrolliert den
    Datenfluss zwischen den Komponenten, speichert Zwischenstände und breitet
    Daten für Komponenten auf. Parser und Präprozessor lesen die Trainingsdaten
    und transformieren diese. Der Label Generator erzeugt die Ground Truth,
    durch welche ein DNF-Blocking Schema vom BS-Lerner erzeugt wird. Auch auf
    der Ground Truth werden die Ähnlichkeitsvektoren anhand der gelernten
    Funktionen erzeugt, wodurch die Hyperparameter bestimmt und abschließend
    das Model trainiert wird."}
|Engine|
start
|Label Generator|
:read transformed dataset;
:generate ground truth;
|Engine|
:save ground truth;
|BS-Learner|
:read ground truth;
:predict DNF Blocking Scheme;
|Engine|
:save DNF Blocking Scheme;
:filter ground truth;
|Sim-Learner|
:read filtered ground truth;
:predict similarity functions;
|Engine|
:save similarity functions;
:calculate ground truth
similarity vectors;
|HP-Optimizer|
:read ground truth;
:read similarity vectors;
:predict hyperparameters;
:train model;
|Engine|
:save model;
stop
```

In der Fit-Phase nimmt die Engine die Konfiguration des Systems vor. In
@fig:engine sind die hierfür benötigten Komponenten gelb hervorgehoben. Bei
großen Datensätzen kann diese Phase sehr lange dauern, weshalb die Engine die
Rückgabewerte aller Komponenten sichert. Dadurch kann die Fit-Phase im Falle
eines Abbruchs, z.B. durch einen Systemneustart, fortgesetzt werden. Wurde die
Fit-Phase abgeschlossen, ist es möglich die ermittelte Konfiguration einzulesen.
Wodurch die Fit-Phase übersprungen wird. @fig:fit_phase zeigt das
Aktivitätsdiagramm der Fit-Phase.

**Label Generator**. Der Label Generator erzeugt die für später in der Fit-Phase
folgenden Komponenten die nötige Ground Truth in Form von klassifizierten
Matches und Non-Matches. Dazu liest er die, in der Vorverarbeitung
transformierten, Trainingsdaten ein und bildet Datensatzpaare. Dabei gibt es
zwei Ausprägungen. In der ersten Ausprägung erhält der Label Generator eine
Ground Truth für den gegebenen Datensatz. Aufgrund der Verteilung von Matches
und Non-Matches, die fast immer ein deutliches Ungleichgewicht zugunsten der
Non-Matches aufweist, werden für einen Datensatz mit Ground Truth in fast allen
Fällen nur die Matches angegeben. Dementsprechend sind alle Datensatzpaare,
welche kein bekanntes Match sind, Non-Matches. Aus der riesigen Menge der
Non-Matches selektiert der Label Generator eine repräsentative Untermenge. In
der zweiten Ausprägung stehen dem Label Generator keine vorklassifizierten
Matches zur Verfügung. Weshalb die Ground Truth vollständig automatisiert
bestimmt werden muss. Klar ist, dass die Konfiguration auf Basis der zweiten
Ausprägung, in den meisten Fällen schlechter ist, als die der ersten Ausprägung.
Ein Label Generator kann beide Ausprägungen implementieren, ist jedoch nur die
erste Ausprägung implementiert werden zwangsweise vorklassifizierte Matches
benötigt. Sollte nur die zweite Ausprägung vorhanden sein, werden die
vorklassifizierten Matches ignoriert.

**Blocking Schema Lerner**. Der Blocking Schema Lerner ermittelt ein Blocking
Schema in disjunktiver Normalform nach [@KM:Unsupervised:13], welches in
{#sec:blk_scheme} vorgestellt wurde. Dafür benötigt der Blocking Schema Lerner
die vorverarbeiteten Trainingsdaten, sowie die Ground Truth Daten des Label
Generators. Das Lernen eines Schemas ist ein rechenintensiver Job, weshalb der
Benutzer über Laufzeitparameter die maximale Anzahl an Konjunktionen innerhalb
der Ausdrücke, sowie die maximale Anzahl an Disjunktionen von Ausdrücken angeben
kann.

**Similarity Lerner**. Der Similarity Lerner bestimmt für jedes Attribut eines
Datensatzes die geeignetste Ähnlichkeitsfuntion. Dazu werden die Datensatzpaare
der Grund Truth bewertet. Bevor die Ground Truth an den Similarity Lerner
übergeben wird, filtert die Engine die Datensatzpaare heraus, welche nicht vom
Blocking Schema erfasst werden. Das sind diejenigen Datensatzpaare, welche von
einem Blocking Verfahren nicht zusammen gruppiert werden und daher kein Paar
werden können.

**Hyperparameter-Optimierer**. Der Hyperparameter-Optimierer ermittelt für einen
gegebenen Klassifikator die Parameter, die auf der Ground Truth das Modell mit
der beste F-measure erzeugen. Bevor der Hyperparameter-Optimierer aufgerufen
werden kann, erzeugt die Engine für jedes Ground Truth Paar, anhand der
Ähnlichkeitsfunktionen des Similarity Lerners, einen Ähnlichkeitsvektor pro
Paar. Die Ähnlichkeitsvektoren werden dann vom Hyperparameter-Optimierer
genutzt, um ein Modell mit gegebenen Parametern zu trainieren. Die Parameter,
die zur Optimierung in Frage kommen, müssen von der Klassifikatorkomponente
bereitgestellt werden. Ein einfacher Hyperparameter-Optimierer ist eine
Grid-Search, welche im Brute-Force Stil alle Parameterkombinationen ausprobiert.

### Build-Phase

```{.plantuml #fig:build_phase
    caption="Aktivitätsdiagramm der Build-Phase. Der liest alle vorverarbeiteten
    Datensätze einer initalen Datensatzes ein und fügt diese seinem Index hinzu."}
|Engine|
start
:read transformed dataset;
repeat
    :get record from dataset;
    |Indexer|
    :insert record into index;
repeat while (more records?)
|Engine|
:save index;
stop
```

In der Build-Phase wird auf dem aktuellen vorverarbeiteten Datenbestand ein
Blocking-Verfahren durchgeführt. Der **Indexer** ist ein Blocking Mechanismus,
der zum einen mit dynamischen Daten umgehen können muss und zum anderen das
Blocking anhand des DNF-Blocking Schemas durchführt. In @fig:build_phase wird
die Build-Phase erläutert. Die Engine liest zunächst alle vorverarbeiteten
Datensätze ein und fügt diese anschließend dem Index hinzu. Dabei besteht
die Möglichkeit, dass der Index während des Einfügens anhan der gelernten
Ähnlichkeitsfunktionen bestimmte Ähnlichkeiten vorausberechnet. Das Bauen des
Index kann einige Minuten, eventuell sogar Stunden, dauern. Deshalb wird der
Index nach dem Bauen gespeichert. Im Falle eines Neustarts der Engine müssen
dann nur die Datensätze eingefügt werden, welche während der letzten Query-Phase
hinzugekommen sind.

### Query-Phase

```{.plantuml #fig:query_phase
    caption="Aktivitätsdiagramm der Query-Phase."}
|Engine|
start
:read transformed dataset;
repeat
    :get query record from dataset;
    |Indexer|
    :query candidates from index;
    |Klassifier|
    :predict matches on candidates;
    |Engine|
    :save match result;
repeat while (more queries?)
|Engine|
:pass results to user;
stop
```

In der Query-Phase (siehe @fig:query_phase) erhält die Engine von einem
Query-Parser eine Menge von Anfragedatensätzen. Nachdem diese vorverarbeitet
wurden, wird jeder Datensatz einzeln dem Indexer übergeben. Dieser erzeugt für
den übergebenen Datensatz eine Kandidatenmenge möglicher Matches. Anschließend
wird diese Kandidatenmenge dem Klassifikator übergeben. Das Modell des
**Klassifikators** wurde während der *Fit-Phase* von dem
Hyperparameter-Optimierer trainiert und kann nun in der *Query-Phase* genutzt
werden, um die Kandidatenliste des Indexers in Matches und Non-Matches zu
klassifizieren. Für den Hyperparameter-Optimierer stellt der Klassifikator eine
Liste von Parametern bereit, welche für die Eingabedaten als Optimierung zur
Verfügung stehen sollen. Um einen optimalen Klassifikator für die Eingabedaten
zu bekommen ist es abgesehen von der Parameterliste möglich eine Liste von
verschiedenen Klassifikatoren anzugeben, beispielsweise DecisionTree und SVM.
Das Ergebnis der Klassifikation speichert die Engine zwischen, bis alle
Datensätze verarbeitet wurden. Abschließend werden die Ergebnisse gesammelt an
den Benutzer übergeben.

### Nachverarbeitung

Die Auswertung der Qualität und der Effizienz ist ein wichtiges Indiz wie gut
die gewählte Konfiguration funktioniert. Des Weiteren ist es dadurch möglich das
Zusammenspiel der Komponenten untereinander zu bewerten, indem beispielsweise
eine alternative Komponente eingesetzt wird, um die Auswirkungen der neuen
Komponente in den Metriken zu überprüft werden. Von den Metriken, welche in
@sec:measurements beschrieben wurden, kann die Engine für das Blocking die Pairs
Completeness, Pairs Quality und Reduction Ratio aufzeichnen, sowie für den
Klassifikator Recall, Precision und F-measure messen. Des Weiteren werden
die Daten zum Zeichnen eines F-measure Graphen und einer Precision-Recall Kurve
bereitgestellt. Darüber hinaus kann die Engine messen, wie lange einzelne
Operationen einer Komponente benötigen. Beispielsweise wird die gemessen, wie
lange es dauert einen Datensatz in den Index einzufügen bzw. zu einem
Anfragedatensatz die Kandidatenliste zu erhalten. Dadurch kann die Performanz,
beispielsweise in Anfragen pro Sekunde auf einer Testhardware angegeben werden.

## Komponenten

In diesem Abschnitt werden die konkreten Komponenten für die Engine detailiert
beschrieben.

### Label Generator

Für den Label Generator wurden beide Ausprägungen implementiert. Zunächst wird
die Variante ohne Ground Truth beschrieben und anschließend die Variante mit
Ground Truth, welche die erste Ausprägung modifiziert.

#### Ohne Ground Truth

Der Label Generator ohne Ground Truth implementiert den WeakLabel Algorithmus
vom Kejriwal & Miranker [@KM:Unsupervised:13] zur Erzeugung von schwachen
Labels. Dabei werden die Parameter automatisch auf gute Grundwerte gesetzt. Die
obere Schelle $ut$ beträgt 0.6 und die untere Schwelle $lt$ 0.1. Die maximalen
Matches $max_p$ werden anhand der Datensatzgröße ermittelt $max_p = |D| *
0.025$. Die maximalen Non-Matches sind Faktor 5 der Matches $max_n = max_p * 5$.
Der Algorithmus besteht aus vier Teilen (Algorithmus \ref{alg:weaklabels}).
Zunächst wird die TF/IDF Statistik über $D$ erzeugt (Zeile 4). Anschließend wird
jeder Datensatz per Attribute in Token zerlegt, nach welchen ein Standard
Blocking durchgeführt wird (Zeilen 5-10). Danach wird eine Kandidatenmenge
generiert, indem ein Fenster der Größe $c$ über jeden einzelnen Block geschoben
wird (Zeile 11 -15). Abschließend wird für jedes Paar die TF/IDF-Ähnlichkeit
(aus Cohen [@Coh:WHIRL:00]) bestimmt und je nach Schwellenwertklassifikation in
das Set der Matches oder Non-Matches aufgenommen (Zeilen 16-36).

```texalgo
#alg:weaklabels WeakTrainingSet w\textbackslash o Ground Truth
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Dataset: $D$
  \item Upper Threshold: $ut$
  \item Lower Threshold: $lt$
  \item Blocking Window Size: $c$
  \item Maximum Duplicate Pairs: $d$
  \item Maximum Non-Duplicate Pairs: $nd$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item A set of positive samples: $P$
  \item A set of negative samples: $N$
  \end{itemize}
}
\Statex
\State Initialize set $P = ()$
\State Initialize set $N = ()$
\State Initialize set of tuple pairs $C = ()$
\State Generate TFIDF statistics of $D$
\For{fields $f \in D$}
    \For{records $r \in D$}
        \State Tokenize $r_f$
        \State Block $r$ on generate tokens
    \EndFor
\EndFor
\For{block $B$ generate in previous step}
    \State Slide a window of size c over tupels in $B$\\
           Generate all possible pairs within window and\\
           add to $C$
\EndFor
\For{pairs $(t_1, t_2) \in C$}
    \State Compute TFIDF similarity $sim$ of $(t_1, t_2)$
    \If{$sim \geq ut$}
        \If{$|P| < d$}
            \State add $(t_1, t_2)$ to $P$
            \State \textbf{continue}
        \EndIf
        \If{$sim >$ lowest $sim$ in $P$}
            \State Replace pair with lowest $sim$ in $P$ with $(t_1, t_2)$
        \EndIf
    \EndIf
    \If{$sim < lt$}
        \If{$|N| < nd$}
            \State add $(t_1, t_2)$ to $N$
            \State \textbf{continue}
        \EndIf
        \If{$sim >$ lowest $sim$ in $N$}
            \State Replace pair with lowest $sim$ in $N$ with $(t_1, t_2)$
        \EndIf
    \EndIf
\EndFor
\State Return $P$ and $N$

#alg:labels WeakTrainingSet with Ground Truth
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Dataset: $D$
  \item Ground Truth $GT$
  \item Blocking Window Size: $c$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item A set of positive samples: $P$
  \item A set of negative samples: $N$
  \end{itemize}
}
\Statex
\State Initialize set $P = ()$
\State Initialize set $N = ()$
\State Initialize set of tuple pairs $C = ()$
\State Generate TFIDF statistics of $D$
\For{fields $f \in D$}
    \For{records $r \in D$}
        \State Tokenize $r_f$
        \State Block $r$ on generate tokens
    \EndFor
\EndFor
\For{block $B$ generate in previous step}
    \State  Slide a window of size c over tupels in $B$
    \StatexIndent[1] Generate all possible pairs within window and
    \StatexIndent[1] add to $C$
\EndFor
\For{pair $(t_1, t_2) \in GT$}
    \State Add $(t_1, t_2)$ to $P$
\EndFor
\State Initialize dictionary $M = \{\}$
\For{pairs $(t_1, t_2) \in C$}
    \State Compute TFIDF similarity $sim$ of $(t_1, t_2)$
    \State $M[(t_1, t_2)] = sim$
\EndFor
\State Calculate probability distribution over $M$
\State $max_n = |GT| * 5$
\For{$i = 1$ \textbf{to} $max_n$}
    \State Choose a pair $p$ from $M$ based on probability distribution
    \State Add $p$ to $N$
\EndFor
\State Return $P$ and $N$
```

#### Mit Ground Truth

Die Implementierung des Label Generators mit Ground Truth, ist eine Modifikation
des WeakLabel-Algorithmuses von Kejriwal & Miranker (Algorithmus
\ref{alg:labels}). Dabei sind die ersten drei Schritte gleich zum ursprünglichen
Algorithmus. Nachdem die Kandidatenmenge erzeugt wurde, werden alle Ground Truth
Paare nach $P$ übernommen (Zeilen 16-18). Anschließend werden die
TF/IDF-Ähnlichkeit ermittelt und in $M$ zwischengespeichert (Zeilen 19-23).
Danach wird die Wahrscheinlichkeitsverteilung der Ähnlichkeiten in $M$ durch ein
Histogramm ermittelt (Zeile 24). Aus den Behältern des Histogramms wird
anschließend zufällig ein Paar gezogen (Zeile 27). Dabei erfolgt die Ziehung
nach der Wahrscheinlichkeitsverteilung, d.h. aus ein Behältnis mit vielen Paaren
wird mit höhere Wahrscheinlichkeit ein Paar ausgewählt, als aus einem Behältnis
mit wenigen Paaren. Die Ziehen wird $max_n$ mal wiederholt bzw. solange bis
keine Paare mehr übrig sind (Zeilen 26-29).

### Blocking Schema Generator

#### Blocks DNF Generator

Der Blocks DNF Generator erzeugt ein Blocking Schema in disjunktiver Normalform.
Dazu bildet er Ausdrücke und bewertet die Qualität und Effektivität mit
Algorithmus \ref{alg:dnf_eval}. Zur Evaluierung eines Ausdrucks $t$ benötigt der
Algorithmus den Datensatz $D$, die Matches $P$ und die Non-Matches $N$, sowie
den von der Engine eingesetzen Indexer $IX$. Der Ausdruck $t$ wird dem Indexer
$IX$ als Blocking Schema übergeben, wodurch dieser in der Lage ist seinen Index
$I$ über $D$ zu bauen (Zeile 1). Anschließend werden alle Blöcke aus $I$ einzeln
betrachtet (Zeile 4). Für jeden Block wird zunächst die Paarkombination aller
dem Block zugehöriger Datensätze ermittelt, welche der Menge $C$ hinzugefügt
werden (Zeile 5). Zudem wird mittels der Match $P$ und Non-Matches $N$ die
Anzahl der true positives, false positives und true negatives ermittelt und
global in $TP$, $FP$ und $FN$ aufsummiert (Zeile 6). Damit Ausdrücke
untereinander verglichen werden können werden zwei Arrays $y_{true}$ und
${y_pred}$ mit der Länge $|P \cup N|$ erzeugt mit deren Hilfe das F-measure
bestimmt werden kann. $y_{true}$ gibt an welcher Klasse ein Paar $p$ angehört:
Match, wenn $p \in P$ oder Non-Match, wenn $p \in N$. $y_{pred}$ bestimmt, ob
ein Datensatzpaar einen gemeinsamen Block in $I$ hat $y_{pred}[p] = True$ oder
nicht $y_{pred}[p] = False$ (Zeilen 10-27). Durch die von den Blöcken
aufsummierten $TP$, $FP$, $FN$ wird als Bewertung für $t$ der F-measure Wert $f$
bestimmt. Die Werte für F-measure, $y_{true}$ und $y_{pred}$ werden zum Schluss
an den Aufrufer zurückgegeben.

Der Algorithmus zur Bestimmung des Blocking Schemas ist in Algorithmus
\ref{alg:dnf} dargestellt. Dieser bekommt als Eingangsdaten die spezifischen
Blockingprädikate $S$. Da die maximale Konjunktion der Blockingprädikate bzw.
die maximale Disjunktion potentiell unendlich groß ist, wird diese über die
Parameter $k$ für die Konjunktionen und $d$ für die Disjunktionen begrenzt. Aus
Erfahrung zeigt sich, dass Werte $>3$ keine wesentliche Verbesserung bieten. Ein
weiterer Grund die Konjunktionen bzw. Disjunktionen nicht beliebig zu erhöhen
ist, dass der Indexer deutlich komplexere Blöcke bauen muss, was sich in der
Effektiviät niederschlägt. Der Algorithmus beginnt die Ausdrücke für die DNF zu
erzeugen, indem alle Kombinationen der Menge spezifischer Blockingprädikte $S$
bis zur Länge $k$ der maximalen Konjunktionen berechnet werden (Zeilen 3-5).
Anschließend wird jeder Ausdruck $t$ durch Algorithmus \ref{dnf:eval} evaluiert.
Ist der F-measure Wert, der für $t$ bestimmt wurde, gleich 0, indiziert dies
einen ungeeigneten Block und der Ausdruck wird entfernt (Zeile 9). Aus den noch
in $T$ vorhandenen Ausdrücken werden durch Disjunktion bis zur Länge $d$
mögliche Kandidaten eines Blocking Schemas generiert (Zeilen 12-14). Ein
Blocking Schema wird ausgewählt, indem die $y_{pred}$ und $y_{true}$ Arrays der
Ausdrücke in jedem potentiellen Blocking Schema verodert werden (Zeilen 19-22)
und daraus das F-measure berechnet wird (Zeile 23). Das potentielle Blocking
Schema mit dem höchsten F-measure wird abschließend ausgewählt und an die Engine
zurückgegeben.

```texalgo
#alg:dnf DNF Blockng Schema
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Set of specific blocking predicates: $S$
  \item Maximum conjunctions per term: $k$
  \item Maximum disjunctions of terms: $d$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Blocking Scheme: $BS$
  \end{itemize}
}
\Statex
\State Initialize set of blocking scheme candidates $BS_C = ()$
\State Initialize set of terms $T = ()$
\For{$i = 1$ \textbf{to} $k$}
    \State Generate combination of $S$ with depth $i$ and
    \StatexIndent[1] add to $T$
\EndFor
\For{term $t \in T$}
    \State $fmeasure, y_{true}, y_{pred} = evaluateTerm(t)$\Comment
    Algorithm~\ref{alg:dnf_eval}
    \If{$fmeasure = 0$}
        \State Remove $t$ from $T$
    \EndIf
\EndFor
\For{$i = 1$ \textbf{to} $d$}
    \State Generate combination $C$ of $T$ with depth $i$
    \State Add $C$ to $BS_C$
\EndFor
\For{Blocking scheme $bs \in BS_C$}
    \State Initialize array $y_{true}$ with length $|P \cup N|$
    \State Initialize array $y_{pred}$ with length $|P \cup N|$
    \For{term $t \in bs$}
        \State $y_{true} \lor t.y_{true}$
        \State $y_{pred} \lor t.y_{pred}$
    \EndFor
    \State Score $s = fmeasure(y_{true}, y_{pred})$
    \If{$s > top_score$}
        \State $BS = bs$
    \EndIf
\EndFor
\State return $BS$

#alg:dnf_eval Evaluate Term
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Term: $t$
  \item Dataset: $D$
  \item Indexer: $IX$
  \item Set of positive pairs: $P$
  \item Set of negative pairs: $N$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item F-measure: $f$
  \item Labels: $y_{true}$
  \item Predictions: $y_{pred}$
  \end{itemize}
}
\Statex
\State Build Index $I$ over $D$ using Indexer $IX$ and Term $t$
\State Initialize set of pairs $C = ()$
\State Initialize $TP = 0, FP = 0, FN = 0$
\For{block $b \in I$}
    \State Generate pair combinations $pc$ for records in $b$
    \StatexIndent[1] and add them to $C$
    \State According to $P$ and $N$ calculate number of true
    \StatexIndent[1] positives, false positives and false negatives and
    \StatexIndent[1] sum them up with $TP$, $FP$ and $FN$.
\EndFor
\State Initialize array $y_{true}$ with length $|P \cup N|$
\State Initialize array $y_{pred}$ with length $|P \cup N|$
\For{$i = 1$ \textbf{to} $|P|$}
    \State Pair $p = P[i]$
    \State $y_{true} = True$
    \If{$p \in C$}
        \State $y_{pred} = True$
    \Else
        \State $y_{pred} = False$
    \EndIf
\EndFor
\For{$i = |P| + 1$ \textbf{to} $|N|$}
    \State Pair $p = N[i]$
    \State $y_{true} = False$
    \If{$p \in C$}
        \State $y_{pred} = True$
    \Else
        \State $y_{pred} = False$
    \EndIf
\EndFor
\State Calculate F-measure $f$ according to $TP, FN, FP$
\State return $f, y_{true}, y_{pred}$
```

### Indexer

#### MDySimII

Der MDySimII Indexer ist eine Erweiterung des DySimII (vgl. @sec:dysimII), der
in der Lage ist ein DNF Blocking Schema, statt einzelner Blockschlüssel, zu
nutzen. Dadurch ergeben sich einige Unterschiede zur ursprünglichen Umsetzung.
Die Idee des DySimII, die Ähnlichkeit aller Attribute vorauszuberechnen, basiert
auf der Annahme, dass es für jedes Attribut eine Enkodierungsfunktion gibt, die
Blockschlüssel für ein Attribut erzeugt. Durch das DNF Blocking Schema ist es
jedoch nicht mehr garantiert, dass jedes Attribut beim Blocking berücksichtigt
wird. Im schlimmsten Fall besteht das Blocking Schema nur aus einem einstelligen
Ausdruck, dadurch wird das Blocking lediglich auf einem Attribut durchgeführt.
Dementsprechend muss bei einer Anfrage, zwischen den, im Blocking Schema nicht
enthaltenen Attribute, immer die Ähnlichkeit ermittelt werden und kann nicht im
Index nachgeschlagen werden. Eine weitere Änderung ist, dass das DNF Blocking
Schema zu einem Attribut mehrere Blockschlüssel erzeugen kann, wodurch ein
Datensatz pro Feld in mehrere Blöcke eingefügt werden kann. Des Weiteren
erhalten bei Ausdrücken mit zwei oder mehr spezifischen Blockingprädikaten zwei
oder mehr Attribute dieselben Blockschlüssel und müssen entsprechend eingeordnet
werden. Als Ergebnis einer Anfrage wurde von der ursprünglichen DySimII
Implementierung eine Kandidatenliste mit der aufsummierten
Gesamtwahrscheinlichkeit der Kandidaten zurückgegeben. Der MDySimII hingegen
gibt für jeden Kandidaten einen Vektor mit den einzelnen Attributsähnlichkeiten
zurück.

In Algorithmus \ref{alg:mdysim_insert} ist, die für den MDySimII angepasste,
*Build-Phase* beschrieben. Zunächst werden die Index Datenstrukturen Record
Index, Block Index und Similarity Index für jedes, in der DNF vorkommende
Attribute, erzeugt (Zeilen 1-3). Die im Algorithmus genannten $fields$ die
Positionen der Attribute in einem Datensatz $r = [a_1, \cdot, a_n]$.
Anschließend werden alle Datensätze in $D$ nacheinander eingefügt. Dazu wird
zunächst der Datensatzidentifier, in alle oben erzeuge RIs, unter dem
entsprechenden Attribute eingefügt (Zeilen 5-7). Anschließend werden alle
Ausdrücke der DNF einzeln betrachtet. Zu jedem Ausdruck werden für den Datensatz
$r$ die Blockschlüsselwerte erzeugt (Zeile 9). Für jedes abgedeckte Attribut
des aktuellen Ausdrucks, werden die Attributswerte von $r$ unter dem
Blockschlüssel $bkv$ in den entsprechenden Block Index eingefügt (Zeilen 12-14).
Nachdem ein Attribut in einen Block eingefügt wurde, werden analog zum
ursprünglichen DySimII Verfahren die Ähnlichkeiten der Attribute ermittelt und
gegenseitig im Similarity Index ergänzt bzw. eingefügt (Zeilen 17-24).

```texalgo
#alg:mdysim_insert DNF Similarity-Aware Index - Build
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Data set: $D$
  \item DNF Blocking Scheme: $BS$
  \item Fields used in $BS$ as: $F$
  \item Similarity funcitons: $S_i,i=1 \cdots n$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Index data structures: $RI, BI, SI$
  \end{itemize}
}
\Statex
\For{fields $f \in F$}
  \State Initialize $RI_f = \{\}$, $BI_f = \{\}$, $SI_f = \{\}$
\EndFor
\For{records $r \in D$}
  \For{fields $f \in F$}
    \State insert $r.id$ into $RI_f[r.f]$
  \EndFor
  \For{terms $t \in BS$}
    \State $bkvs = blocking\_key\_values(t, r)$
    \For{$bkv \in bkvs$}
      \For{fields $f \in t.fields$}
        \State $bi = BI_f[bkv]$
        \State Append r.f to $bi$
        \State $BI_f[bkv] = bi$
        \State Initialize inverted index list $si = ()$
        \For{$v \in bi$}
          \If{$v \notin SI_f$}
            \State $sim = S_f(r.f, v)$
            \State $oi = SI_f[v]$
            \State Append$(r.f, sim)$ to $oi$
            \State $SI_f[v] = oi$
            \State Append$(v, sim)$ to $si$
          \EndIf
          \State $SI_f[r.f] = si$
        \EndFor
      \EndFor
    \EndFor
  \EndFor
\EndFor

#alg:mdysim_query DNF Similarity-Aware Index - Query
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Query record: $q$
  \item DNF Blocking Schema: $BS$
  \item Fields used in $BS$ as: $F$
  \item Similarity funcitons: $S_i,i=1 \cdots n$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Matches: $M$
  \end{itemize}
}
\Statex
\State Initialize dictionary $M = \{\}$
\State Insert $q$ into Index
\For{fields $f \in F$}
    \State $ri = RI_f[q.f]$
    \For{$r.id \in ri$}
        \State $M[(r.id, field)] = 1.0$
    \EndFor
    \State $si = SI_f[q.f]$
    \For{$(r.f, sim) \in si$}
        \State $ri = RI_f[r.f]$
        \For{$r.id \in ri$}
            \State $M[(r.id, field)] = sim$
        \EndFor
    \EndFor
\EndFor
```

Die *Query-Phase* des MDySimII wird in Algorithmus \ref{alg:mdysim_query}
beschrieben. Zunächst wird die Kandidatenliste $C$ initialisiert (Zeile
1). Dann wird der Anfragedatensatz nach Algorithmus \ref{alg:mydysim_insert} in
den Index eingefügt (Zeile 2). Sollte der Datensatz sich schon im Index befinden
wird dieser Schritt übersprungen. Für jedes Attribut aus $q$, das vom
dem Blocking Schema $BS$ abgedeckt wird, wird zunächst alle Kandidaten
mit übereinstimmenden Attribut aus dem RI geholt und mit dem Ähnlichkeitswert
1.0 in die Kandidatenliste übernommen (Zeilen 4-7). Anschließend werden für das
Attribute alle Kandidaten im selben Block mit ihrer vorberechneten Ähnlichkeit
aus dem SI geholt. Die Identifier der Attribute im selben Block werden über den
RI aufgelöst und anschließend mit dem Ähnlichkeitswert aus dem SI in die
Kandidatenlist übernommen (Zeilen 8-14).

