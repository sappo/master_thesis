# Design eines selbstkonfigurierenden Systems

In diesem Kapitel wird zunächst die Prozesse eines sich selbst konfigurierenden
Entity Resolution System, für dynamische Datenquellen, zur Behandlung von
Anfrageströme, beschrieben. Anschließend die zu lernende Konfiguration formal
definiert. Anschließend werden die Komponenten des Systems vorgestellt und deren
Schnittstellen beschrieben. Werden die Aufgaben der Komponenten in den einzelnen
Prozessschritten erklärt.

## Prozesssicht

```{.a2s #fig:engine_state
    caption="Zustandsdiagramm des selbstkonfigurierenden System. Lernen der
    Konfiguration versetzt das System von unangepasst nach angepasst. Wurde der
    Index gebaut, ist das System im Zustand gebaut und kann Anfrage
    entgegennehmen."}
        .------------.              .--------.  building    .-------.
        | not fitted |   fitting    | fitted +------------->| built |
 ●----->+------------+------------->+--------+  re-fitting  +-------+
        |            | load config  |        |<-------------+       |
        '------------'              '------+-'              '-----+-'
                                      ^    |                  ^   |
                                      '----'                  '---'
                                   save config              querying/
                                                            evalute
```

Die in Kapitel 2 und 3 vorgestellten Verfahren, für dynamische Entity
Resolution, trennen zwischen Build-Phase und Query-Phase. Diese Trennung wird
auch für das selbstkonfigurierende System aufrecht erhalten. Zusätzlich gibt es
noch eine weitere Phase zum Erlernen der Konfiguration, im Folgenden als
*Fit-Phase* bezeichnet. Je nach Phase befindet sich bzw. wechselt das System in
einen von drei Zuständen, die in @fig:engine_state dargestellt sind. Ein neu
erzeugtes System ist *unangepasst* und kann durch das Lernen der Konfiguration
(engl. fitting) in den Zustand *angepasst* wechseln. Alternativ kann der
Zustandsübergang durch das Laden einer bereits gelernte Konfiguration
durchgeführt werden. Anhand dieser Konfiguration kann der Index auf einem
initialen Datenbestand gebaut (engl. building) werden. Danach befindet sich das
System im Zustand *gebaut*. In diesem Zustand kann die eigentliche Entity
Resolution, durch stellen von Anfragen aus einem Datenstrom (engl. querying),
durchgeführt werden. Da die Möglichkeit besteht jede Anfrage in den Datenbestand
(den Index) aufzunehmen, liegen nach einer gewissen Zeit genügend neue Daten
vor, sodass sich auf Basis derer auch die optimale Konfiguartion verändert haben
kann. Während des erneuten Lernens (engl. refitting) können weiterhin Anfragen
beantwortet werden. Wenn der Lernvorgang abgeschlossen ist, muss der Index
erneut gebaut werden, bevor das System wieder anfragen entgegen nehmen kann.
Wenn Komponenten für das System entwickelt werden, ist es notwendig deren
Qualität und Effektivität auszuwerten. Weshalb das System im Entwicklungsbetrieb
entsprechende Metriken erheben und auswerten kann. Die Auswertung erfolgt
nachdem mindestens eine Anfrage durchgeführt wurde.

In der Fit-Phase nimmt die Engine die Konfiguration des Systems vor. Eine
Konfiguration ist ein Tupel $(GT, BS, S, M)$ bestehend aus der Grund Truth, dem
Blocking Schema, den Ähnlichkeitsfunktionen und dem Klassikationsmodell. Die
Ground Truth $GT = (P, N)$ ist ebenfalls ein Tupel, dass sich in die Menge der
positive Datensatzpaare, die tatsächlichen Matches (true positives), sowie die
Menge der negativen Datensatzpaare, die tatsächlichen Non-Matches (true
negatives) teilt. Ein Datensatz wird definiert als $n$-Tupel, wobei $n$ die
Anzahl der Attribute ist. Ein Tupel hat die Form $t = (a_1, a_2, \dots, a_n)$.
Ein Attribut hat eine feste Position im Tupel, die als Feld oder Datenfeld $f$
bezeichnet wird. Ein Datensatzensatzpaar ist definiert als $p = (t_j, t_k),
j \neq k$, wobei $j$ und $k$ zwei beliebige Tupel desselben Datensatzes sein
können. Weiterhin gilt $\forall p \in P, p \notin N$ und umgekehrt $\forall
p \in N, p \notin P$. Das Blocking Schema entspricht der Definition aus
@sec:blk_scheme, $BS = (term_1 \land \dots \land term_j) \lor \dots \lor (term_k
\land \dots \land term_n)$. Eine Ähnlichkeitsfunktion wird während des Lernens
der Konfiguration mit einem Attribut verknüpft. Die Menge der gelernten
Ähnlichkeitsfunktionen werden entsprechend als Tupel angegeben $S = {(f_1, sim),
\dots, (f_n, sim)}$. Die Ähnlichkeitsfuntion $sim$ ist eine von $m$ möglichen
Ähnlichkeitsfunktionen ${sim_1, \dots, sim_m}$, die vom System implementiert
wurden. Das Klassifikationsmodell $M$ ist spezifisch für den eingesetzten
Klassifikator und entspricht, bespielsweise einem trainierten Entscheidungsbaum.

## Komponentenmodell

```{.plantuml #fig:engine
    caption="Komponentenmodell des selbstkonfigurierenden Systems. Bestehend aus
    dem Ground Truth Generator, dem Blocking Scheme Lerner, dem Similarity
    Lerner und dem Fusion-Lerner, welche für das Erlernen der Konfiguration
    (Fit-Phase) nötig sind, dem Indexer, welcher anhand der gelernten
    Konfiguration gebaut wird und dem Klassifikator. Der Parser, um Daten einer
    Datenquelle zu laden und der Präprozessor, um die geladenen Daten für Entity
    Resolution zu manipulieren"}
skinparam componentStyle uml2
component "Engine" {
    [Parser] -right- D
    D )-right- [Preprocessor]
    [Preprocessor] -down- PD

    package "Fit-Phase" {
        PD )-down- [Blocking Scheme Learner]
        PD )-down- [Label Generator]
        PD )-down- [Similarity Learner]
        PD )-down- [Fusion-Learner]
        GT  -up- [Label Generator]
        GT )-up- [Blocking Scheme Learner]
        GT )-up- [Fusion-Learner]
        GT )-up- [Similarity Learner]
        BS -up- [Blocking Scheme Learner]
        M -up- [Fusion-Learner]
        S -up- [Similarity Learner]
        B )-up- [Blocking Scheme Learner]
        PG )-up- [Fusion-Learner]
    }

    package "Build-/Query-Phase" {
        B -up- [Indexer]
        BS )-down- [Indexer]
        PD )-down- [Indexer]
        S )-down- [Indexer]

        C -left- [Indexer]
        PG -down- [Klassifier]
        M )-down- [Klassifier]
        C )-right- [Klassifier]
        R -left- [Klassifier]
    }
}
```

Die Engine ist das Herzstück des selbstkonfigurierenden Systems und besteht aus
einzelnen Komponenten, die bei Schnittstellenkompatibilität beliebig
ausgetauscht werden. Die Komponenten und Schnittstellen der Engine sind in
@fig:engine dargestellt.

* **Parser**. Der Parser liest Datensätze aus einer Datenquelle bietet eine
  Menge von Tupeln $D$ an.
* **Präprozessor**. Der Präprozessor vorverarbeitet jedes Attribut jedes
  Datensatzes aus $D$ in einer Pipeline, anhand einer Reihe von
  benutzerdefinierten Operationen, welche sequentiell angewendet werden,
  beispielsweise Rechtschreibprüfung, das Ergebnis ist die vorverarbeitete Menge
  an Tupeln $PD$.
* **Label Generator**. Der Label Generator erzeugt eine geeignete Ground Truth
  $GT$ zum Einstellen der Parameter in den folgenden Komponenten. Er konsumiert
  dazu die vorverbeiteten Tupel $PD$.
* **Blocking Schema Lerner**. Der Blocking Schema Lerner erzeugt eine Blocking
  Schema $BS$ in distributiver Normalform nach [@KM:Unsupervised:13]. Zur
  Bewertung eines Ausdrucks, konsumiert er die generierten Blöcke $B$ eines
  Indexers.
* **Similarity Lerner**. Der Similarity Lerner bestimmt für jedes Attribut eine
  geeignete Ähnlichkeitsfunktion $S$.
* **Fusion-Lerner**. Der Fusion-Lerner ermittelt die besten Parameter für den
  verwendeten Klassifikator. Von diesem erhält der Fusion-Lerner mögliche
  Parameter $PG$, anhand welcher das Klassifikationsmodell $M$ trainert wird.
* **Indexer**. Der Indexer wendet ein Blocking Verfahren auf die
  vorverarbeiteten Daten $PD$ an und bietet bei einer Anfrage eine
  Kandidatenliste $C$ mit möglichen Duplikaten an.
* **Klassifikator**. Der Klassifikator ordnet die Kandidate aus $C$ in Matches
  und Non-Matches, die Menge an Matches $R$, ist das Ergebnis einer Anfrage.

Die Hauptaufgabe der Engine ist es die Interaktionen zwischen den Komponenten zu
steuern. Dazu werden im simpelsten Fall die Daten von einer Komponente zur
nächsten weitergereicht. Zum Teil muss die Engine zunächst jedoch die
Rückgabewerte für die nächste Komponente aufbereitet. Die Engine dient weiterhin
als die Schnittstelle für den Benutzer. Alle drei Phasen haben den Schritt der
Vorverarbeitung gemeinsam.

### Vorverarbeitung

Die Vorverarbeitung der Daten ist in allen drei Phasen notwendig und macht die
Datensätze robuster gegenüber Missklassifikationen, indem offensichtliche Fehler
korrigiert und eventuelle, für die Identifikation von Entitäten irrelevante,
Varianzen bereinigt weren. In @fig:preprocessing sind die beteiligten
Komponenten Parser und Präprozesser mit ihren Aktivitäten visualisiert. Jede
Phase beginnt mit der Auswahl des korrekten Parsers durch die Engine.

```{.plantuml #fig:preprocessing
    caption="Aktivitätsdiagramm der Vorverarbeitung. Der Parser liest einen
    Datensatz, welcher vom Präprozessor transformieren wird. Der transformierte
    Datensatz wird von der Engine abgespeichert."}
|Engine|
start
:choose parser for Fit-,
Build- or Query-Phase;
|Parser|
:read dataset into D;
if (is Fit-Phase?) then (yes)
    :assign attribute datatypes;
endif
|Preprozessor|
:transform dataset into PD;
|Engine|
:save transformed dataset PD;
:proceed with (Fit/Build/Query)-Phase;
```

**Parser**. Der Parser ist eine einfache Komponente, welche Datensätze aus einer
Datenquelle liest und eine Menge von Tupeln $D$ an die Engine übergibt. Je nach
Phase kann die Datenquelle ein beliebiges Format haben, weshalb für jede Phase
ein eigener Parser bestimmt werden kann. Für *Fit-* und *Build-Phase*, wo große
Datenmengen bearbeitet werden, liest der Parser beispielsweise aus einer
CSV-Datei oder selektiert die Datensätze aus einer Datenbank. Währenddessen in
der *Query-Phase* nur einzelne oder kleine Datenmengen gelesen werden, weshalb
der Parser hier aus einer Message Queue (MQ) Datensätze erhalten könnte. Während
der *Fit-Phase* hat der Parser zudem dafür Sorge zu tragen, dass der Engine die
Attribute des Datensatzes, sowie deren Datentypen bekannt gemacht werden. Anhand
der Datentypen können die Komponenten der Fit-Phase effizienter eine gute
Konfigurationen bestimmen. Wenn der Parser diese Information nicht bereitstellt,
werden alle Attribute als Zeichenketten behandelt.

**Präprozessor**. Der Präprozessor bzw. die Präprozessor-Pipeline besteht aus
einer Reihe von Funktionen, die nacheinander auf alle Tupel aus $D$ angewandt
werden, um diese für die Entity Resolution vorzubereiten und robuster zu machen.
Je nach Datentyp des Attributs wird dabei eine andere Pipeline verwendet.
Dieselbe Präprozessor-Pipeline muss in allen drei Phasen verwendet, damit die
vorverarbeiteten Datenmenge $PD$ stets die gleichen Charakteristiken aufweist.
Werden vom Benutzer keine Operationen vorgegeben, beschränkt sich die Pipeline
auf generische Modifkationen. Die zum Zeitpunkt dieser Thesis entwickelte Engine
ist, zum Zwecke der Vorverarbeitung, automatisiert lediglich in der Lage Strings
in Kleinschreibweise zu konvertiert. Andere Operationen wie das Entfernen von
Stopwörtern (z.B. *und*, *oder*) benötigen zum einen die Sprache der Attribute,
welche zu erkennen durchaus eine lösbare Aufgabe ist, zum anderen aber auch
einen Datenbestand gegen den geprüft wird. Ein komplexere domänenspezifische
Anwendung hierfür ist, beispielsweise die Überprüfung der postalischen Addresse,
welche zum einen länderspezifische Daten benötigt und zum anderen auch ständig
auf dem aktuellen Stand gehalten werden muss. Neben zusätzlichen Funktionen muss
der Benutzer auch die Reihenfolge der Funktionen vorgeben. Beispielweise
zunächst die Rechtspreibprüfung und anschließend die Konvertierung in
Kleinschreibweise, da durch die Rechtschreibprüfung diese Konvertierung in
Teilen wieder aufgehoben wird.

Die vorverarbeiteten Tupel $PD$ des Präprozessors, werden abschließend
abgespeichert, um zu einem späteren Zeitpunkt geladen zu werden.

### Fit-Phase

```{.plantuml #fig:fit_phase
    caption="Aktivitätsdiagramm der Fit-Phase. Die Engine kontrolliert den
    Datenfluss zwischen den Komponenten, speichert Konfigurationen und breitet
    Daten für Komponenten auf. Der Label Generator erzeugt die Ground Truth,
    durch welche ein DNF-Blocking Schema vom BS-Lerner erzeugt wird. Auf einer
    durch das Blocking Schema gefilterten Liste werden anschließend die
    Ähnlichkeitsfunktionen bestimmt. Anhand dieser Funktionen können
    Ähnlichkeitsvektoren auf der Ground Truth berechnet werden und vom
    Fusion-Lerner dadurch die Hyperparameter für den Klassifikator bestimmt,
    sowie abschließend das Klassifikationsmodell trainiert werden."}
|Engine|
start
:read transformed dataset PD;
|Label Generator|
:generate ground truth GT;
|Engine|
:save ground truth GT;
|BS-Learner|
:predict DNF Blocking Scheme BS;
|Engine|
:save DNF Blocking Scheme BS;
:filter ground truth GT into FGT;
|Sim-Learner|
:predict similarity functions S;
|Engine|
:save similarity functions S;
:calculate ground truth
similarity vectors;
|HP-Optimizer|
:predict hyperparameters;
:train model M;
|Engine|
:save model M;
stop
```

Die für die Fit-Phase relevanten Komponenten und Schnittstellen sind in
@fig:engine in der Box "Fit-Phase" gruppiert. Bei großen Datensätzen kann diese
Phase sehr lange dauern, weshalb die Engine die Teilkonfigurationen der
Komponenten direkt sichert. Dadurch kann die Fit-Phase im Falle eines Abbruchs,
z.B. durch einen Systemneustart, fortgesetzt werden und nur die unterbrochene
Komponente muss wiederholt werden. Wurde die Fit-Phase abgeschlossen, ist es
möglich die ermittelte Konfiguration einzulesen. Wodurch die Fit-Phase
übersprungen wird. @fig:fit_phase zeigt das Aktivitätsdiagramm der Fit-Phase,
ohne existierende Konfiguratation.

**Label Generator**. Der Label Generator erzeugt die Ground Truth $GT$, in Form
von klassifizierten Matches und Non-Matches, für später in der Fit-Phase
folgenden Komponenten,  Dazu nutz der Label Generator die, vorverarbeiteten
Tupel $PD$ und bildet Datensatzpaare (@fig:fit_phase). Dabei gibt es zwei
Ausprägungen. In der ersten Ausprägung erhält der Label Generator
vorklassifizierte Matches, für den vom Parser eingelesenen Datensatz. In der
zweiten Ausprägung stehen dem Label Generator keine vorklassifizierten Matches
zur Verfügung. Weshalb die Ground Truth vollständig automatisiert bestimmt
werden muss (siehe @sec:lblgen_nogt). Ein Label Generator kann beide
Ausprägungen implementieren. Falls nur die erste Ausprägung implementiert ist,
kann die Engine, ohne existierende Ground Truth, die Fit-Phase nicht
durchführen. Sollte nur die zweite Ausprägung vorhanden sein, werden die
vorklassifizierten Matches ignoriert.

**Blocking Schema Lerner**. Der Blocking Schema Lerner ermittelt ein Blocking
Schema in disjunktiver Normalform nach [@KM:Unsupervised:13], welches in
@sec:blk_scheme vorgestellt wurde. Dafür benötigt der Blocking Schema Lerner die
vorverarbeiteten Tupel $PD$, sowie die Ground Truth Daten $GT$ des Label
Generators. Das Lernen eines Schemas ist ein rechenintensive, weshalb der
Benutzer über Laufzeitparameter die maximale Anzahl an Konjunktionen innerhalb
der Ausdrücke, sowie die maximale Anzahl an Disjunktionen von Ausdrücken angeben
kann.

### Grund Truth Filter

```texalgo
#alg:gt_filter FilterGT($BS$, $D$, $P$, $N$, $AN$, $max_n$)
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Blocking Scheme: $BS$
  \item Dataset: $D$
  \item Set of positive pairs: $P$
  \item Set of negative pairs: $N$
  \item Set of all generated negative pairs: $AN$
  \item Maximum Non-Duplicate Pairs: $max_n$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Set of filtered positive pairs: $fP$
  \item Set of filtered negative pairs: $fN$
  \item Predictions: $y_{pred}$
  \end{itemize}
}
\Statex
\State Initialize empty sets $fP = (), fN = ()$
\For{pair $(p_1.id, p_2.id) \in P$}\label{alg:fgt:p}
    \If{$HasCommonBlock(BS, D, (p_1.id, p_2.id))$}
        \State Append $(p_1.id, p_2.id)$ to $fP$\label{alg:fgt:ap}
    \EndIf
\EndFor
\For{pair $(p1, p2) \in N$}\label{alg:fgt:n}
    \If{$HasCommonBlock(BS, D, (p_1.id, p_2.id))$}
        \State Append $(p_1.id, p_2.id)$ to $fN$\label{alg:fgt:an}
    \EndIf
\EndFor
\While{$|fN| < max_n$ and $|AN| > 0$}\label{alg:fgt:wan}
    \State Draw pair $(p_1.id, p_2.id)$ from $AN$
    \If{$HasCommonBlock(BS, D, (p_1.id, p_2.id))$}\label{alg:fgt:cb}
        \State Append $(p_1.id, p_2.id)$ to $fN$\label{alg:fgt:aan}
    \EndIf
\EndWhile
\State return $fP, fN$

#alg:common_block HasCommonBlock($BS$, $D$, $p$)
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Blocking Scheme: $BS$
  \item Dataset: $D$
  \item Pair: $p = (p_1.id, p_2.id)$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item True if $p$ has common block, false otherwise
  \end{itemize}
}
\Statex
\State Initialize empty sets $p_{1_{bkvs}} = (), p_{2_{bkvs}} = ()$
\For{term $t \in BS$}
    \State $r_1 = D[p_1.id], r_2 = D[p_2.id]$
    \State Add $BlockingKeyValues(t, r_1)$ to $p1_{bkvs}$\label{alg:ct:bkv1}
    \State Add $BlockingKeyValues(t, r_2)$ to $p2_{bkvs}$\label{alg:ct:bkv2}
\EndFor
\If{$p1_{bkvs} \cup p2_{bkvs} \neq \emptyset$}
    \State return True\label{alg:ct:t}
\Else
    \State return False\label{alg:ct:f}
\EndIf
```

Das Filtern der Ground Truth auf Basis des ermittelten Blocking Schema, wird von
der Engine durchgeführt, bevor der Similarity Lerner beginnt (siehe Algorithmus
\ref{alg:gt_filter}). Dabei werden nacheinander alle Matches und Non-Matches der
Ground Truth betrachet (Zeilen \ref{alg:fgt:p}, \ref{alg:fgt:n}). In Algorithmus
\ref{alg:common_block} werden für jedes Paar $(p_1.id, p_2.id)$ die
Blockschüssel, anhand des gegeben Blocking Schema, generiert (Zeilen
\ref{alg:ct:bkv1}, \ref{alg:ct:bkv2}). Gibt es dabei eine Überlappung, dann gibt
es für mindestens ein Attribut einen gemeinsamen Block, in welchem das Paar
zusammen vorkommt. In diesem Fall gibt der Algorithmus Wahr zurück (Zeile
\ref{alg:ct:t}). Gibt es keine Überlappung wird Falsch zurückgegeben (Zeile
\ref{alg:ct:f}). Wurde durch Algorithmus \ref{alg:common_block} festgestellt,
dass ein Match bzw. ein Non-Match einen gemeinsamen Blockschlüssel hat, dann
werden dieses zur gefilterten Ground Truth $fP$ oder $fN$ hinzugefügt (Zeilen
\ref{alg:fgt:ap}, \ref{alg:fgt:an}). Da das Ziel des Blocking Schema ist,
möglichst nur gleiche Entitäten zu gruppieren, werden beim Filtern sehr viele
Non-Machtes, im schlimmsten Fall alle, herausgefiltert. Dadurch ist die
gefilterte Ground Truth zugunsten der Matches unbalanciert. Damit der Similarity
Lerner und der Fusion-Lerner dennoch eine sinnvolle und aussagekräftige
Konfiguration ermitteln können, werden die Non-Matches künstlich angereichert.
Dazu werden die vom Label Generator zuvor verworfenen Non-Matches $AN$ benötigt.
Diese werden nun versucht zur Ground Truth hinzuzufügen, indem wie davor eine
Überlappung der Blockschlüssel gesucht wird (Zeile \ref{alg:fgt:cb}). Gibt es
eine Überlappung wird das Paar zu $fN$ hinzugefügt (Zeile \ref{alg:fgt:aan}).
Dies wird solange wiederholt, bis die Ground Truth $max_n$ Non-Matches
beinhaltet oder die gesamte Menge der Non-Matches des Label Generators erschöpft
sind (Zeile \ref{alg:fgt:wan}).

### Similarity Lerner

**Similarity Lerner**. Der Similarity Lerner bestimmt aus den zur Verfügung
stehenden Ähnlichkeitsfunktionen für jedes Attribut die beste. Dazu werden die
Datensatzpaare der Grund Truth bewertet. Bevor die Ground Truth an den
Similarity Lerner übergeben wird, filtert die Engine die Datensatzpaare heraus,
welche nicht vom Blocking Schema erfasst werden. Das sind diejenigen
Datensatzpaare, welche in folgenden den Verarbeitungsschritten aus
Effizientgründen nicht weiter betrachtet werden.

```texalgo
#alg:simlearn PredictSimilarities(D, BS, S, P, N)
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Dataset $D$
  \item Blocking Scheme $BS$
  \item Fields used in $BS$: $F$
  \item Similarity functions: $S_i,i=1 \cdots |F|$
  \item Set of positive pairs: $P$
  \item Set of negative pairs: $N$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item : $SIMS_i, i=1 \cdots |F|$
  \end{itemize}
}
\Statex
\State Initialize list $SIMS = []$
\For{field $f \in F$}\label{alg:sim:1}
  \State Initialize bestScore = 0
  \For{similarity function $sim \in S$}\label{alg:sim:2}
    \State score = $FieldScore(BS, sim, field, P, N)$\label{alg:sim:3}
    \If{$score > bestScore$}\label{alg:sim:4}
      \State $bestScore = score$
      \State $bestSim = sim$
    \EndIf\label{alg:sim:4}
  \EndFor
  \State $SIMS[field] = bestSim$
\EndFor
\State return $SIMS$

#alg:simscore FieldScore(BS, sim, field, P, N)
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Blocking Scheme $BS$
  \item Similarity function: $sim$
  \item Attribute field: $field$
  \item Set of positive pairs: $P$
  \item Set of negative pairs: $N$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item field score: $score$
  \end{itemize}
}
\Statex
\State Initialize $y_{true} = [], y_scores = []$\label{alg:sis:0}
\For{pair $(p_1.id, p_2.id) \in P \cup N$}\label{alg:sis:1}
  \State $p_1.f = D[p_1.id][field]$
  \State $p_2.f = D[p_2.id][field]$
  \For{term $t \in BS$}\label{alg:sis:2}
    \If{$field \in term$}\label{alg:sis:3}
      \State $p_{1_{bkv}} = BlockingKeyValues(t, p_1.f)$\label{alg:sis:31}
      \State $p_{2_{bkv}} = BlockingKeyValues(t, p_2.f)$\label{alg:sis:32}
      \If{$p_{1_{bkv}} \cup p_{2_{bkv}} \neq \emptyset$}\label{alg:sis:4}
        \If{$p \in P$}\label{alg:sis:5}
          \State Append 1 to $y_{true}$
        \Else
          \State Append 0 to $y_{true}$
        \EndIf
        \State Append $sim(p_1.f, p_2.f)$ to $y_{score}$\label{alg:sis:6}
      \EndIf
    \EndIf
  \EndFor
\EndFor
\State return $average\_precision\_score(y_{true}, y_{score})$
```

Aus der Vielfalt der möglichen Ähnlichkeitsmaße gibt es keines das allen anderen
klar überlegen ist. Es ist daher sehr domainabhängig, welches Maß gute
Ergebnisse liefert. Beim Vergleich von Datensätzen sind diese Domänen meist
durch die unterschiedlichen Attribute getrennt. Daher ist es notwendig
herauszufinden, für welches Attribute welche Ähnlichkeitsmetrik besonders gut
funktioniert. Bevor ein Maß für die Qualität verschiedener Ähnlichkeitsmaße
gefunden werden kann, muss das Problem der Vergleichbarkeit gelöst werden. Für
zwei Strings $a$ und $b$ liefert der Jaccard-Koeffizient beispielsweise Werte
zwischen 0 und 1, die Levenshtein-Distanz hingegen Werte zwischen 0 und
$maxlen(a, b)$. Deshalb ist es notwendig die verschiedenen Ähnlichkeitsmaße zu
normieren. Dafür wird das Intervall von 0 bis 1 gewählt, wobei 1 totale
Übereinstimmung und 0 keine Übereinstimmung bedeutet. Dieses Intervall ist
sinnvoll, da viele Klassifikatoren dadurch ihre Ausführungszeit optimiert
können. Ähnlichkeitsmaße, die einen höheren Wert berechnen, je unähnlicher zwei
Strings sind, werden als Abstandsfunktionen bezeichnet. Eine wichtige
Eigenschaft von Abstandsfunktionen ist, dass diese die Dreiecksungleichung in
metrischen Räumen erfüllt. Der metrische Raum ist definiert als $(X, d)$, wobei
$X$ hier die Menge an Wörtern einer Sprache ist und $d$ eine beliebige
Abstandsfunktion. Die Dreiecksungleichung sagt aus, dass der Abstand von $x$
nach $z$ nicht größer sein darf, als die Summe beliebiger Zwischenschritte über
andere Wörter, $x$ nach $y$ und $y$ nach $z$, daraus folgt $d(x, z) \leq d(x,
y)+ d(y, z)$, für alle $x, y, z \in X$. Bei der Normalisierung muss
berücksichtigt werden, dass die Dreiecksgleichung nicht verletzt wird, da
ansonsten nicht garantiert ist, dass sich alle normalisierten Werte im Intervall
0 bis 1 befinden. Um korrekt zu normalisieren muss für eine Abstandsfunktion,
der größste Wert bestimmt werden. Dafür wird meist der länger der beiden Strings
genutzt. Bei den Editierdistanzen, beispielsweise der Levenshtein-Distanz, ist
dies die Anzahl der Zeichen im längeren String $maxlen(a, b)$. In diesem Fall
wird der String in jeder Postition modifiziert, um $a$ in $b$ zu wandeln.
Beispielsweise ist $Levenshtein(Liste, Baum) = 5 = maxlen(Liste, Baum)$, weil
$(L \rightarrow B, i \rightarrow a, s \rightarrow u, t \rightarrow m, del~e)$.
Daraus folgt die Normalisierungsfunktion für Editierdistanzen: $$sim_{norm}(sim,
a, b) = 1 - \frac{sim(a, b)}{max\_sim\_val(a, b)}$$ Diese
Normalisierungfunktion, anhand des größt möglichen Wertes der
Ähnlichkeitsfunktion zwischen $a$ und $b$, hat den Nachteil, dass die
errechnetet Ähnlichkeiten z.T. zu optimistisch sind. Eine verbreitete
Alternative, Abstandsfunktionen zu normalisieren, ist den größtmöglichen Wert,
anhand des kürzen Strings zu berechnen. Dadurch wird zwar überschwinglicher
Optimismus, beim Normalisieren korrigiert, jedoch verstößt diese Art der
Normalisierung gegen die Dreiecksungleichung.

Durch die Normalisierung ist der Similarity Lerner in der Lage für jedes
Attribut das beste Ähnlichkeitsmaß auszuwählen. Algorithmen \ref{alg:simlearn}
und \ref{alg:simscore} beschreibt das Vorgehen. In @#sec:similarity wurde
gezeigt, dass die verschiedenen Ähnlichkeitsfunktionen oft mindestens einen
Parameter haben. Da teilweise diese Parameter die Dreiecksungleichung aufheben,
beispielsweise die Gewichte bzw. Kosten bei den Editierdistanzen, prüft der
Similarity Lerner nur die Ähnlichkeitsfunktionen mit den Standardparametern. Von
der Engine bekommt er dazu eine Auswahl an Ähnlichkeitsfunktionen $S$, das
Blocking Schema $BS$, sowie die Ground Truth $P$ und $N$. Der Algorithmus prüft
nur die Attribute, welche im Blocking Scheme enthalten sind (Zeile
\ref{alg:sim:1}). Auf das gewählte Attribut werden die Ähnlichkeitsfunktionen in
$S$ (Zeile \ref{alg:sim:3}) durch den Algorithmus \ref{alg:simscore} angewandt
und bewertet (Zeile \ref{alg:sim:3}). Die Ähnlichkeitsfunktion, die für ein
Attribut die beste Bewertung liefert, wird für den Indexer als
Ähnlichkeitsfunktion ausgewählt. Die Liste der ausgewählten Attribute wird
abschließend an die Engine zurückgegeben. Zur Bewertung der Ähnlichkeiten eines
Attributes wird die Average Precision Score genutzt. Diese wird berechnet anhand
der Fläche unter der Precision-Recall Kurve. Die Average Precision Funktion
benötigt zur Berechnung für jedes Paar der Ground Truth die Klasse, Match oder
Non-Match, sowie den errechneten und normalisierten Ähnlichkeitswert. Diese
Werte werden in den beiden Array $y_{true}$, für die Klassen und $y_{score}$,
für die Ähnlichkeitswerte, gesammelt (Zeile \ref{alg:sis:0}). Für jedes Paar
$(p_1.id, p_2.id)$ der Ground Truth, wird zunächst das entsprechende Attribute
aus dem Datensatz $D$ geholt (Zeile \ref{alg:sis:1}). Anhand der Attribute
werden für jeden Ausdruck im Blocking Schema $BS$, die Blockschlüssel
$p_{1_{bkv}}$ und $p_{2_{bkv}}$ erzeugt (Zeilen \ref{alg:sis:31},
\ref{alg:sis:32}). Falls die Schnittmenge der beiden Blockschlüsselmengen
mindestens einen gemeinsamen Blockschlüssel beinhaltet (Zeile \ref{alg:sis:4}),
wird die Ähnlichkeit zwischen den beiden Attributes des Paares berechnet
\ref{alg:sis:6}. Der Ähnlichkeitswert wird in die Liste $y_{scores}$
aufgenommen. Ist die Schnittmenge leer, so haben die Attribute des Paares keinen
gemeinsamen Block und werden folglich vom Indexer nicht miteinander verglichen,
weshalb der Vergleich auch hier übersprungen wird. Zusätzlich wird der Liste
$y_{true}$ eine angefügt, wenn das Paar ein Match ist bzw. eine 0, wenn das Paar
ein Non-Match ist. Abschließend wird die Average Precision Score berechnet und
zurückgegeben.

**Fusion-Lerner**. Der Fusion-Lerner ermittelt für einen gegebenen Klassifikator
die Parameter, die das Modell mit der besten F-measure erzeugen. Bevor der
Fusion-Lerner aufgerufen werden kann, erzeugt die Engine für jedes gefilterte
Ground Truth Paar, anhand der Ähnlichkeitsfunktionen des Similarity Lerners,
einen Ähnlichkeitsvektor pro Paar. Die Ähnlichkeitsvektoren werden dann vom
Fusion-Lerner genutzt, um ein Modell mit gegebenen Parametern zu trainieren. Die
Parameter, die zur Optimierung in Frage kommen, müssen von der
Klassifikatorkomponente bereitgestellt werden, beispielsweise die maximale Tiefe
eines DecisionTree. Um einen optimalen Klassifikator für die Eingabedaten zu
bekommen ist es abgesehen von der Parameterliste möglich eine Liste von
verschiedenen Klassifikatoren anzugeben, beispielsweise einen DecisionTree und
eine SVM.

### Build-Phase

```{.plantuml #fig:build_phase width=60%
    caption="Aktivitätsdiagramm der Build-Phase. Der liest alle vorverarbeiteten
    Datensätze einer initalen Datensatzes ein und fügt diese seinem Index hinzu."}
|Engine|
start
:read transformed dataset;
repeat
    :get record from dataset;
    |Indexer|
    :insert record into index;
repeat while (more records?)
|Engine|
:save index;
stop
```

Die Build-Phase dient der Vorbearbeitung der Daten, bevor das
selbstkonfigurierte ER-System seinen Betrieb aufnehmen kann. Dazu wird der
komplette Datenbestand, in welchem Entitäten gesucht werden sollen, betrachtet.
Nachdem diese durch die Vorverarbeitung gelaufen sind, wird auf den Daten ein
Blocking-Verfahren durchgeführt. Der **Indexer** ist ein Blocking Mechanismus,
der zum einen mit dynamischen Daten umgehen können muss und zum anderen das
Blocking anhand des DNF-Blocking Schemas durchführt. In @fig:build_phase wird
die Build-Phase erläutert. Die Engine liest zunächst alle vorverarbeiteten
Datensätze ein. Anschließend werden die Datensätze einzel dem Indexer übergeben,
welcher diese zu seinem Index hinzufügt. Dabei besteht die Möglichkeit, dass der
Index während des Einfügens anhand der gelernten Ähnlichkeitsfunktionen
bestimmte Ähnlichkeiten vorausberechnet. Das Bauen des Index kann einige
Minuten, eventuell sogar Stunden, dauern. Deshalb wird der Index nach dem Bauen
gespeichert. Im Falle eines Neustarts der Engine müssen dann nur die Datensätze
eingefügt werden, welche während der letzten Query-Phase hinzugekommen sind.

### Query-Phase

```{.plantuml #fig:query_phase width=90%
    caption="Aktivitätsdiagramm der Query-Phase. Zunächst werden der
    transformierte Datensatz vom Präprozessor gelesen. Danach werden Datensätze
    einzeln entnommen und dem Indexer übergeben. Dieser liefert eine
    Kandidatenliste. Jeder Kandidat wird vom Klassifikator in Match bzw.
    Non-Match klassifiziert. Matches werden von der Engine gespeichert und
    Non-Matches verworfen. Am Schluss wird das Ergebnis aller Anfragen dem
    Benutzer übergeben."}
|Engine|
start
:read transformed dataset;
while (more queries?) is (yes)
    :get query record from dataset;
    |Indexer|
    :query candidates from index;
    |Engine|
    while (more candidates?) is (yes)
        |Engine|
        :get candidate record from candidate list;
        |Klassifier|
        :predict candidate class;
        |Engine|
        if (is candidate a match?) then (yes)
            |Engine|
            :save candidate as match;
        else (no)
            |Engine|
            :discard candidate;
        endif
    endwhile (no)
endwhile (no)
|Engine|
:pass results to user;
stop
```

In der Query-Phase (siehe @fig:query_phase) erhält die Engine von einem
Query-Parser eine Menge von Anfragedatensätzen. Nachdem diese vorverarbeitet
wurden, wird jeder Datensatz einzeln dem Indexer übergeben. Dieser erzeugt für
den übergebenen Datensatz eine Kandidatenmenge möglicher Matches. Diese
Kandidaten werden dem Klassifikator übergeben. Das Modell des **Klassifikators**
wurde während der *Fit-Phase* von dem Fusion-Lerner trainiert und kann nun in
der *Query-Phase* genutzt werden, um die Kandidaten in Matches und Non-Matches
zu klassifizieren. Das Ergebnis der Klassifikation speichert die Engine
zwischen, bis alle Datensätze verarbeitet wurden. Abschließend werden die
gesammelten Ergebnisse an den Benutzer übergeben.

### Auswertung

Für die Entwicklung von Komponenten besitzt die Engine die Möglichkeit Metriken
zu messen und diese auszuwerten. Diese liefern ein wichtiges Indiz, wie gut eine
Komponente funktioniert. Des Weiteren ist es dadurch möglich das Zusammenspiel
der Komponenten untereinander zu bewerten, indem beispielsweise eine alternative
Komponente eingesetzt wird, um die Auswirkungen der neuen Komponente in den
Metriken zu überprüft werden. Von den Metriken, welche in @sec:measurements
beschrieben wurden, kann die Engine für das Blocking die Pairs Completeness,
Pairs Quality und Reduction Ratio aufzeichnen, sowie für den Klassifikator
Recall, Precision und F-measure messen. Des Weiteren werden die Daten zum
Zeichnen eines F-measure Graphen und einer Precision-Recall Kurve
bereitgestellt. Darüber hinaus kann die Engine messen, wie lange einzelne
Operationen einer Komponente benötigen. Beispielsweise wird gemessen, wie lange
es dauert einen Datensatz in den Index einzufügen bzw. zu einem Anfragedatensatz
die Kandidatenliste zu erhalten. Dadurch kann die Performanz, beispielsweise in
Anfragen pro Sekunde auf einer Testhardware angegeben werden. Alle Metriken
werden während der Query-Phase erhoben und können nach jeder Anfrage erhalten
werden.
