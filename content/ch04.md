# Selbstkonfigurierendes System

Ein komplettes Entity Resolution System, wie in Kapitel 2 betrachtet, führt eine
Reihe von Schritten aus, um Datensätze, die auf dieselbe Entität beschreiben, zu
finden. Für ein statisches Entity Resolution System lassen sich diese Schritte
grob in vier Phasen gliedern. Zunächst die Vorverarbeitung, um offensichtliche
Fehler zu korrigieren, gefolgt von der Blocking-Phase, welche die Komplexität
der Suche reduziert, der Matching Phase mit Paarvergleich und Klassifizierung in
Matches und Non-Matches und abschließend die Nacharbeitung, um Gruppen von
Duplikaten zu bilden. Für dynamische Entity Resolution trennt man zunächst in
Build-Phase, aufbauen eines Index zur effizienten Suche und Query-Phase,
Durchführung der Entity Resolution, auf einem Anfragestrom. In beiden Phasen
wird der Vorverarbeitungsschritt durchgeführt. Die Blocking-Phase findet
hauptsächlich in der Build-Phase statt und wird in der Query-Phase ergänzt. Der
Matching-Phase findet ausschließlich in der Query-Phase statt, da jeweils nur
ein Datensatz betrachtet wird, ist keine Nacharbeitung notwendig, da das
Ergebnis der aus mehreren Datensätzen automatisch die Gruppe von selben
Entitäten bildet.

Im weiteren Kapitel wird ein Entity Resolution System betrachtet, das sein
Hauptaugenmerk auf dynamische Datenquellen und die Anforderungen an die Laufzeit
der Anfragen legt. Neben der Wahl geeigneter Verfahren und Algorithmen zur
Entity Resolution, ist die größte Schwierigkeit, die vielen freien Parameter auf
die Datenquelle anzupassen. Insbesondere das Blocking Schema spielt hierbei eine
entscheidende Rolle, da es überhaupt beeinflusst, ob Entitäten gefunden werden
können. Werden beispielsweise die Parameter des DySimII Blocking Verfahren aus
@sec:dysimII betrachtet, so wird pro Attribute einen Blockschlüssel und eine
Ähnlichkeitsfunktion benötigt. Bei einem Datensatz mit fünf Attributen, sind
dies bereits 10 Parameter. Beim Matching kommen Parameter für die
Ähnlichkeitsfunktionen, beispielsweise die Kosten der Operationen (einfügen,
ersetzen, löschen) bei der Levenshtein Distanz, welche auf ein Attribut
optimiert werden. Bei einem Attribut pro Ähnlichkeitsfunktion und beispielsweise
abweichenden Werten für die Kosten der Einfügeoperation der Levenshtein Distanz,
kommen weitere fünf Parameter hinzu. Ebenfalls in der Matching-Phase wird ein
Klassifikator eingesetzt. Beispielsweise kann ein simpler
Schwellenwertklassifikator mit einer Schwelle genutzt werden. In diese
Konstellation (ohne Vorverarbeitung) mit Blocking Verfahren, verschiedenen
Ähnlichkeitsfunktionen und einem Klassifikator, kommt das ER-System bereits 16
Parameter. Diese Parameter manuell zu bestimmen, ist selbst mit einer cleveren
Strategie, die Parameter auszuprobieren, sehr zeit- und kostenintensiv.
Besonders bei großen Datenmengen kann dieses Trial and Error Verfahren sehr
lange dauern, da das Ausprobieren mehrere Stunden, wenn nicht Tage dauern kann.
Noch schwieriger wird es, wenn keine Ground Truth Daten vorhanden sind. Dadruch
entfällt größtenteils die Möglichkeit die eingestellten Parameter qualitativ zu
überprüfen.

In diesem Kapitel wird deshalb zunächst ein Design für ein sich
selbstkonfigurierendes Entity Resolution System für dynamische Datenquellen zur
Behandlung von Anfrageströme vorgestellt. Das Ziel ist es, mit und ohne Ground
Truth, die Einstellungen möglichst vieler (vorzugsweiser aller) Parameter
bestmöglichst auf die Eingabedatenmenge zu optimieren, ohne das der Benutzer
eine langwierige Trial and Error Phase durchlaufen muss. Damit sollen sich die
erlaubten Parameter auf Laufzeitoptimierungen beschränken, beispielsweise solche
die die Zeit der Selbstkonfiguration, auf Kosten der Qualität, um mehrere
Stunden bzw. Tage reduzieren können. Somit kann das ER System bei Bedarf
schneller in eine produktive Phase gebracht werden, wenn entsprechende
Anforderungen bestehen. Nach einem Überblick des Systems (genannt Engine) werden
die Phasen und die Rolle der Komponenten in den Phasen erklärt. Anschließend
werden in den weiteren Abschnitten die konkreten Komponeten und ihre Algorithmen
beschrieben.

## Engine

```{.plantuml #fig:engine
    caption="Engine des selbstkonfigurierenden Systems. Bestehend aus 8
    Komponenten. In Gelb sind der Ground Truth Generator, der Blocking Scheme
    Lerner, der Similarity Lerner und der Fusion-Lerner, welche für
    das Erlernen der Konfiguration (Fit-Phase) nötig sind. In Grün ist der Indexer, welcher
    aus anhand der gelernten Konfiguration gebaut wird und der Klassifikator.
    In Blau ist der Parser, um Daten einer Datenquelle zu laden und der
    Präprozessor, um die geladenen Daten für Entity Resolution zu manipulieren"}
@startuml
ditaa(--no-shadows, scale=5)
+-----------------------------------Engine--------------------------------------+
|+--------------+-------------------------+--------------------+---------------+|
||cBLU          |cYEL                     |cYEL                |cGRE           ||
|| Parser       | Label Generator         | Similarity Learner | Indexer       ||
||              |                         |                    |               ||
|+--------------+-------------------------+--------------------+---------------+|
||cBLU          |cYEL                     |cYEL                |cGRE           ||
|| Präprozessor | Blocking Scheme Learner | Fusion-Lerner      | Klassifikator ||
||              |                         |                    |               ||
|+--------------+-------------------------+--------------------+---------------+|
\-------------------------------------------------------------------------------/
 +----+               +----+           +----+
 |cBLU| Preprocessing |cYEL| Fit-Phase |cGRE| Build-/Query-Phase
 +----+               +----+           +----+
@enduml
```

Die Engine ist das Herzstück des selbstkonfigurierenden Systems und besteht aus
einzelnen Komponenten, welche wie in einem Steckkastensystem ausgetauscht
werden. Die Komponenten der Engine sind in @fig:engine dargestellt.

* **Parser**. Der Parser liest Datensätze aus einer Datenquelle in eine Menge
  von Tupel.
* **Präprozessor**. Der Präprozessor vorverarbeitet jedes Attribut in einer
  Pipeline, anhand einer Reihe von benutzerdefinierten Operationen, welche
  sequentiell angewendet werden, beispielsweise Rechtschreibprüfung.
* **Label Generator**. Der Label Generator erzeugt bestimmt eine geeignete
  Ground Truth zum Einstellen der Parameter in den folgenden Komponenten.
* **Blocking Schema Lerner**. Der Blocking Schema Lerner erzeugt eine Blocking
  Schema in distributiver Normalform nach [@KM:Unsupervised:13].
* **Similarity Lerner**. Der Similarity Lerner bestimmt für jedes Attribut eine
  geeignete Ähnlichkeitsfunktion.
* **Fusion-Lerner**. Der Fusion-Lerner lernt die besten
  Parameter für den verwendeten Klassifikator und trainiert das
  Klassifikationsmodell.
* **Indexer**. Der Indexer wendet ein Blocking Verfahren auf die Eingabedaten an
  und ermöglicht es diese anzufragen.
* **Klassifikator**. Der Klassifikator sortiert die Kandidatenmenge einer
  Indexanfrage in Matches und Non-Matches.

```{.a2s #fig:engine_state
    caption="Zustandsdiagramm der Engine. Lernen der Konfiguration versetzt die
    Engine von unangepasst nach angepasst. Wurde der Index gebaut, ist die
    Engine im Zustand gebaut und kann Anfrage entgegennehmen."}
        .------------.              .--------.  building    .-------.
        | not fitted |   fitting    | fitted +------------->| built |
 ●----->+------------+------------->+--------+  re-fitting  +-------+
        |            | load config  |        |<-------------+       |
        '------------'              '------+-'              '-----+-'
                                      ^    |                  ^   |
                                      '----'                  '---'
                                   save config              querying/
                                                          evalute (dev)
```

Die Hauptaufgabe der Engine ist es die Interaktionen zwischen den Komponenten zu
steuern. Dazu werden im simpelsten Fall die Daten von einer Komponente zur
nächsten weitergereicht. Zum Teil muss die Engine allerdings zunächst die
Rückgabewerte für die nächste Komponente aufbereitet. Die Engine dient weiterhin
als die Schnittstelle für den Benutzer. Dabei kann der Benutzer die Engine in
drei Zustände versetzten (siehe @fig:engine_state). Eine neu erzeugte Engine ist
*unangepasst* und kann durch das Lernen der Konfiguration (engl. fitting) in den
Zustand *angepasst* wechseln. Alternativ kann der Zustandsübergang durch das
laden einer bereits gelernte Konfiguration durchgeführt werde durchgeführt
werden. Anhand dieser Konfiguration kann der Index auf den initialen Daten
(Datenbestand zum Zeitpunkt des Bauens) gebaut (engl. building) werden. Danach
befindet sich die Engine im Zustand *gebaut*. In diesem Zustand kann die Engine
mit Datensätzen angefragt (engl. querying) werden. Da die Möglichkeit besteht
jede Anfrage in den Datenbestand (den Index) aufzunehmen, liegen nach einer
gewissen Zeit genügend neue Daten vor, sodass sich auf Basis derer auch die
optimale Konfiguartion verändert haben kann. Während des erneuten lernens (engl.
refitting) können weiterhin Anfragen beantwortet werden, allderings ist dies
aufgrund des enormen Ressourcenverbrauch nicht ratsam. Vielmehr empfiehlt sich
die Engine seperat neu zu konfigurieren und die erlernte Konfiguration über
einen Neustart der Engine zu laden. Wenn Komponenten für die Engine entwickelt
werden, ist es notwendig deren Qualität und Effektivität auszuwerten. Weshalb
die Engine im Entwicklungsbetrieb entsprechende Metriken erheben und auswerten
kann. Die Auswertung erfolgt nachdem mindestens eine Anfrage durchgeführt wurde.
Die drei Phasen zum Wechseln der Zustände werden im Folgenden als *Fit-Phase*,
*Build-Phase* und *Query-Phase* bezeichnet. Alle drei Phasen haben den Schritt
der Vorverarbeitung gemeinsam.

### Vorverarbeitung

Die Vorverarbeitung der Daten ist in allen drei Phasen notwendig und macht die
Datensätze robuster gegenüber Missklassifikationen, indem offensichtliche Fehler
korrigiert und eventuelle, für die Identifikation von Entitäten irrelevante,
Varianzen bereinigt weren. In @fig:preprocessing sind die beteiligten
Komponenten Parser und Präprozesser (@fig:engine in blau) mit ihren Aktivitäten
visualisiert. Jede Phase beginnt mit der Auswahl des korrekten Parsers durch die
Engine.

```{.plantuml #fig:preprocessing
    caption="Aktivitätsdiagramm der Vorverarbeitung. Der Parser liest einen
    Datensatz, welcher vom Präprozessor transformieren wird. Der transformierte
    Datensatz wird von der Engine abgespeichert."}
|Engine|
start
:choose parser for Fit-,
Build- or Query-Phase;
|Parser|
:read dataset;
if (is Fit-Phase?) then (yes)
    :assign attribute datatypes;
endif
|Preprozessor|
:transform dataset;
|Engine|
:save transformed dataset;
:proceed with (Fit/Build/Query)-Phase;
```

**Parser**. Der Parser ist eine einfache Komponente, welche Datensätze aus einer
Datenquelle liest und eine Menge von Tupeln zurückgibt. Dabei entspricht immer
ein Tupel einem Datensatz. Für einen Datensatz mit $n$ Attribute hat ein Tupel
die Form $t = (a_1, a_2, \dots, a_n)$. Je nach Phase kann die Datenquelle ein
beliebiges Format haben, weshalb für jede Phase ein eigener Parser bestimmt
werden kann. Für *Fit-* und *Build-Phase*, wo große Datenmengen bearbeitet
werden, liest der Parser beispielsweise aus einer CSV-Datei oder selektiert die
Datensätze aus einer Datenbank. Währenddessen in der *Query-Phase* nur einzelne
oder kleine Datenmengen gelesen werden, weshalb der Parser hier aus einer
Message Queue (MQ) Datensätze erhalten kann. Während der *Fit-Phase* hat der
Parser zudem dafür Sorge zu tragen, dass der Engine die Attribute des
Datensatzes, sowie deren Datentypen bekannt gemacht werden. Anhand dieser des
Datentyps können die Komponenten der Fit-Phase optimalere Konfigurationen
bestimmen. Wenn der Parser diese Information nicht bereitstellt, werden alle
Attribute als Zeichenketten behandelt.

**Präprozessor**. Der Präprozessor bzw. die Präprozessor-Pipeline besteht aus
einer Reihe von Funktionen, die nacheinander auf die Attribute aller Datensätze
angewandt werden, welche vom Parser zurückgegeben wurden. Je nach Datentyp des
Attributs wird dabei eine andere Pipeline verwendet. Der Präprozessor wird in
allen drei Phasen verwendet, um einen Datensatz für die Entity Resolution
vorzubereiten und robuster zu machen. Werden vom Benutzer keine Operationen
vorgegeben beschränkt sich die Pipeline auf generische Modifkationen. Die zum
Zeitpunkt dieser Thesis entwickelte Engine ist, zum Zwecke der Vorverarbeitung,
automatisiert lediglich in der Lage Strings in Kleinschreibweise zu konvertiert.
Andere Operationen wie das Entfernen von Stopwörtern (z.B. *und*, *oder*)
benötigen zum einen die Sprache der Attribute, welche zu erkennen durchaus eine
lösbare Aufgabe ist, zum anderen aber auch einen Datenbestand gegen den geprüft
wird. Ein komplexere domänenspezifische Anwendung hierfür ist, beispielsweise
die Überprüfung der postalischen Addresse, welche neben länderspezifischen Daten
benötigt und diesewp auch ständig auf dem aktuellen Stand halten muss. Neben
weiteren Funktionen muss der Benutzer auch die Reihenfolge der Funktionen
vorgeben. Beispielweise zunächst die Rechtspreibprüfung und anschließend die
Konvertierung in Kleinschreibweise, da durch die Rechtschreibprüfung diese
Konvertierung in Teilen wieder aufgehoben werden kann.

Die Menge der transformierten Tupel des Präprozessors wird abschließend von der
Engine im Hierarchical Data Format (HDF) gespeichert. Das HDF-Format ist eine
wissenschaftliches Datenformat, welches entwickelt worden ist, um große
Datenmengen effizient und hierachisch (vergleichbar mit UNIX-Filesystem) zu
persistieren. Um Kapazität zu sparen, werden die Daten mit der
Blosc-Komprimierung verkleinert. Dem Blosc-Komprimator liegt ein hochperformates
Design zugrunde, dass insbesondere den Datenaustausch für den CPU-Cache
optimiert. Obwohl es für Binärdaten entwickelt wurde, werden auch für Strings
gute Ergebnise erzielt.[^2]

[^2]: http://www.blosc.org/benchmarks-blosclz.html

### Fit-Phase

```{.plantuml #fig:fit_phase
    caption="Aktivitätsdiagramm der Fit-Phase. Die Engine kontrolliert den
    Datenfluss zwischen den Komponenten, speichert Konfigurationen und breitet
    Daten für Komponenten auf. Der Label Generator erzeugt die Ground Truth,
    durch welche ein DNF-Blocking Schema vom BS-Lerner erzeugt wird. Auf einer
    durch das Blocking Schema gefilterten Liste werden anschließend die
    Ähnlichkeitsfunktionen bestimmt. Anhand dieser Funktionen können
    Ähnlichkeitsvektoren auf der Ground Truth berechnet werden und vom
    Fusion-Lerner dadurch die Hyperparameter für den Klassifikator bestimmt,
    sowie abschließend das Klassifikationsmodell trainiert werden."}
|Engine|
start
:read transformed dataset;
|Label Generator|
:generate ground truth;
|Engine|
:save ground truth;
|BS-Learner|
:predict DNF Blocking Scheme;
|Engine|
:save DNF Blocking Scheme;
:filter ground truth;
|Sim-Learner|
:predict similarity functions;
|Engine|
:save similarity functions;
:calculate ground truth
similarity vectors;
|HP-Optimizer|
:predict hyperparameters;
:train model;
|Engine|
:save model;
stop
```

In der Fit-Phase nimmt die Engine die Konfiguration des Systems vor. Eine
Konfiguration ist ein Tupel $(GT, BS, S, M)$ bestehend aus der Grund Truth, dem
Blocking Schema, den Ähnlichkeitsfunktionen und dem Klassikationsmodell. Die
Ground Truth $GT = (P, N)$ ist ebenfalls ein Tupel, dass sich in die Menge der
positive Datensatzpaare, die tatsächlichen Matches (true positives), sowie die
Menge der negativen Datensatzpaare, die tatsächlichen Non-Matches (true
negatives) teilt. Ein Datensatzensatzpaar ist definiert als $p = (t_j, t_k), j
\neq k$, wobei $j$ und $k$ beliebige Tupel sein können. Weiterhin gilt $\forall
p \in P, p \notin N$ und umgekehrt $\forall p \in N, p \notin P$. Das Blocking
Schema entspricht der Definition aus @sec:scheme, $BS = (term_1 \land \dots
\land term_j) \lor \dots \lor (term_k \land \dots \land term_n)$. Die
Ähnlichkeitsfunktionen werden als Menge von Tupeln angegeben $S = {(f_1, sim),
\dots, (f_m, sim)}$, wobei $f$ das Datenfeld eines Datensatztupels und $m$ die
Anzahl der Attribute in einem Datensatztupel ist. Die Ähnlichkeitsfuntion $sim$
ist eine von $r$ möglichen Ähnlichkeitsfunktionen ${sim_1, \dots, sim_r}$, die
durch die Engine bereitgestellt werden. Das Klassifikationsmodell $M$ ist
spezifisch für den eingesetzten Klassifikator und entspricht bespielsweise einem
trainierten Entscheidungsbaum.

In @fig:engine sind die Komponenten für die Fit-Phase in gelb hervorgehoben. Bei
großen Datensätzen kann diese Phase sehr lange dauern, weshalb die Engine die
einzelnen Konfigurationen der Komponenten direkt sichert. Dadurch kann die
Fit-Phase im Falle eines Abbruchs, z.B. durch einen Systemneustart, fortgesetzt
werden und nur die unterbrochene Komponente muss wiederholt werden. Wurde die
Fit-Phase abgeschlossen, ist es möglich die ermittelte Konfiguration einzulesen.
Wodurch die Fit-Phase übersprungen wird. @fig:fit_phase zeigt das
Aktivitätsdiagramm der Fit-Phase, ohne existierende Konfiguratation.

**Label Generator**. Der Label Generator erzeugt, die für später in der
Fit-Phase folgenden Komponenten, nötige Ground Truth in Form von klassifizierten
Matches und Non-Matches. Dazu bekommt er von der Engine die, in der
Vorverarbeitung transformierten, Trainingsdaten und bildet Datensatzpaare
(@fig:fit_phase). Dabei gibt es zwei Ausprägungen. In der ersten Ausprägung
erhält der Label Generator eine Ground Truth für den gegebenen Datensatz.
Aufgrund der Verteilung von Matches und Non-Matches, die fast immer ein
deutliches Ungleichgewicht zugunsten der Non-Matches aufweist, werden für alle
öffentlich verfügbaren Datensätze mit Ground Truth, lediglich die Matches
angegeben. Dementsprechend sind alle Datensatzpaare, welche nicht in den Matches
der Ground Truht enthalten sind, als Non-Matches zu interpretieren. Über der
riesigen Menge an Non-Matches führt der Label Generator ein Sampling aus um eine
repräsentative Stichprobe zu erhalten. In der zweiten Ausprägung stehen dem
Label Generator keine vorklassifizierten Matches zur Verfügung. Weshalb die
Ground Truth vollständig automatisiert bestimmt werden muss (siehe
@sec:lblgen_nogt). Ein Label Generator kann beide Ausprägungen implementieren.
Falls nur die erste Ausprägung implementiert ist, kann die Engine, ohne
existierende Ground Truth, die Fit-Phase nicht durchführen. Sollte nur die
zweite Ausprägung vorhanden sein, werden die vorklassifizierten Matches
ignoriert.

**Blocking Schema Lerner**. Der Blocking Schema Lerner ermittelt ein Blocking
Schema in disjunktiver Normalform nach [@KM:Unsupervised:13], welches in
@sec:blk_scheme vorgestellt wurde. Dafür benötigt der Blocking Schema Lerner die
vorverarbeiteten Trainingsdaten, sowie die Ground Truth Daten des Label
Generators. Das Lernen eines Schemas ist ein rechenintensive, weshalb der
Benutzer über Laufzeitparameter die maximale Anzahl an Konjunktionen innerhalb
der Ausdrücke, sowie die maximale Anzahl an Disjunktionen von Ausdrücken angeben
kann.

**Similarity Lerner**. Der Similarity Lerner bestimmt aus den zur Verfügung
stehenden Ähnlichkeitsfunktionen für jedes Attribut die beste. Dazu werden die
Datensatzpaare der Grund Truth bewertet. Bevor die Ground Truth an den
Similarity Lerner übergeben wird, filtert die Engine die Datensatzpaare heraus,
welche nicht vom Blocking Schema erfasst werden. Das sind diejenigen
Datensatzpaare, welche in folgenden den Verarbeitungsschritten aus
Effizientgründen nicht weiter betrachtet werden.

**Fusion-Lerner**. Der Fusion-Lerner ermittelt für einen gegebenen Klassifikator
die Parameter, die das Modell mit der besten F-measure erzeugen. Bevor der
Fusion-Lerner aufgerufen werden kann, erzeugt die Engine für jedes gefilterte
Ground Truth Paar, anhand der Ähnlichkeitsfunktionen des Similarity Lerners,
einen Ähnlichkeitsvektor pro Paar. Die Ähnlichkeitsvektoren werden dann vom
Fusion-Lerner genutzt, um ein Modell mit gegebenen Parametern zu trainieren. Die
Parameter, die zur Optimierung in Frage kommen, müssen von der
Klassifikatorkomponente bereitgestellt werden, beispielsweise die maximale Tiefe
eines DecisionTree. Um einen optimalen Klassifikator für die Eingabedaten zu
bekommen ist es abgesehen von der Parameterliste möglich eine Liste von
verschiedenen Klassifikatoren anzugeben, beispielsweise einen DecisionTree und
eine SVM.

### Build-Phase

```{.plantuml #fig:build_phase width=60%
    caption="Aktivitätsdiagramm der Build-Phase. Der liest alle vorverarbeiteten
    Datensätze einer initalen Datensatzes ein und fügt diese seinem Index hinzu."}
|Engine|
start
:read transformed dataset;
repeat
    :get record from dataset;
    |Indexer|
    :insert record into index;
repeat while (more records?)
|Engine|
:save index;
stop
```

Die Build-Phase dient der Vorbearbeitung der Daten, bevor das
selbstkonfigurierte ER-System seinen Betrieb aufnehmen kann. Dazu wird der
komplette Datenbestand, in welchem Entitäten gesucht werden sollen, betrachtet.
Nachdem diese durch die Vorverarbeitung gelaufen sind, wird auf den Daten ein
Blocking-Verfahren durchgeführt. Der **Indexer** ist ein Blocking Mechanismus,
der zum einen mit dynamischen Daten umgehen können muss und zum anderen das
Blocking anhand des DNF-Blocking Schemas durchführt. In @fig:build_phase wird
die Build-Phase erläutert. Die Engine liest zunächst alle vorverarbeiteten
Datensätze ein. Anschließend werden die Datensätze einzel dem Indexer übergeben,
welcher diese zu seinem Index hinzufügt. Dabei besteht die Möglichkeit, dass der
Index während des Einfügens anhand der gelernten Ähnlichkeitsfunktionen
bestimmte Ähnlichkeiten vorausberechnet. Das Bauen des Index kann einige
Minuten, eventuell sogar Stunden, dauern. Deshalb wird der Index nach dem Bauen
gespeichert. Im Falle eines Neustarts der Engine müssen dann nur die Datensätze
eingefügt werden, welche während der letzten Query-Phase hinzugekommen sind.

### Query-Phase

```{.plantuml #fig:query_phase width=90%
    caption="Aktivitätsdiagramm der Query-Phase. Zunächst werden der
    transformierte Datensatz vom Präprozessor gelesen. Danach werden Datensätze
    einzeln entnommen und dem Indexer übergeben. Dieser liefert eine
    Kandidatenliste. Jeder Kandidat wird vom Klassifikator in Match bzw.
    Non-Match klassifiziert. Matches werden von der Engine gespeichert und
    Non-Matches verworfen. Am Schluss wird das Ergebnis aller Anfragen dem
    Benutzer übergeben."}
|Engine|
start
:read transformed dataset;
while (more queries?) is (yes)
    :get query record from dataset;
    |Indexer|
    :query candidates from index;
    |Engine|
    while (more candidates?) is (yes)
        |Engine|
        :get candidate record from candidate list;
        |Klassifier|
        :predict candidate class;
        |Engine|
        if (is candidate a match?) then (yes)
            |Engine|
            :save candidate as match;
        else (no)
            |Engine|
            :discard candidate;
        endif
    endwhile (no)
endwhile (no)
|Engine|
:pass results to user;
stop
```

In der Query-Phase (siehe @fig:query_phase) erhält die Engine von einem
Query-Parser eine Menge von Anfragedatensätzen. Nachdem diese vorverarbeitet
wurden, wird jeder Datensatz einzeln dem Indexer übergeben. Dieser erzeugt für
den übergebenen Datensatz eine Kandidatenmenge möglicher Matches. Diese
Kandidaten werden dem Klassifikator übergeben. Das Modell des **Klassifikators**
wurde während der *Fit-Phase* von dem Fusion-Lerner trainiert und kann nun in
der *Query-Phase* genutzt werden, um die Kandidaten in Matches und Non-Matches
zu klassifizieren. Das Ergebnis der Klassifikation speichert die Engine
zwischen, bis alle Datensätze verarbeitet wurden. Abschließend werden die
gesammelten Ergebnisse an den Benutzer übergeben.

### Auswertung

Für die Entwicklung von Komponenten besitzt die Engine die Möglichkeit Metriken
zu messen und diese auszuwerten. Diese liefern ein wichtiges Indiz, wie gut eine
Komponente funktioniert. Des Weiteren ist es dadurch möglich das Zusammenspiel
der Komponenten untereinander zu bewerten, indem beispielsweise eine alternative
Komponente eingesetzt wird, um die Auswirkungen der neuen Komponente in den
Metriken zu überprüft werden. Von den Metriken, welche in @sec:measurements
beschrieben wurden, kann die Engine für das Blocking die Pairs Completeness,
Pairs Quality und Reduction Ratio aufzeichnen, sowie für den Klassifikator
Recall, Precision und F-measure messen. Des Weiteren werden die Daten zum
Zeichnen eines F-measure Graphen und einer Precision-Recall Kurve
bereitgestellt. Darüber hinaus kann die Engine messen, wie lange einzelne
Operationen einer Komponente benötigen. Beispielsweise wird gemessen, wie lange
es dauert einen Datensatz in den Index einzufügen bzw. zu einem Anfragedatensatz
die Kandidatenliste zu erhalten. Dadurch kann die Performanz, beispielsweise in
Anfragen pro Sekunde auf einer Testhardware angegeben werden. Alle Metriken
werden während der Query-Phase erhoben und können nach jeder Anfrage erhalten
werden.

## Komponenten

In diesem Abschnitt werden die konkreten Komponenten betrachtet und ihre
Funktionalität Algorithmus beschrieben. Die Details der Implementierung der
Komponenten werden in @sec:impl vorgenommen.

### Label Generator {#sec:weaklbl}

Für den Label Generator wurden beide Ausprägungen (mit und ohne Ground Truth)
umgesetzt. Zunächst wird die Variante ohne Ground Truth beschrieben und
anschließend die Variante mit Ground Truth, welche eine Modifikation der ersten
Ausprägung ist.

#### Ohne Ground Truth {#sec:lblgen_nogt}

Der Label Generator ohne Ground Truth implementiert den WeakLabel Algorithmus
vom Kejriwal & Miranker [@KM:Unsupervised:13] zur Erzeugung von schwachen
Labels. Der Algorithmus definiert zwei Schwellen, die obere Schwelle $ut$ und
die untere Schwelle $lt$. Damit vor allem die erzeugten Ground Truth
Non-Matches, der klassifizierten Paare, nicht beliebig groß werden, kann der
Anwender festlegen, wie viele Matches $max_p$ bzw. Non-Matches Paare $max_n$
maximal erzeugt werden sollen. Die vier Abschnitte sind in Algorithmus
\ref{alg:weaklabels}) dargestellt. Zunächst wird die TF/IDF Statistik über $D$
erzeugt (Zeile \ref{alg:wl:tfidf}), welche für einen späteren Paarvergleich
benötigt wird. Die in diesem und folgenden Algorithmen genannten $fields$
beschreiben die Positionen eines Attributes im Tupel eines Datensatzes,
beispielsweise für ein Tupel $t = ("Kevin", "Sapper", "Hochschule RheinMain")$
hat der Nachname die Position $f = 2$.

```texalgo
#alg:weaklabels WeakTrainingSet w\textbackslash o Ground Truth
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Dataset: $D$
  \item Upper Threshold: $ut$
  \item Lower Threshold: $lt$
  \item Blocking Window Size: $c$
  \item Maximum Duplicate Pairs: $max_p$
  \item Maximum Non-Duplicate Pairs: $max_n$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item A set of positive samples: $P$
  \item A set of negative samples: $N$
  \end{itemize}
}
\Statex
\State Initialize set $P = ()$, set $N = ()$
\State Initialize set of tuple pairs $C = ()$
\State Generate TFIDF statistics of $D$\label{alg:wl:tfidf}
\For{fields $f \in D$} \label{alg:wl:tks}
    \For{records $r \in D$}
        \State Tokenize $r_f$ into $BKV_f$
        \State Block $r$ on generate tokens for field $f$
    \EndFor
\EndFor \label{alg:wl:tke}
\For{block $B$ generate in previous step}\label{alg:wk:cs}
    \State  Slide a window of size c over tupels in $B$
    \StatexIndent[1] Generate all possible pairs within window and
    \StatexIndent[1] add to $C$
\EndFor \label{alg:wk:ce}
\For{pairs $(t_1, t_2) \in C$}
    \State Compute TFIDF similarity $sim$ of $(t_1, t_2)$
    \If{$sim \geq ut$}\label{alg:wk:ps}
        \If{$|P| < d$}
            \State add $(t_1, t_2)$ to $P$
        \ElsIf{$sim >$ lowest $sim$ in $P$}\label{alg:wk:pcks}
            \State Replace pair with lowest $sim$ in $P$ with $(t_1, t_2)$
        \EndIf\label{alg:wk:pcke}
    \EndIf\label{alg:wk:pe}
    \If{$sim < lt$}\label{alg:wk:ns}
        \If{$|N| < nd$}
            \State add $(t_1, t_2)$ to $N$
        \ElsIf{$sim >$ lowest $sim$ in $N$}\label{alg:wk:ncks}
            \State Replace pair with lowest $sim$ in $N$ with $(t_1, t_2)$
        \EndIf\label{alg:wk:ncke}
    \EndIf\label{alg:wk:ne}
\EndFor\label{alg:wk:sime}
\State Return $P$ and $N$

#alg:labels WeakTrainingSet with Ground Truth
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Dataset: $D$
  \item Ground Truth $GT$
  \item Blocking Window Size: $c$
  \end{itemize}
}
\Statex \Statex \Statex
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item A set of positive samples: $P$
  \item A set of negative samples: $N$
  \end{itemize}
}
\Statex\color{gray}
\State Initialize set $P = ()$, set $N = ()$\label{alg:wk:inits}
\State Initialize set of tuple pairs $C = ()$
\State Generate TFIDF statistics of $D$
\For{fields $f \in D$}
    \For{records $r \in D$}
        \State Tokenize $r_f$ into $BKV_f$
        \State Block $r$ on generate tokens for field $f$
    \EndFor
\EndFor
\For{block $B$ generate in previous step}
    \State  Slide a window of size c over tupels in $B$
    \StatexIndent[1] Generate all possible pairs within window and
    \StatexIndent[1] add to $C$
\EndFor\color{black}\label{alg:wk:inite}
\For{pairs $(t_1, t_2) \in GT$}\label{alg:wk:gts}
    \State Add $(t_1, t_2)$ to $P$
    \If{$p \in C$}
        \State Remove $p$ from $C$
    \EndIf
\EndFor\label{alg:wk:gte}
\State Initialize dictionary $M = \{\}$
\For{pairs $(t_1, t_2) \in C$}\label{alg:wk:tfidfs}
    \State Compute TFIDF similarity $sim$ of $(t_1, t_2)$
    \State $M[(t_1, t_2)] = sim$
\EndFor\label{alg:wk:tfidfe}
\State Calculate probability distribution over $M$\label{alg:wk:hist}
\State $max_n = |GT| * 5$
\For{$i = 1$ \textbf{to} $max_n$}\label{alg:wk:ss}
    \State Choose a pair $p$ from $M$ based on probability distribution\label{alg:wk:smpl}
    \State Add $p$ to $N$
\EndFor\color{gray}\label{alg:wk:se}
\State Return $P$ and $N$
```

Anschließend wird ein Blocking der Daten per Standard Blocking und Sorted
Neighborhood durchgeführt. Jeder Datensatz wird (pro Attribute) in Token zerlegt
(Zeilen \ref{alg:wl:tks}-\ref{alg:wl:tke}). Anhand der Token wird das Standard
Blocking durchgeführt, wobei jeder Datensatz in mehreren Blöcken vertreten sein
kann. Die Menge von Blöcken sind jeweils nach Attributen gruppiert, sodass Token
unterschiedlicher Attribute nicht als Blockschüssel desselben Blockes genutzt
werden, da die Datensätze in den entsprechenden Blocken, trotz übereinstimmenden
Token, vermutlich wenig Ähnlichkeit haben. Danach wird die Kandidatenmenge $C$
möglicher Matches bzw. Non-Matches anhand der gruppierten Datensätze generiert
(Zeile \ref{alg:wk:cs}-\ref{alg:wk:ce}). Um innerhalb der Blöcke den
Paarvergleichsaufwand zu reduzieren, wird die Sorted Neighborhood verwendet und
ein Fenster der Größe $c$ über den Block geschoben. Nachdem das Fenster über
jeden Block geschoben wurde, steht die Menge möglicher Kandidatenpaare fest.
Diese Paare werden nun mit der TF/IDF-Ähnlichkeit $sim$ (aus Cohen
[@Coh:WHIRL:00]) verglichen (Zeilen \ref{alg:wk:ps}-\ref{alg:wk:pe}). Aufgrund
der, über die kompletten Daten erfassen, TF/IDF Statistik beträgt die
Komplexität des Vergleiches $O(1)$, da lediglich die entsprechenden TF und IDF
Werte, der Datensätze des Paares, nachgeschlagen werden müssen. Ist die
Ähnlichkeit $sim \geq ut$, wird das Paar als Match klassifiziert und zu $P$
hinzugefügt (Zeilen \ref{alg:wk:ps}-\ref{alg:wk:pe}). Analog, ist $sim < lt$
wird das Paar als Non-Match klassifiziert und zu $N$ hinzugefügt (Zeilen
\ref{alg:wk:ps}-\ref{alg:wk:pe}). Von allen Matches werden jeweils die $max_p$
mit der höchsten Ähnlichkeit $sim$ ausgewählt (Zeilen
\ref{alg:wk:pcks}-\ref{alg:wk:pcke}). Analog werden ebenfalls die $max_n$
Non-Matches mit der höchsten Ähnlichkeit $sim$ gewählt (Zeilen
\ref{alg:wk:ncks}-\ref{alg:wk:ncke}). Bei den Non-Matches soll dadurch
verhindern, dass lediglich Paare mit $sim \approx 0.0$ ausgewählt werden, da
diese für gewöhnlich zu niedrigen Klassifikationsraten führen. Die
Gesamtkomplexität des Algorithmus ist $O(n + nm + nm)$, welcher sich in die
Erzeugung der TF/IDF Statistik ($O(n)$), die Erzeugung der Blöcke über $m$
Attribute ($O(nm)$) und die Erzeugung der Kandidatenpaare $O(nm)$ gliedert.
Kritisch bei diesem Algorithmus zu betrachten ist, dass ein Großteil der
Datensatzpaare, aufgrund der Lücke zwischen den Schwellen, nicht für die Ground
Truth ausgewählt werden kann. @fig:weaklbl_problem illustriert diese Lücke
zwischen einer unteren Schwelle bei 0.1 und oberen Schwelle bei 0.7. Für alle
Paare $p$ gilt, wenn $lt \leq sim(p) < ut$, dann folgt $p \notin P \cup N$.
Dadurch ist die generierte Repräsentation eines Datensatzes, durch die Ground
Truth, nicht sonderlich repräsentativ, da viele aussagekräftige Paare
ausgeschlossen sind. Inwiefern diese Einschränkung eine Konfiguration
beeinflusst wird in Kapitel 6 überprüft.

```{.a2s #fig:weaklbl_problem
    caption="Darstellung der Lücke zwischen oberer und unterer Schwelle, des
    Algorithmuses des Label Generator ohne Ground Truth (GT), innerhalb welcher
    Paare nicht für die Ground Truth ausgewählt werden können."}
     lt=0.1                             ut=0.7
       |                                  |
       |    Pairs not available for GT    |
       |<-------------------------------->|
       :                                  :
 0     v                                  v                 1
 <---------------------------------------------------------->
                      TF/IDF Similarity
```

#### Mit Ground Truth

Der Algorithmus eines Label Generators mit Ground Truth, welcher in Algorithmus
\ref{alg:labels} beschrieben ist, modifiziert den Algorithmus
\ref{alg:weaklabels}. Gegeben ist die Ground Truth in Form von Matches. Davon
ausgehen soll eine repräsentative Menge von Non-Matches aus dem Datensatz $D$
selektiert werden. Die ersten drei Schritte das Generieren der TF/IDF Statistik,
das Blocken durch die Tokens und das Erzeugen der Kandidatenmenge $C$ (Zeilen
\ref{alg:wk:inits}-\ref{alg:wk:inite} in grau), sind identisch zum
ursprünglichen Algorithmus. Nachdem die Kandidatenmenge erzeugt wurde, werden
zunächst alle Ground Truth Paare nach $P$ übernommen (Zeilen
\ref{alg:wk:gts}-\ref{alg:wk:gte}). Zusätzlich werden alle Matches aus der
Kandidatenmenge $C$ entfernt, sodass diese ausschließlich Non-Matches
beinhaltet. Anschließend werden ebenfalls die TF/IDF-Ähnlichkeit der Paare in
$C$ ermittelt und in $M$ zwischengespeichert (Zeilen
\ref{alg:wk:tfidfs}-\ref{alg:wk:tfidfe}). Anhand dieser wird die
Wahrscheinlichkeitsverteilung der Ähnlichkeiten in $M$, beispielsweise durch ein
Histogramm ermittelt (Zeile \ref{alg:wk:hist}). In @fig:label_sampling ist
beispielhaft eine Verteilung von Non-Matches (`-` Symbol) dargestellt. Die
X-Achse gibt den Ähnlichkeitswert der Paare an. Die Häufung, auf der Y-Achse,
illustriert, wie viele Paare eine entsprechende Ähnlichkeit haben. Eine Häufung
ist vor allen Dingen im unteren Ähnlichkeitsbereich zu erwarten. Durchaus
möglich sind allerdings auch größere Anhäufungen im mittleren Bereich, da durch
das Blocking der Großteil der Paare mit Ähnlichkeit 0.0 ausgeschlossen worden
ist. In Zeile \ref{alg:wk:smpl} werden nun Non-Matches, anhand der
Wahrscheinlichkeitsverteilung, zufällig aus $M$ gezogen, sodass Paare innerhalb
einer großen Anhäufung (z.B. unterer Bereich) häufiger ausgewählt werden, als
Paare in kleinen Anhäufungen (z.B. oberer Bereich). Damit wird erreicht, dass
die Menge, der für die Ground Truth gewählten Non-Matches, möglichst
repräsentativ ist. Die Ziehung wird $max_n$-Mal wiederholt bzw., solange bis
keine Paare mehr übrig sind (Zeilen \ref{alg:wk:ss}-\ref{alg:wk:se}). Zum
Schluss wird analog zum ursprünglichen Algorithmus die Grund Truth bestehend aus
$P$ und $N$ an die Engine übergeben.

```{.a2s #fig:label_sampling
    caption="Beispielhalfte Verteilung von Non-Matches ('-' Symbol) auf der über
    die Ähnlichkeit (X-Achse) zwischen 0 und 1. Wie viele Non-Matches einen
    bestimmten Ähnlichkeitswert haben, wird durch die Häufung (Y-Achse)
    dargestellt."}
 Cluster-Size

      ^
      |     -
      |    - -
      |   - - -                         -
      |   -  - -                       - -
      |  - -  - -                      - - -
      |  - -  -  -            -      -   -  -
      |  - -  -   - -       -  -     -  - -  -            -
      |  - - -  - - -      -  -     -  -   - -           - - -
      | - - -  - -  - - -  - - -    - -  - - -  - -      - - -  - -                  - -
      +--------------------------------------------------------------------------------------------------->
      0                                            0.5                                                    1

                                              TF/IDF Similarity
```

### Blocking Schema Generator

#### Blocks DNF Generator

Der Blocks DNF Generator erzeugt ein Blocking Schema in disjunktiver Normalform,
welche für dynamische Entity Resolution Verfahren geeignet ist. Um die
Hintergründe des Blocks DNF Generator zu verstehen wird zunächst das Verfahren
von Kejriwal & Miranker [@KM:Unsupervised:13] untersucht, wessen Autoren das
DNF Blocking Schema entwickelt haben. Kejriwal & Miranker erzeugen Blocking
Schema, indem Ausdrücke über die Fisher-Score bewertet werden. Die berechnete
Fisher-Score drückt für einen Ausdruck $t$, in Abhängigkeit der Groud Truth $P$
und $N$, die Blockschlüsselabdeckung (engl. blocking key coverage) aus. Laut
Ramadan & Christen [@RC:Unsupervised:15] führt eine hohe Schlüsselabdeckung
dazu, dass viele true positive Matches in einem Block gruppiert werden, während
die Anzahl an negativen Matches gering gehalten wird. Durch dieses Verfahren
wird für einen Entity Resolution Workflow hochqualitative Blöcke erzeugt. Für
dynamische Verfahren, die Anfragen im Subsekundenbereich antworten und möglichst
gleiche Latenzen haben sollten, ist aufgrund der niedrigen Dichte von Duplikaten
in Datensätzen die Fisher-Score als Bewertungskriterum ungeeignet. Zwar werden
für die Duplikate Blöcke generiert, die es erlauben (möglichst) alle zur Anfrage
passenden Entitäten schnell und präzise zu erhalten, allerdings ist der Großteil
aller Anfragen ergebnislos. Ergebnislos in diesem Zusammenhang bedeutet, dass es
zu einer Anfrage keinen Datensatz gibt, der derselben Entität entspricht. Das
Problem ist, dass die Fisher-Score für diese Datensätze keine Aussage trifft,
weshalb die generierten Blöcke, in welchen sich keine Matches befinden, zum Teil
sehr groß werden können. Aufgrund der Menge dieser Anfragen, wird die
Effektivität des ER Systems dramatisch reduziert.

```texalgo
#alg:dnf LearnOptimalBS($S$, $k$, $d$)
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Set of specific blocking predicates: $S$
  \item Maximum conjunctions per term: $k$
  \item Maximum disjunctions of terms: $d$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Blocking Scheme: $BS$
  \end{itemize}
}
\Statex
\State Initialize set of blocking scheme candidates $BS_C = ()$
\State Initialize set of terms $T = ()$
\For{$i = 1$ \textbf{to} $k$}\label{alg:bs:dis}
    \State Generate combination of $S$ with cardinality $i$ and
    \StatexIndent[1] add to $T$
\EndFor\label{alg:bs:die}
\For{term $t \in T$}
    \State $fmeasure, y_{true}, y_{pred} = evaluateTerm(t)$\Comment
    \If{$fmeasure = thres$}
        \State Remove $t$ from $T$\label{alg:bs:del}
    \EndIf
\EndFor
\For{$i = 1$ \textbf{to} $d$}\label{alg:ref:cms}
    \State Generate combination $C$ of $T$ with cardinality $i$
    \State Add $C$ to $BS_C$\label{alg:ref:cme}
\EndFor
\For{Blocking scheme $bs \in BS_C$}
    \State Initialize array $y_{true}$ with length $|P \cup N|$
    \State Initialize array $y_{pred}$ with length $|P \cup N|$
    \For{term $t \in bs$}
        \State $y_{true} \lor t.y_{true}$\label{alg:bs:ort}
        \State $y_{pred} \lor t.y_{pred}$\label{alg:bs:ory}
    \EndFor
    \State Score $s = fmeasure(y_{true}, y_{pred})$\label{alg:bs:fm}
    \If{$s > top_score$}
        \State $BS = bs$
    \EndIf
\EndFor
\State return $BS$

#alg:dnf_eval EvaluateTerm($t$, $D$, $IX$, $P$, $N$)
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Term: $t$
  \item Dataset: $D$
  \item Indexer: $IX$
  \item Set of positive pairs: $P$
  \item Set of negative pairs: $N$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item F-measure: $f$
  \item Labels: $y_{true}$
  \item Predictions: $y_{pred}$
  \end{itemize}
}
\Statex
\State Build Index $I$ over $D$ using Indexer $IX$ and Term $t$\label{alg:bs:idx}
\State Initialize set of pairs $C = ()$
\State Initialize $TP = 0, FP = 0, FN = 0$
\For{block $b \in I$}\label{alg:bs:feb}
    \State Generate pair combinations $pc$ for records in $b$\label{alg:bs:cmb}
    \StatexIndent[1] and add them to $C$
    \State According to $P$ and $N$ calculate number of true\label{alg:bs:cnt}
    \StatexIndent[1] positives, false positives and false negatives and
    \StatexIndent[1] sum them up with $TP$, $FP$ and $FN$.
\EndFor
\State Calculate F-measure $f$ according to $TP, FN, FP$\label{alg:bs:fmes}
\State Initialize array $y_{true}$ and $y_{pred}$ with length $|P \cup N|$\label{alg:bs:yarr}
\For{$i = 1$ \textbf{to} $|P|$}\label{alg:bs:p}
    \State Pair $p = P[i]$
    \State $y_{true} = True$\label{alg:bs:p1}
    \If{$p \in C$}
        \State $y_{pred} = True$\label{alg:bs:p2}
    \Else
        \State $y_{pred} = False$\label{alg:bs:p3}
    \EndIf
\EndFor
\For{$i = |P| + 1$ \textbf{to} $|N|$}\label{alg:bs:n}
    \State Pair $p = N[i]$
    \State $y_{true} = False$\label{alg:bs:n1}
    \If{$p \in C$}
        \State $y_{pred} = True$\label{alg:bs:n2}
    \Else
        \State $y_{pred} = False$\label{alg:bs:n3}
    \EndIf
\EndFor
\State return $f, y_{true}, y_{pred}$
```

Der Blocks DNF Generator erzeugt daher ein Blocking Schema, unter
Berücksichtigung aller erzeugten Blöcke. Dazu werden wie bei Kejriwal & Miranker
Kombinationen von konjugierten Ausdrücken, beispielsweise für einen
Publikationsdatensatz (`EnthältGemeinsamenToken`, `Autor`) $\land$
(`ExakteÜbereinstimmung`, `Konferenz`), gebildet. Diese werden neben der
Qualität, auch in ihrer Effektivität untersucht. Die Evaluierung eines Ausdrucks
ist in Algorithmus \ref{alg:dnf_eval} beschrieben. Zur Bewertung eines Ausdrucks
$t$ benötigt der Algorithmus den Datensatz $D$, sowie die Matches $P$ und die
Non-Matches $N$, der Ground Truth. Zudem wird, der durch die Engine
instanziierte Indexer $IX$ benötigt. Der Ausdruck $t$ wird dem Indexer $IX$ als
Blocking Schema übergeben, woraus dieser seinen Index $I$ über $D$ zu baut
(Zeile \ref{alg:bs:idx}). Durch die Betrachtung des konkreten Index, kann der
Block DNF Generator eine DNF erzeugen, die auf den Indexer zugeschnitten ist.
Als nächstes werden alle generierten Blöcke aus $I$ betrachtet (Zeile
\ref{alg:bs:feb}). Der Indexer muss dazu eine entsprechende Blockliste
bereitstellen. Ein Block ist in diesem Zusammenhang, nicht zwangsweise eine
Gruppierung, welche über einen Blockschlüssel, gebildet wurde, sondern jegliche
Anhäufungen von Datensätze, die bei einer Anfrage zusammen als Kandidatenmenge
ausgewählt werden. Die Details hierzu werden in @sec:indexer erläutert. Für
jeden Block werden zunächst die Paarkombinationen[^3], aller dem Block
zugehöriger Datensätze, ermittelt. Diese werden zu der Menge aller
Paarkombinationen aller Blöcke $C$ hinzugefügt (Zeile \ref{alg:bs:cmb}). Des
Weiteren wird für einen Block $b$ die Anzahl der Paare in den
Klassifikationskategorien

* true positives, wenn ein Paar $p \in b$ und $p \in P$
* false positives, wenn ein Paar $p \in b$ und $p \in N$
* true negatives, wenn ein Paar $p \notin b$ und $p \in P$

über die Grund Truth ermittelt und in $TP$, $FP$ und $FN$ aufsummiert (Zeile
\ref{alg:bs:cnt}). Anhand dieser $TP$, $FP$, $FN$ wird das F-measure zur
Bewertung des Ausdrucks $t$ bestimmt (Zeile \ref{alg:bs:fmes}). Bei der späteren
Disjunktion von Ausdrücken kann dieses F-measure allderdings nur zur Vorauswahl
der infrage kommenden Audrücke genutzt werden, da sich die F-measure Werte
verschiedener Ausdrücke aus unterschiedlichen Paarkombinationen berechnen. Damit
die Ausdrücke effizient disjunktiert werden können, wird die Paarkombination auf
die Ground Truth abgebildet. Dazu werden zwei Arrays $y_{true}$ und $y_{pred}$
mit der Länge $|P \cup N|$ erzeugt (Zeile \ref{alg:bs:yarr}). Diese können beim
Zusammenfügen der DNF einfach verodert und daraus das F-measure bestimmt werden.
Für die Abbildung auf die Ground Truth müssen alles Matches $P$ (Zeile
\ref{alg:bs:p}) und alle Non-Matches (Zeile \ref{alg:bs:n}) betrachtet werden.
$y_{true}$ gibt an, welcher Klasse ein Paar $p$ angehört: Match, wenn $p \in P$
(Zeile \ref{alg:bs:p1}) oder Non-Match, wenn $p \in N$ (Zeile \ref{alg:bs:n1}).
$y_{pred}$ gibt an, ob ein Datensatzpaar einen gemeinsamen Block in $I$ hat
$y_{pred}[p] = True$ (Zeilen \ref{alg:bs:p2},\ref{alg:bs:n2}) oder nicht
$y_{pred}[p] = False$ (Zeilen \ref{alg:bs:p3},\ref{alg:bs:n3}). Die Werte für
F-measure, $y_{true}$ und $y_{pred}$ werden zum Schluss an den Aufrufer
zurückgegeben.

[^3]: 2-Tupel der Datensätze ohne festgelegte Reihenfolge

Der Algorithmus zur Bestimmung des optimalen Blocking Schemas ist in Algorithmus
\ref{alg:dnf} dargestellt. Der erste Parameter sind die spezifischen
Blockingprädikate $S$. Diese werden von der Engine je nach Attributstyp
bestimmt. Da die maximale Konjunktion der Blockingprädikate bzw. die maximale
Disjunktion potentiell unendlich groß ist, werden diese über die Parameter $k$
für die Konjunktionen und $d$ für die Disjunktionen begrenzt. Ein weiterer Grund
die Konjunktionen bzw. Disjunktionen nicht beliebig zu erhöhen ist, dass der
Indexer deutlich komplexere Blockschlüssel erzeugen muss. Denn für jedes
spezifische Blockingprädikat muss, beim Erzeugen der Blockschlüssel eines
Datensatzes, die Prädikatsfunktion aufgerufen werden. Demnach nimmt die
Effizienz der Blockschlüsselgenerierung ab, je mehr Konjunktionen bzw.
Disjunktionen ein Blocking Schema hat. Am Anfang werden die konjugierten
Ausdrücke erzeugt, indem alle Kombinationen der Menge spezifischer
Blockingprädikte $S$ bis zur Länge $k$ der maximalen Konjunktionen berechnet
werden (Zeilen \ref{alg:bs:dis}-\ref{alg:bs:die}), somit ist $$T =
\{\{\text{2-Tupel von S}\}, \{\text{3-Tupel von S}\}, \dots, \{\text{k-Tupel von
S}\}\}.$$ Anschließend wird jeder Ausdruck $t$ durch oben erklärten Algorithmus
\ref{alg:dnf_eval} evaluiert. Ist der F-measure Wert $f$ für $t$ kleiner einer
Schranke $thres$, indiziert dies einen ungeeigneten Block und der Ausdruck wird
entfernt (Zeile \ref{alg:bs:del}). Aus den noch in $T$ vorhandenen Ausdrücken,
werden durch Disjunktion bis zur Länge $d$, mögliche Kandidaten eines Blocking
Schemas generiert (Zeilen \ref{alg:ref:cms}-\ref{alg:ref:cme}). Ein Blocking
Schema wird ausgewählt, indem die Arrays $y_{pred}$ und $y_{true}$ der Ausdrücke
in jedem potentiellen Blocking Schema verodert werden (Zeilen
\ref{alg:bs:ort}-\ref{alg:bs:ory}) und daraus das F-measure berechnet wird
(Zeile \ref{alg:bs:fm}). Das potentielle Blocking Schema mit dem höchsten
F-measure wird abschließend ausgewählt und an die Engine zurückgegeben.

### Indexer {#sec:indexer}

#### MDySimII

Der Multi-Dynamic Similarity-Aware Inverted Index (MDySimII) ist eine Anpassung
des ursprünglichen DySimII (vgl. @sec:dysimII) Verfahrens. Dabei steht das Multi
für einen Multi-pass Ansatz, bei welchem zu einem Datensatz mehrere
Blockschlüssel erzeugt werden. Dadurch können die Datensätze in mehrere Blöcke
eingeordnet werden, womit sich die Wahrscheinlichkeit erhöht ein Duplikat zu
finden. Die Idee des DySimII ist es, die Ähnlichkeit aller Attribute
vorauszuberechnen. Dafür wird für jedes Attribut eine Enkodierungsfunktion
genutzt, die einen Blockschlüssel erzeugt. Anhand dieser kann die Ähnlichkeit
für die Kandidatenmenge jedes Attributes vorausberechnet werden. Im Wesentlichen
handelt es sich bei DySimII bereits um eine Multi-pass Verfahren, da für jedes
Attribut der Datensatz in einen Block gruppiert wird. Bei $k$ Attributen wird
der Datensatz folglich zu $k$ Blöcken hinzugefügt. Die Generierung von
Blockschlüsseln ist jedoch stark eingeschränkt, da ein Schlüssel ausschließlich
auf einem Attribut berechnet wird. Darüber hinaus darf maximal ein Schlüssel pro
Attribut generiert werden. Aufgrund dessen wird der DySimII Ansatz nicht als
Multi-pass Ansatz betrachtet und es ist demzufolge auch nicht möglich das DNF
Blocking Schema nutzen. Der MDySimII hingegen implementiert einen DNF
kompatiblen Multi-pass Ansatz. Das bedeutet, dass Blockschlüssel über mehrere
Attribute generiert werden können, dass nicht jedes Attribut zur Generierung
genutzt werden muss und zudem kann eine Funktion mehrere Blockschlüssel erzeugen
darf. Da das DNF Blocking Schema allerdings nicht mehr garantiert, dass jedes
Attribut berücksichtigt wird, entfällt eine vollständige Vorausberechnung der
Ähnlichkeiten. Im schlimmsten Fall besteht das Blocking Schema nur aus einem
einstelligen Ausdruck, wodurch das Blocking lediglich auf einem Attribut
durchgeführt. Dementsprechend muss bei einer Anfrage, zwischen den im Blocking
Schema nicht enthaltenen Attributen, immer die Ähnlichkeit ermittelt werden und
kann nicht im Index nachgeschlagen werden. Als Ergebnis einer Anfrage wurde vom
der ursprünglichen DySimII Implementierung eine Kandidatenliste mit der
aufsummierten Gesamtwahrscheinlichkeit der Kandidaten zurückgegeben. Der
MDySimII hingegen gibt für jeden Kandidaten einen Vektor mit den einzelnen
Attributsähnlichkeiten zurück, sodass für den Klassifikator möglich wenig
Informationen verloren gehen.

```{.texalgo #alg:bkvs caption="BlockingKeyValues(t, r)"}
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Term from Blocking Schema $t$
  \item Record $r$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Blocking Key Values: $BKV$
  \end{itemize}
}
\Statex
\State Initialize list $BKV = []$
\For{specific blocking predicate $p \in t$}\label{alg:bkv:fep}
  \State field $f = p.field$
  \State attribute keys $ak = p.predicate(r.f)$\label{alg:bkv:pre}
  \If{$BKV$ is empty}
    \State $BKV = ak$\label{alg:bkv:f1}
  \Else
    \State $bkv$ = []
    \While{$BKV$ is not empty}\label{alg:bkv:as}
      \State Take key $x$ from BKV
      \For{key $y$ in $ak$}
        \State $xy = concatenate(x ,y)$\label{alg:bkv:cc}
        \State Append $xy$ to $BKV$
      \EndFor
    \EndWhile\label{alg:bkv:ae}
    \State $BKV = bkv$\label{alg:bkv:rpl}
  \EndIf
\EndFor
\State return $BKV$
```

Durch die erläuterten Anpassungen für den MDySimII ergeben einige Änderungen im
Ablauf. Zunächst wird in Algorithmus \ref{alg:bkvs} gezeigt, wie die
Blockschlüssel des DNF Blocking Schema erzeugt werden. Jeder Ausdruck $t$ der
Disjunktion erzeugt eine unabhängige Menge von Blockschlüsseln für einen
Datensatz $r$. Aus diesem Grund erzeugt der Algorithmus Blockschlüssel für die
Konjunktion von spezifischen Blockingprädikaten in $t$ über $r$. Die
Blockingprädikate werden dazu der Reihe nach betrachtet (Zeile
\ref{alg:bkv:fep}). Anhand des spezifische Blockingprädikat $p$ werden alle
Schlüssel für das verknüpfte Attribut $p.field$ generiert, beispielsweise
liefert das Prädikat `GemeinsamerToken` alle durch Leerzeichen getrennte Token
des Attributes $r.f$ (Zeile \ref{alg:bkv:pre}). Ist die BKV Liste zu diesem
Zeitpunkt leer, wird die Schlüsselliste $ak$ als $BKV$ Liste übernommen.
Existieren in $BKV$ allerdings schon Schlüssel wird zunächst eine temporäre
Liste $bkv$ erzeugt. Anschließend werden aus $BKV$ solange Schlüssel entnommen,
bis diese leer ist (Zeile \ref{alg:bkv:as}). Für jeden entnommenen Schlüssel $x$
werden $|ak|$ neue Schlüssel erzeugt. Dazu wird der neue Schlüssel $xy$
gebildet, indem ein Schlüssel $y$ aus $ak$ mit $x$ konkateniert wird (Zeile
\ref{alg:bkv:cc}). Alle Schlüssel $xy$ werden zu $bkv$ hinzugefügt. Wenn die
$BKV$ Liste leer ist, wird die temporäre Liste $bkv$ nach $BKV$ übernommen
(Zeile \ref{alg:bkv:rpl}). Nachdem alle Prädikate bearbeitet wurden, wird die
Liste der Blockschlüssel $BKV$ zurückgegeben.

```texalgo
#alg:mdysim_insert MDySimII - Build
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Data set: $D$
  \item DNF Blocking Scheme: $BS$
  \item Fields used in $BS$ as: $F$
  \item Similarity funcitons: $S_i,i=1 \cdots n$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Index data structures: $RI, BI, SI$
  \end{itemize}
}
\Statex
\For{fields $f \in F$}\label{alg:dII:is}
  \State Initialize $RI_f = \{\}$, $BI_f = \{\}$, $SI_f = \{\}$
\EndFor\label{alg:dII:ie}
\For{records $r \in D$}
  \For{fields $f \in F$}\label{alg:dII:ris}
    \State insert $r.id$ into $RI_f[r.f]$
  \EndFor\label{alg:dII:rie}
  \For{terms $t \in BS$}
    \State $bkvs = BlockingKeyValues(t, r)$\label{alg:dII:bkv}
    \For{$bkv \in bkvs$}
      \For{fields $f \in t.fields$}
        \State Append r.f to $BI_f[bkv]$\label{alg:dII:bi}
        \State Initialize inverted index list $si = ()$
        \For{attribute $a \in bi$}
          \If{$a \notin SI_f$}
            \State $sim = S_f(r.f, a)$\label{alg:dII:sim}
            \State Append $(r.f, sim)$ to $SI_f[a]$\label{alg:dII:si1}
            \State Append $(a, sim)$ to $si$\label{alg:dII:si2}
          \EndIf
        \EndFor
        \State $SI_f[r.f] = si$\label{alg:dII:si3}
      \EndFor
    \EndFor
  \EndFor\label{alg:dII:ins}
\EndFor

#alg:mdysimIII_insert MDySimIII - Build
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Data set: $D$
  \item DNF Blocking Scheme: $BS$
  \item Fields used in $BS$ as: $F$
  \item Similarity funcitons: $S_i,i=1 \cdots n$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Index data structures: $BI, SI$
  \end{itemize}
}
\Statex\color{gray}
\For{fields $f \in F$}
  \State Initialize $BI_f = \{\}$, $SI_f = \{\}$
\EndFor
\For{records $r \in D$}
  \For{terms $t \in BS$}
    \State $bkvs = BlockingKeyValues(t, r)$
    \For{$bkv \in bkvs$}
      \For{fields $f \in t.fields$}
        \State Add $r.f$ to $BI_f[bkv]$\color{black}
        \State $ri = bi[r.f]$
        \State Add $r.id$ to $ri$
        \State $BI_f[bkv] = ri$\color{gray}
        \State Initialize inverted index list $si = ()$
        \For{attribute $a \in bi$}
          \If{$a \notin SI_f$}
            \State $sim = S_f(r.f, a)$
            \State Append $(r.f, sim)$ to $SI_f[a]$
            \State Append $(a, sim)$ to $si$
          \EndIf
        \EndFor
        \State $SI_f[r.f] = si$
      \EndFor
    \EndFor
  \EndFor
\EndFor
```

In Algorithmus \ref{alg:mdysim_insert} ist die *Build-Phase* des MDySimII
beschrieben. Zunächst werden die Index Datenstrukturen Record Identifier Index
(RI), welcher alle Attribute speichert und diese ihren Datensätzen zuordnet,
Block Index (BI), welcher Attribute anhand der Blockschlüssel gruppiert und
Similarity Index (SI), welcher Attributsähnlichkeiten zwischen Attributen im
gleichen Block hält, für jedes in der DNF vorkommende Attribut erzeugt (Zeilen
\ref{alg:dII:is}-\ref{alg:dII:ie}). Als Nächstes werden alle Datensätze in $D$
nacheinander hinzugefügt. Dazu wird zuerst der Datensatzidentifier unter dem
entsprechenden Attribute, in alle initialisierten RIs, eingefügt (Zeilen
\ref{alg:dII:ris}-\ref{alg:dII:rie}). Anschließend werden die disjunkten
Ausdrücke der DNF einzeln betrachtet. Zu jedem Ausdruck werden für den Datensatz
$r$ die Blockschlüsselwerte $bkvs$ erzeugt (Zeile \ref{alg:dII:bkv}). Für jedes,
durch den aktuellen Ausdrucks erfasste Attribut, werden die Attributswerte von
$r$ unter dem Blockschlüssel $bkv$ in den entsprechenden Block Index eingefügt
(Zeilen \ref{alg:dII:bi}). Nachdem ein Attribut in einen Block eingefügt wurde,
werden analog zum ursprünglichen DySimII Verfahren, die Ähnlichkeiten zwischen
$r.f$ und den bisherigen Attributen des Blocks ermittelt (Zeile
\ref{alg:dII:sim}). Im Similarity Index wird für jedes bisherige Attribut $a$
der ermittelte Ähnlichkeits $sim$ zu $r.f$ ergänzt (Zeile \ref{alg:dII:si1}).
Ebenso für $r.f$ die Ähnlichkeiten zu den Attributen des Blocks in $si$
aufgenommen (Zeile \ref{alg:dII:si2}) und abschließend zum SI des Attributes
$SI_f$ hinzugefügt (Zeile \ref{alg:dII:si3}). Der Algorithmus endet, wenn alle
Datensätze $r \in D$ hinzugefügt wurden. Wird später in der *Query-Phase* ein
einzelner Datensatz hinzugefügt, werden lediglich die Schritte in Zeile
\ref{alg:dII:ris}-\ref{alg:dII:ins} durchgeführt.

```texalgo
#alg:mdysim_query DNF Similarity-Aware Index - Query
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Query record: $q$
  \item DNF Blocking Schema: $BS$
  \item Fields used in $BS$ as: $F$
  \item Similarity funcitons: $S_i,i=1 \cdots n$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Matches: $M$
  \end{itemize}
}
\Statex
\State Initialize dictionary $M = \{\}$
\State Insert $q$ into Index
\For{fields $f \in F$}
    \State $ri = RI_f[q.f]$
    \For{$r.id \in ri$}
        \State $M[(r.id, f)] = 1.0$
    \EndFor
    \State $si = SI_f[q.f]$
    \For{$(r.f, sim) \in si$}
        \State $ri = RI_f[r.f]$
        \For{$r.id \in ri$}
            \State $M[(r.id, f)] = sim$
        \EndFor
    \EndFor
\EndFor
\State return $M$

#alg:mdysimIII_query DNF Similarity-Aware Index - Query
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Query record: $q$
  \item DNF Blocking Schema: $BS$
  \item Fields used in $BS$ as: $F$
  \item Similarity funcitons: $S_i,i=1 \cdots n$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Matches: $M$
  \end{itemize}
}
\Statex\color{gray}
\State Initialize dictionary $M = \{\}$
\State Insert $q$ into Index\color{black}
\For{terms $t \in BS$}
  \State $bkvs = BlockingKeyValues(t, r)$
  \For{$bkv \in bkvs$}
    \For{fields $f \in t.fields$}
      \State $bi = BI_f[bkv]$
      \For{attribute $r.f \in bi$}
        \If{$q.f = r.f$}
          \For{identifier $r.id \in bi[q.f]$}
            \State $M[(r.id, f)] = 1.0$
          \EndFor
        \Else
          \State $si = SI_f[q.f]$
          \State $sim = si[r.f]$
          \For{identifier $r.id \in bi[r.f]$}
            \State $M[(r.id, f)] = sim$
          \EndFor
        \EndIf
      \EndFor
    \EndFor
  \EndFor
\EndFor\color{gray}
\State return $M$
```

Die *Query-Phase* des MDySimII wird in Algorithmus \ref{alg:mdysim_query}
beschrieben. Dieser Algorithmus ist fast identisch zum DySimII Verfahren, bis
auf die Ausnahmen, das ein Ähnlichkeitsvektor erstellt wird, anstatt die
einzelnen Ähnlichkeiten aufzusummieren und das nur Attribute betrachtet werden,
die im Blocking Schema vorkommen. Zunächst wird die Kandidatenliste $M$
initialisiert (Zeile 1). Bevor die Ähnlichkeiten aus dem Index gelesen werden,
wird dieser nach dem Algorithmus \ref{alg:mdysim_insert} zunächst in den Index
eingefügt (Zeile 2). Sollte der Datensatz sich schon im Index befinden, wird
dieser Schritt übersprungen. Dadurch ist sichergestellt, dass die Ähnlichkeiten
für die Kandidaten von $q$ berechnet wurden, falls diese noch nicht im SI
vorhanden waren. Für jedes Attribut aus $q$, das vom Blocking Schema $BS$
abgedeckt wird, werden alle Kandidaten mit übereinstimmenden Attribut aus dem RI
geholt und mit dem Ähnlichkeitswert 1.0 (Total Übereinstimmung), in die
Kandidatenliste übernommen (Zeilen 4-7). Anschließend werden für das Attribut
$q.f$ alle Kandidaten im selben Block mit ihrer vorausberechneten Ähnlichkeit
aus dem SI geholt. Die Identifier der Attribute im selben Block werden im
Anschluss über den RI aufgelöst und schließlich mit dem Ähnlichkeitswert
zusammen in die Kandidatenlist übernommen (Zeilen 8-14). In der Einleitung des
MDySimII wurde erwähnt, dass Ähnlichkeiten zwischen Attributen, die nicht im
Blocking Schema enthalten sind, immer berechnet werden müssen. Aus
Effizienzgründen wurde das für diesen Query-Algorithmus nicht umgesetzt, wodurch
der erzeugte Ähnlichkeitsvektor in mehreren Stellen unbesetzt sein kann. Was
genau die Auswirkungen dieser Entscheidung sind, wird in @sec:dysim_fvsp
evaluiert.

Das ursprüngliche Design des Similarity-Aware Inverted Index von Christen &
Gayler [@CG:Scalable:08] hat eine fundamentale Schwachstelle, die auch in den
Varianten DySimII und MDySimII vorhanden ist. Diese Schwachstelle ist der Record
Identifier Index (RI), welcher den Index enorm ausbremst, wenn ein Attribut nur
wenige Auswahlmöglichkeiten bietet, beispielsweise Geschlecht oder Bundesland,
bzw. wenn wenige Attributswerte besonders oft vorkommen, beispielsweise der
Nachname `Müller`, welcher besonders oft im getragen wird. Wenn ein solches
Attribut im DNF Blocking Schema vorkommt, wird zwangsweise über den Record
Identifier Index eine riesige Menge an Kandidaten selektiert, wovon nur ein
Bruchteil tatsächlich relevant ist. Der schlimmste Fall wäre beispielsweise ein
Datensatz mit einem Attribut Geschlecht (männlich/weiblich), mit einer
Geschlechterverteilung von 50 zu 50. Dafür erzeugen alle Variationen des
Similarity-Aware Inverted Index eine Kandidatenmenge mit mindestens 50% der
Datensätze, eben jene 50 % *weibliche* oder 50 % *männliche*. Aufgrund der
vielen false positives in der Kandidatenmenge, wird der Blocks DNF Generator
Ausdrücke mit diesen Attributen, sowohl alleinstehend als auch in Konjunktion
mit anderen Attributen, sehr schlecht bewerten. Im ungünstigsten Fall wird
dadurch ein Ausdruck, welcher für den BI sehr gute Blöcke erzeugt, durch die
rießigen Blöcke im, irrelevant.

#### MDySimIII

```{.a2s #fig:mdysim_example
    caption="Ein beispielhafter MDySimIII-Index, welcher aus der Tabelle links
    erzeugt worden ist. Die Beispieldatensätze enthalten das Namensattribut
    eines Restaurants und die Art der Küche. BI ist der Block Index, welcher aus
    dem Blocking Schema (CommonToken, Kitchen) erzeugt wurde. SI ist der
    Similarity Index."}
 Blocking Scheme: (CommonToken, Name) ∧ (CommonToken, Kitchen)

#-----------+--------------+--------------#  #----------------------------------------------# #--------------#
|[RID      ]| Name         | Kitchen      |  | SI (name)                                    | | SI (kitchen) |
#-----------+--------------+--------------#  | .--------------.      .-------------.        | |              |
|     r1    | tonys pizza  | italian      |  | | tonys gelato |      | tonys pizza |        | | {empty}      |
+-----------+--------------+--------------+  | '--+-----------'      '--+----------'        | #--------------#
|     r2    | tonys gelato | vegi         |  |    |                     |                   |
+-----------+--------------+--------------+  |    v                     v                   |
|     r3    | tonys pizza  | italian vegi |  | .--+----------+-----. .--+-----------+-----. |
+-----------+--------------+--------------+  | | tonys pizza | 0.7 | | tonys gelato | 0.7 | |
|     r4    | tonys pizza  | american     |  | '-------------+-----' '--------------+-----' |
#-----------+--------------+--------------#  #----------------------------------------------#
#-------------------------------------------------------------------------------------------# #---------------------------------------------------------------------------#
| BI (name)                                                                                 | | BI (kitchen)                                                              |
| .--------------.         .--------------.         .---------------.                       | | .--------------.     .--------------.     .---------------.               |
| | tonysitalian |         | pizzaitalian |         | tonysamerican |                       | | | tonysitalian |     | pizzaitalian |     | tonysamerican |               |
| '---+----------'         '---+----------'         '---+-----------'                       | | '---+----------'     '---+----------'     '---+-----------'               |
|     |                        |                        |                                   | |     |                    |                    |                           |
|     v            RI          v            RI          v            RI                     | |     v        RI          v        RI          v         RI                |
| .---+---------.  .--+--. .---+---------.  .--+--. .---+---------.  .--.                   | | .---+-----.  .--+--. .---+-----.  .--+--. .---+------.  .--.              |
| | tonys pizza +->+r1|r3| | tonys pizza +->+r1|r3| | tonys pizza +->+r4|                   | | | italian +->+r1|r3| | italian +->+r1|r3| | american +->+r4|              |
| '-------------'  '--+--' '-------------'  '--+--' '-------------'  '--'                   | | '---------'  '--+--' '---------'  '--+--' '----------'  '--'              |
|                                                                                           | |                                                                           |
| .-----------.          .------------.         .-----------.         .---------------.     | | .-----------.     .------------.    .-----------.     .---------------.   |
| | tonysvegi |          | gelatovegi |         | pizzavegi |         | pizzaamerican |     | | | tonysvegi |     | gelatovegi |    | pizzavegi |     | pizzaamerican |   |
| '--+--------'          '--+---------'         '--+--------'         '---+-----------'     | | '--+--------'     '--+---------'    '--+--------'     '---+-----------'   |
|    |                      |                      |                      |                 | |    |                 |                 |                  |               |
|    v              RI      v              RI      v             RI       v            RI   | |    v      RI         v      RI         v      RI          v         RI    |
| .--+-----------.  .--. .--+-----------.  .--. .--+----------.  .--. .---+---------.  .--. | | .--+---.  .--+--. .--+---.  .--+--. .--+---.  .--+--. .---+------.  .--.  |
| | tonys gelato +->|r2| | tonys gelato +->|r2| | tonys pizza +->|r3| | tonys pizza +->+r4| | | | vegi +->+r2|r3| | vegi +->+r2|r3| | vegi +->+r2|r3| | american +->+r4|  |
| +--------------+  #--# '--------------'  '--' '-------------'  '--' '-------------'  '--' | | '------'  '--+--' '------'  '--+--' '------'  '--+--' '----------'  '--'  |
| | tonys pizza  +->|r3|                                                                    | |                                                                           |
| '--------------'  '--'                                                                    | |                                                                           |
#-------------------------------------------------------------------------------------------# #---------------------------------------------------------------------------#
[RID      ]: {"fill":"#cccccc", "a2s:label": " Record ID"}
```

Der MDySimIII ist eine Modifikation des MDySimII Verfahrens, der dahingehend
verändert wurde, dass die Anzahl der Kandidaten, auch bei spezifischen
Blockingprädikaten mit wenigen Optionen bzw. oft vorkommenden Werten, effizient
eingeschränkt werden kann. Dadurch ist es möglich, im Gegensatz zur bisherigen
Familie von Similarity-Aware Inverted Indices, deutlich mehr spezifische
Blockingprädikate, in einem Blocking Schema, zu erlauben. Damit dies möglich
ist, wurde der globale Record Identifier Index (RI), in seiner bisherigen Form,
aufgesplittet und in den Block Index (BI) verschoben. Der Similarity Index
bleibt unverändert und verlinkt weiterhin Attribute eines Blockes mit ihren
Ähnlichkeiten. In @fig:mdysim_example ist ein solcher Index aus den Datensätzen
der Tabelle links oben und dem Blocking Schema `(CommonToken, Name)` $\land$
`(CommonToken, Kitchen)` erstellt worden. Ein Datensatz besteht aus den beiden
Attributen Restaurantname `Name` und der Küchenart `Kitchen`. Anhand des
Blocking Schema wurden durch Algorithmus \ref{alg:bkvs} fünf Blockschlüssel
generiert, nämlich `tonysitalian`, `tonysvegi`, `pizzaitalian`, `pizzavegi` und
`gelatovegi`. Jeder Block beinhaltet weiterhin die Attribute, welche zum
entsprechenden Blockschlüssel gehören. Die große Veränderung des MDySimIII ist ,
dass jedes Attribut eines Blockes einen eigenen Record Identifier Index besitzt.
Anstatt, wie vorher alle Datensatzidentifier des gleichen Attributes global zu
gruppieren, werden hier ausschließlich diejenigen in denselben RI eingefügt,
die auch denselben Blockschlüssel haben, beispielsweise im BI des Namen über
den Blockschlüssel `tonysitalian` landen `r1` und `r3` zusammen im RI, nicht
jedoch `r4`, welcher keinen gemeinsamen Blockschlüssel zu `r1` oder `r3` hat.
Die Anzahl der Blöcke sind identisch zum MDySimII Verfahren, allerdings wird ein
Attribut $r.f$ $k$-Mal mit seinem Datensatzidentifier verknüpft, wobei $$k =
\sum_{t \in BS}|BlockingKeyValues(t, r.f)|.$$ Beispielsweise `r1` viermal, `r2`
fünfmal, `r3` neunmal und `r4` auch viermal. Das hat zur Folge, dass der
MDySimIII mehr Speicherplatz benötigt, als sein Vorgänger. Wie viel größer der
Bedarf ist, wird in @sec:dysim_ram überprüft.

Aufgrund der Änderungen am RI hat sich die Build-Phase an zwei Stellen leicht
verändert. In Algorithmus \ref{alg:mdysimIII_insert} ist das Bauen des Index
gezeigt. In grau sind die Schritte markiert, welche sich gegenüber Algorithmus
\ref{alg:mdysim_insert} nicht verändert haben. Die erste Veränderung ist, dass
das initiale Hinzufügen der Attribute, in ihren attributsspezifischen RI
wegfällt, da dieser so nicht mehr existiert. Die zweite Veränderung (Zeilen
10-12) ist beim Hinzufügen eines Attributes in einen Block. Nachdem das
Attribut wie gewohnt in den Block eingefügt wurde, wird dessen RI geholt (Zeile
10), zu welchem anschließend der Datensatzidentifier hinzugefügt wird (Zeile
11).

Im Gegensatz zur Build-Phase hat sich die Query-Phase grundlegend verändert, um
an die Identifier in den Blöcken zu gelangen, müssen für den Anfragedatensatz,
die Blockschlüssel generiert werden (siehe Algorithmus
\ref{alg:mdysimIII_query}). Diese werden nacheinander aus den Termen $t$ erzeugt
(Zeilen 3-4). Für jeden Blockschlüssel werden anschließend die entsprechenden
Blöcke der, an dem Ausdruck beteiligten Attribute, betrachtet (Zeilen 5-7). Für
jedes Attribut wird zunächst überprüft, ob dies dem eigenen entspricht. Ist dies
der Fall, wird der Ähnlichkeitsvektor der Kandidaten im RI $bi[q.f]$, mit dem
Ähnlichkeitswert 1.0 ergänzt (Zeilen 9-12). Falls die Attribute unterschiedlich
sind, wird die Ähnlichkeit $sim$ im SI nachgeschlagen (Zeile 15) und der
Ähnlichkeitsvektor der Kandidaten im RI $bi[r.f]$, mit dem Ähnlichkeitswert
$sim$ ergänzt. Zum Schluss wird ebenfalls der Kandidatenmenge $M$ an die Engine
zurückgegeben.
