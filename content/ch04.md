# Design eines selbstkonfigurierenden Systems

In diesem Kapitel werden zunächst die Prozesse eines sich selbst
konfigurierenden Entity Resolution System für dynamische Datenquellen, zur
Bearbeitung von Anfrageströme, beschrieben. Anschließend wird die zu lernende
Konfiguration formal definiert. Danach werden die Komponenten des Systems
vorgestellt und deren Schnittstellen beschrieben. In Bezug auf den jeweiligen
Prozess werden dann die Details zu den Komponenten erläutert, falls diese noch
nicht aus Kapitel 3 bekannt sind.

## Prozesssicht

```{.a2s #fig:engine_state
    caption="Zustandsdiagramm des selbstkonfigurierenden System. Lernen der
    Konfiguration versetzt das System von unangepasst nach angepasst. Wurde der
    Index gebaut, ist das System im Zustand gebaut und kann Anfrage
    entgegennehmen."}
        .------------.              .--------.  building    .-------.
        | not fitted |   fitting    | fitted +------------->| built |
 ●----->+------------+------------->+--------+  re-fitting  +-------+
        |            | load config  |        |<-------------+       |
        '------------'              '------+-'              '-----+-'
                                      ^    |                  ^   |
                                      '----'                  '---'
                                   save config              querying/
                                                            evalute
```

Die in Kapitel 2 und 3 vorgestellten Verfahren, für dynamische Entity
Resolution, trennen zwischen Build-Phase und Query-Phase. Diese Trennung wird
auch für das selbstkonfigurierende System aufrecht erhalten. Zusätzlich gibt es
noch eine weitere Phase zum Erlernen der Konfiguration, im Folgenden als
*Fit-Phase* bezeichnet. Je nach Phase befindet sich bzw. wechselt das System in
einen von drei Zuständen, die in @fig:engine_state dargestellt sind. Ein neu
erzeugtes System ist *unangepasst* und kann durch das Lernen der Konfiguration
(engl. fitting) in den Zustand *angepasst* wechseln. Alternativ kann der
Zustandsübergang durch das Laden einer bereits gelernte Konfiguration
durchgeführt werden. Anhand dieser Konfiguration kann der Index auf einem
initialen Datenbestand gebaut (engl. building) werden. Danach befindet sich das
System im Zustand *gebaut*. In diesem Zustand kann die eigentliche Entity
Resolution, durch stellen von Anfragen aus einem Datenstrom (engl. querying),
durchgeführt werden. Da die Möglichkeit besteht jede Anfrage in den Datenbestand
(den Index) aufzunehmen, liegen nach einer gewissen Zeit genügend neue Daten
vor, sodass sich auf Basis derer auch die optimale Konfiguartion verändert haben
kann. Während des erneuten Lernens (engl. refitting) können weiterhin Anfragen
beantwortet werden. Wenn der Lernvorgang abgeschlossen ist, muss der Index
erneut gebaut werden, bevor das System wieder anfragen entgegen nehmen kann.
Wenn Komponenten für das System entwickelt werden, ist es notwendig deren
Qualität und Effektivität auszuwerten. Weshalb das System im Entwicklungsbetrieb
entsprechende Metriken erheben und auswerten kann. Die Auswertung erfolgt
nachdem mindestens eine Anfrage durchgeführt wurde.

In der Fit-Phase nimmt die Engine die Konfiguration des Systems vor. Eine
Konfiguration ist ein Tupel $(BS, S, M)$ bestehend aus dem Blocking Schema, den
Ähnlichkeitsfunktionen und dem Klassikationsmodell. Die Teilkonfigurationen
werden anhand einer Ground Truth erlernt, diese ist definert als $GT = (P, N)$
und ist ebenfalls ein Tupel, dass sich in die Menge der positive Datensatzpaare,
die tatsächlichen Matches (true positives), sowie die Menge der negativen
Datensatzpaare, die tatsächlichen Non-Matches (true negatives) teilt. Ein
Datensatz wird definiert als $n$-Tupel, wobei $n$ die Anzahl der Attribute ist.
Ein Tupel hat die Form $t = (a_1, a_2, \dots, a_n)$. Ein Attribut hat eine feste
Position im Tupel, die als Feld oder Datenfeld $f$ bezeichnet wird. Ein
Datensatzensatzpaar ist definiert als $p = (t_j, t_k), j \neq k$, wobei $j$ und
$k$ zwei beliebige Tupel desselben Datensatzes sein können. Weiterhin gilt
$\forall p \in P, p \notin N$ und umgekehrt $\forall p \in N, p \notin P$. Das
Blocking Schema entspricht der Definition aus @sec:blk_scheme, $BS = (term_1
\land \dots \land term_j) \lor \dots \lor (term_k \land \dots \land term_n)$.
Eine Ähnlichkeitsfunktion wird während des Lernens der Konfiguration mit einem
Attribut verknüpft. Die Menge der gelernten Ähnlichkeitsfunktionen werden
entsprechend als Tupel angegeben $S = {(f_1, sim), \dots, (f_n, sim)}$. Die
Ähnlichkeitsfuntion $sim$ ist eine von $m$ möglichen Ähnlichkeitsfunktionen
${sim_1, \dots, sim_m}$, die vom System implementiert wurden. Das
Klassifikationsmodell $M$ ist spezifisch für den eingesetzten Klassifikator und
entspricht, bespielsweise einem trainierten Entscheidungsbaum.

## Komponentenmodell

```{.plantuml #fig:engine
    caption="Komponentenmodell des selbstkonfigurierenden Systems. Bestehend aus
    dem Ground Truth Generator, dem Blocking Scheme Lerner, dem Similarity
    Lerner und dem Fusion-Lerner, welche für das Erlernen der Konfiguration
    (Fit-Phase) nötig sind, dem Indexer, welcher anhand der gelernten
    Konfiguration gebaut wird und dem Klassifikator. Der Parser, um Daten einer
    Datenquelle zu laden und der Präprozessor, um die geladenen Daten für Entity
    Resolution zu manipulieren"}
skinparam componentStyle uml2
component "Engine" {
    [Parser] - D
    D )-- [Preprocessor]
    [Preprocessor] - PD

    package "Fit-Phase" {
        PD )-down- [Blocking Scheme Learner]
        PD )-down- [Label Generator]
        PD )-down- [Similarity Learner]
        PD )-down- [Fusion-Learner]
        PD )-down- [Label Filter]
        GT )-up- [Label Filter]
        GT  -up- [Label Generator]
        FGT -up- [Label Filter]
        FGT )-up- [Blocking Scheme Learner]
        FGT )-up- [Fusion-Learner]
        FGT )-up- [Similarity Learner]
        BS -up- [Blocking Scheme Learner]
        BS )-up- [Label Filter]
        BS )-up- [Similarity Learner]
        BS )-up- [Fusion-Learner]
        M -up- [Fusion-Learner]
        S -up- [Similarity Learner]
        S )-up- [Fusion-Learner]
        B )-up- [Blocking Scheme Learner]
        PG )-up- [Fusion-Learner]
    }

    package "Build-/Query-Phase" {
        B -up- [Indexer]
        BS )-down- [Indexer]
        PD )-down- [Indexer]
        S )-down- [Indexer]

        C -left- [Indexer]
        PG -down- [Klassifier]
        M )-down- [Klassifier]
        C )-down- [Klassifier]
        R -left- [Klassifier]
    }
}
```

Die Engine ist das Herzstück des selbstkonfigurierenden Systems und besteht aus
einzelnen Komponenten, die bei Schnittstellenkompatibilität beliebig
ausgetauscht werden. Die Komponenten und Schnittstellen der Engine sind in
@fig:engine dargestellt.

* **Parser**. Der Parser liest Datensätze aus einer Datenquelle bietet eine
  Menge von Tupeln $D$ an.
* **Präprozessor**. Der Präprozessor vorverarbeitet jedes Attribut jedes
  Datensatzes aus $D$ in einer Pipeline, anhand einer Reihe von
  benutzerdefinierten Operationen, welche sequentiell angewendet werden,
  beispielsweise Rechtschreibprüfung, das Ergebnis ist die vorverarbeitete Menge
  an Tupeln $PD$.
* **Label Generator**. Der Label Generator erzeugt eine geeignete Ground Truth
  $GT$ zum Einstellen der Parameter in den folgenden Komponenten. Er konsumiert
  dazu die vorverbeiteten Tupel $PD$.
* **Blocking Schema Lerner**. Der Blocking Schema Lerner erzeugt eine Blocking
  Schema $BS$ in distributiver Normalform nach [@KM:Unsupervised:13]. Zur
  Bewertung eines Ausdrucks, konsumiert er die generierten Blöcke $B$ eines
  Indexers.
* **Label Filter**. Der Label Filter ist fester Bestandteil der Engine und
  modifiziert die Ground Truth $GT$, indem nur Paare durchgelassen werden, die
  zum Blocking Schema $BS$ passen. Das Ergebnis ist die gefilterte Ground Truth
  $FGT$.
* **Similarity Lerner**. Der Similarity Lerner bestimmt für jedes Attribut eine
  geeignete Ähnlichkeitsfunktion $S$.
* **Fusion-Lerner**. Der Fusion-Lerner ermittelt die besten Parameter für den
  verwendeten Klassifikator. Von diesem erhält der Fusion-Lerner mögliche
  Parameter $PG$, anhand welcher das Klassifikationsmodell $M$ trainert wird.
* **Indexer**. Der Indexer wendet ein Blocking Verfahren auf die
  vorverarbeiteten Daten $PD$ an und bietet bei einer Anfrage eine
  Kandidatenliste $C$ mit möglichen Duplikaten an.
* **Klassifikator**. Der Klassifikator ordnet die Kandidate aus $C$ in Matches
  und Non-Matches, die Menge an Matches $R$, ist das Ergebnis einer Anfrage.

Die Hauptaufgabe der Engine ist es, die Interaktionen zwischen den Komponenten
zu steuern. Dazu werden im simpelsten Fall die Daten von einer Komponente zur
nächsten weitergereicht. Zum Teil muss die Engine zunächst jedoch die
Rückgabewerte für die nächste Komponente aufbereitet (vgl. Label Filter). Die
Engine dient weiterhin als Schnittstelle für den Benutzer. Alle drei Phasen
haben den Schritt der Vorverarbeitung gemeinsam.

### Vorverarbeitung

Die Vorverarbeitung der Daten ist in allen drei Phasen notwendig und macht die
Datensätze robuster gegenüber Missklassifikationen, indem offensichtliche Fehler
korrigiert und eventuelle, für die Identifikation von Entitäten irrelevante,
Varianzen bereinigt weren. In @fig:preprocessing sind die beteiligten
Komponenten Parser und Präprozesser mit ihren Aktivitäten visualisiert. Jede
Phase beginnt mit der Auswahl des korrekten Parsers durch die Engine.

```{.plantuml #fig:preprocessing
    caption="Aktivitätsdiagramm der Vorverarbeitung. Der Parser liest einen
    Datensatz, welcher vom Präprozessor transformieren wird. Der transformierte
    Datensatz wird von der Engine abgespeichert."}
|Engine|
start
:choose parser for Fit-,
Build- or Query-Phase;
|Parser|
:read dataset into D;
if (is Fit-Phase?) then (yes)
    :assign attribute datatypes;
endif
|Preprozessor|
:transform dataset into PD;
|Engine|
:save transformed dataset PD;
:proceed with (Fit/Build/Query)-Phase;
```

**Parser**. Der Parser ist eine einfache Komponente, welche Datensätze aus einer
Datenquelle liest und eine Menge von Tupeln $D$ an die Engine übergibt. Je nach
Phase kann die Datenquelle ein beliebiges Format haben, weshalb für jede Phase
ein eigener Parser bestimmt werden kann. Für *Fit-* und *Build-Phase*, wo große
Datenmengen bearbeitet werden, liest der Parser beispielsweise aus einer
CSV-Datei oder selektiert die Datensätze aus einer Datenbank. Währenddessen in
der *Query-Phase* nur einzelne oder kleine Datenmengen gelesen werden, weshalb
der Parser hier aus einer Message Queue (MQ) Datensätze erhalten könnte. Während
der *Fit-Phase* hat der Parser zudem dafür Sorge zu tragen, dass der Engine die
Attribute des Datensatzes, sowie deren Datentypen bekannt gemacht werden. Anhand
der Datentypen können die Komponenten der Fit-Phase effizienter eine gute
Konfigurationen bestimmen. Wenn der Parser diese Information nicht bereitstellt,
werden alle Attribute als Zeichenketten behandelt.

**Präprozessor**. Der Präprozessor bzw. die Präprozessor-Pipeline besteht aus
einer Reihe von Funktionen, die nacheinander auf alle Tupel aus $D$ angewandt
werden, um diese für die Entity Resolution vorzubereiten und robuster zu machen.
Je nach Datentyp des Attributs wird dabei eine andere Pipeline verwendet.
Dieselbe Präprozessor-Pipeline muss in allen drei Phasen verwendet, damit die
vorverarbeiteten Datenmenge $PD$ stets die gleichen Charakteristiken aufweist.
Werden vom Benutzer keine Operationen vorgegeben, beschränkt sich die Pipeline
auf generische Modifkationen. Die zum Zeitpunkt dieser Thesis entwickelte Engine
ist, zum Zwecke der Vorverarbeitung, automatisiert lediglich in der Lage Strings
in Kleinschreibweise zu konvertiert. Andere Operationen wie das Entfernen von
Stopwörtern (z.B. *und*, *oder*) benötigen zum einen die Sprache der Attribute,
welche zu erkennen durchaus eine lösbare Aufgabe ist, zum anderen aber auch
einen Datenbestand gegen den geprüft wird. Ein komplexere domänenspezifische
Anwendung hierfür ist, beispielsweise die Überprüfung der postalischen Addresse,
welche zum einen länderspezifische Daten benötigt und zum anderen auch ständig
auf dem aktuellen Stand gehalten werden muss. Neben zusätzlichen Funktionen muss
der Benutzer auch die Reihenfolge der Funktionen vorgeben. Beispielweise
zunächst die Rechtspreibprüfung und anschließend die Konvertierung in
Kleinschreibweise, da durch die Rechtschreibprüfung diese Konvertierung in
Teilen wieder aufgehoben wird.

Die vorverarbeiteten Tupel $PD$ des Präprozessors, werden abschließend
abgespeichert, um zu einem späteren Zeitpunkt geladen zu werden.

### Fit-Phase

```{.plantuml #fig:fit_phase
    caption="Aktivitätsdiagramm der Fit-Phase. Die Engine kontrolliert den
    Datenfluss zwischen den Komponenten, speichert Konfigurationen und breitet
    Daten für Komponenten auf. Der Label Generator erzeugt die Ground Truth,
    durch welche ein DNF-Blocking Schema vom BS-Lerner erzeugt wird. Auf einer
    durch das Blocking Schema gefilterten Liste werden anschließend die
    Ähnlichkeitsfunktionen bestimmt. Anhand dieser Funktionen können
    Ähnlichkeitsvektoren auf der Ground Truth berechnet werden und vom
    Fusion-Lerner dadurch die Hyperparameter für den Klassifikator bestimmt,
    sowie abschließend das Klassifikationsmodell trainiert werden."}
|Engine|
start
:read transformed dataset PD;
|Label Generator|
:generate ground truth GT;
|Engine|
:save ground truth GT;
|BS-Learner|
:predict DNF Blocking Scheme BS;
|Engine|
:save DNF Blocking Scheme BS;
:filter GT through BS into FGT;
|Sim-Learner|
:predict similarity functions S;
|Engine|
:save similarity functions S;
:calculate ground truth
similarity vectors;
|HP-Optimizer|
:predict hyperparameters;
:train model M;
|Engine|
:save model M;
stop
```

Die für die Fit-Phase relevanten Komponenten und Schnittstellen sind in
@fig:engine in der Box "Fit-Phase" gruppiert. Bei großen Datensätzen kann diese
Phase sehr lange dauern, weshalb die Engine die Teilkonfigurationen der
Komponenten direkt sichert. Dadurch kann die Fit-Phase im Falle eines Abbruchs,
z.B. durch einen Systemneustart, fortgesetzt werden und nur die unterbrochene
Komponente muss wiederholt werden. Wurde die Fit-Phase abgeschlossen, ist es
möglich die ermittelte Konfiguration einzulesen, wodurch die Fit-Phase
übersprungen wird. @fig:fit_phase zeigt das Aktivitätsdiagramm der Fit-Phase,
ohne existierende Konfiguratation.

**Label Generator**. Der Label Generator erzeugt die Ground Truth $GT$, in Form
von klassifizierten Matches und Non-Matches, für später in der Fit-Phase
folgenden Komponenten. Dazu nutzt der Label Generator, die vorverarbeiteten
Tupel $PD$ und bildet Datensatzpaare (@fig:fit_phase). Dabei gibt es zwei
Ausprägungen. In der ersten Ausprägung erhält der Label Generator
vorklassifizierte Matches, für den vom Parser eingelesenen Datensatz (vgl.
@sec:ana_lbl). In der zweiten Ausprägung stehen dem Label Generator keine
vorklassifizierten Matches zur Verfügung. Weshalb die Ground Truth vollständig
automatisiert bestimmt werden muss (vgl. @sec:lblgen_nogt). Ein Label Generator
kann beide Ausprägungen implementieren. Falls nur die erste Ausprägung
implementiert ist, kann die Engine, ohne existierende Ground Truth, die
Fit-Phase nicht durchführen. Sollte nur die zweite Ausprägung vorhanden sein,
werden die vorklassifizierten Matches ignoriert.

**Blocking Schema Lerner**. Der Blocking Schema Lerner ermittelt ein Blocking
Schema in disjunktiver Normalform nach [@KM:Unsupervised:13], welches in
@sec:ana_bs vorgestellt wurde. Dafür benötigt der Blocking Schema Lerner die
vorverarbeiteten Tupel $PD$, sowie die Ground Truth Daten $GT$ des Label
Generators. Zudem werden die Blöcke des genutzten Indexers $IX$ zu jedem zu
analysierenden Audrück benötigt. Daraus wird schlussendlich ein DNF Blocking
Schema $BS$ gebildet.

```texalgo
#alg:gt_filter FilterGT($BS$, $D$, $P$, $N$, $AN$, $max_n$)
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Blocking Scheme: $BS$
  \item Dataset: $D$
  \item Set of positive pairs: $P$
  \item Set of negative pairs: $N$
  \item Set of all generated negative pairs: $AN$
  \item Maximum Non-Duplicate Pairs: $max_n$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Set of filtered positive pairs: $fP$
  \item Set of filtered negative pairs: $fN$
  \item Predictions: $y_{pred}$
  \end{itemize}
}
\Statex
\State Initialize empty sets $fP = (), fN = ()$
\For{pair $(p_1.id, p_2.id) \in P$}\label{alg:fgt:p}
    \If{$HasCommonBlock(BS, D, (p_1.id, p_2.id))$}
        \State Append $(p_1.id, p_2.id)$ to $fP$\label{alg:fgt:ap}
    \EndIf
\EndFor
\For{pair $(p1, p2) \in N$}\label{alg:fgt:n}
    \If{$HasCommonBlock(BS, D, (p_1.id, p_2.id))$}
        \State Append $(p_1.id, p_2.id)$ to $fN$\label{alg:fgt:an}
    \EndIf
\EndFor
\While{$|fN| < max_n$ and $|AN| > 0$}\label{alg:fgt:wan}
    \State Draw pair $(p_1.id, p_2.id)$ from $AN$
    \If{$HasCommonBlock(BS, D, (p_1.id, p_2.id))$}\label{alg:fgt:cb}
        \State Append $(p_1.id, p_2.id)$ to $fN$\label{alg:fgt:aan}
    \EndIf
\EndWhile
\State return $fP, fN$

#alg:common_block HasCommonBlock($BS$, $D$, $p$)
\Require
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item Blocking Scheme: $BS$
  \item Dataset: $D$
  \item Pair: $p = (p_1.id, p_2.id)$
  \end{itemize}
}
\Ensure
\Statex{
  \begin{itemize}[noitemsep, topsep=0pt, leftmargin=*, label={-}]
  \item True if $p$ has common block, false otherwise
  \end{itemize}
}
\Statex
\State Initialize empty sets $p_{1_{bkvs}} = (), p_{2_{bkvs}} = ()$
\For{term $t \in BS$}
    \State $r_1 = D[p_1.id], r_2 = D[p_2.id]$
    \State Add $BlockingKeyValues(t, r_1)$ to $p1_{bkvs}$\label{alg:ct:bkv1}
    \State Add $BlockingKeyValues(t, r_2)$ to $p2_{bkvs}$\label{alg:ct:bkv2}
\EndFor
\If{$p1_{bkvs} \cup p2_{bkvs} \neq \emptyset$}
    \State return True\label{alg:ct:t}
\Else
    \State return False\label{alg:ct:f}
\EndIf
```

**Label Filter.** Anhand des Blocking Schema werden die Kandidaten, welcher für
die Entity Resolution infragekommen eingeschränkt. Damit der Similarity Lerner
und der Fusion-Lerner ihre Konfiguration lediglich auf relevanten Paaren
ermitteln, muss die Ground Truth durch das Blocking Schema gefiltert werden. Das
Filtern der Ground Truth auf Basis des ermittelten Blocking Schema, wird von der
Engine durchgeführt, bevor der Similarity Lerner aufgerufen wird (siehe
Algorithmus \ref{alg:gt_filter}). Dabei werden nacheinander alle Matches und
Non-Matches der Ground Truth betrachet (Zeilen \ref{alg:fgt:p},
\ref{alg:fgt:n}). In Algorithmus \ref{alg:common_block} werden für jedes Paar
$(p_1.id, p_2.id)$ die Blockschüssel, anhand des gegeben Blocking Schema,
generiert (Zeilen \ref{alg:ct:bkv1}, \ref{alg:ct:bkv2}). Gibt es dabei eine
Überlappung, dann gibt es für mindestens ein Attribut einen gemeinsamen Block,
in welchem das Paar zusammen vorkommt. In diesem Fall gibt der Algorithmus Wahr
zurück (Zeile \ref{alg:ct:t}). Gibt es keine Überlappung wird Falsch
zurückgegeben (Zeile \ref{alg:ct:f}). Wurde durch Algorithmus
\ref{alg:common_block} festgestellt, dass ein Match bzw. ein Non-Match einen
gemeinsamen Blockschlüssel hat, dann werden dieses zur gefilterten Ground Truth
$fP$ oder $fN$ hinzugefügt (Zeilen \ref{alg:fgt:ap}, \ref{alg:fgt:an}). Da das
Ziel des Blocking Schema ist, möglichst nur gleiche Entitäten zu gruppieren,
werden beim Filtern sehr viele Non-Machtes, im schlimmsten Fall alle,
herausgefiltert. Dadurch ist die gefilterte Ground Truth zugunsten der Matches
unbalanciert. Damit der Similarity Lerner und der Fusion-Lerner dennoch eine
sinnvolle und aussagekräftige Konfiguration ermitteln können, werden die
Non-Matches künstlich angereichert. Dazu werden die vom Label Generator zuvor
verworfenen Non-Matches $AN$ benötigt. Diese werden nun versucht zur Ground
Truth hinzuzufügen, indem wie davor eine Überlappung der Blockschlüssel gesucht
wird (Zeile \ref{alg:fgt:cb}). Gibt es eine Überlappung wird das Paar zu $fN$
hinzugefügt (Zeile \ref{alg:fgt:aan}). Dies wird solange wiederholt, bis die
Ground Truth $max_n$ Non-Matches beinhaltet oder die gesamte Menge der
Non-Matches des Label Generators erschöpft sind (Zeile \ref{alg:fgt:wan}).

**Similarity Lerner**. Der Similarity Lerner bestimmt aus einer Menge von
Ähnlichkeitsfunktion für jedes Attribut die geeigneste nach dem Verfahren aus
@anasim. Zur Bewertung werden die Datensatzpaare der gefilterten Grund Truth
$FGT$ genutzt. Das Ergebnis ist die Tupelliste $S$, welche Ähnlichkeitmaße mit
Datenfeldern verknüpft.

**Fusion-Lerner**. Der Fusion-Lerner ermittelt für einen gegebenen Klassifikator
die Parameter, die das Modell mit der besten F-measure erzeugen. Bevor der
Fusion-Lerner aufgerufen werden kann, erzeugt die Engine für jedes Paar der
gefilterte Ground Truth $FGT$, anhand der Ähnlichkeitsfunktionen des Similarity
Lerners $S$, einen Ähnlichkeitsvektor pro Paar. Die Ähnlichkeitsvektoren sind
dabei nur an den Stellen besetzt, in welches die Attribute des Paares einen
gemeinsamen Block im Blocking Schema $BS$ haben. Die Ähnlichkeitsvektoren werden
dann vom Fusion-Lerner genutzt, um ein Modell mit gegebenen Parametern zu
trainieren. Das Parameternetz $PG$, das zur Optimierung in Frage kommen, muss
von der Klassifikatorkomponente bereitgestellt werden, beispielsweise die
maximale Tiefe eines DecisionTree. Um einen optimalen Klassifikator für die
Eingabedaten zu bekommen, ist es abgesehen von der Parameterliste möglich, eine
Liste von verschiedenen Klassifikatoren anzugeben, beispielsweise einen
DecisionTree und eine SVM. Das Ergebnis des Fusion-Lerners ist ein Modell $M$
des Klassifikator mit den Parametern, die das beste F-measure erzeugen.

### Build-Phase

```{.plantuml #fig:build_phase width=60%
    caption="Aktivitätsdiagramm der Build-Phase. Der liest alle vorverarbeiteten
    Datensätze einer initalen Datensatzes ein und fügt diese seinem Index hinzu."}
|Engine|
start
:read transformed dataset;
repeat
    :get record from dataset;
    |Indexer|
    :insert record into index;
repeat while (more records?)
|Engine|
:save index;
stop
```

Die Build-Phase dient der Vorbearbeitung der Daten, bevor das
selbstkonfigurierte ER-System seinen Betrieb aufnehmen kann. Dazu wird der
komplette Datenbestand, in welchem Entitäten gesucht werden sollen, betrachtet.
Nachdem diese durch die Vorverarbeitung gelaufen sind, wird auf den Daten ein
Blocking-Verfahren durchgeführt. Der **Indexer** ist ein Blocking Mechanismus,
der zum einen mit dynamischen Daten umgehen können muss und zum anderen das
Blocking anhand des DNF-Blocking Schemas durchführt. In @fig:build_phase wird
die Build-Phase erläutert. Die Engine liest zunächst alle vorverarbeiteten
Datensätze ein. Anschließend werden die Datensätze einzel dem Indexer übergeben,
welcher diese zu seinem Index hinzufügt. Dabei besteht die Möglichkeit, dass der
Index während des Einfügens anhand der gelernten Ähnlichkeitsfunktionen
bestimmte Ähnlichkeiten vorausberechnet. Das Bauen des Index kann einige
Minuten, eventuell sogar Stunden, dauern. Deshalb wird der Index nach dem Bauen
gespeichert. Im Falle eines Neustarts der Engine müssen dann nur die Datensätze
eingefügt werden, welche während der letzten Query-Phase hinzugekommen sind.

### Query-Phase

```{.plantuml #fig:query_phase width=90%
    caption="Aktivitätsdiagramm der Query-Phase. Zunächst werden der
    transformierte Datensatz vom Präprozessor gelesen. Danach werden Datensätze
    einzeln entnommen und dem Indexer übergeben. Dieser liefert eine
    Kandidatenliste. Jeder Kandidat wird vom Klassifikator in Match bzw.
    Non-Match klassifiziert. Matches werden von der Engine gespeichert und
    Non-Matches verworfen. Am Schluss wird das Ergebnis aller Anfragen dem
    Benutzer übergeben."}
|Engine|
start
:read transformed dataset;
while (more queries?) is (yes)
    :get query record from dataset;
    |Indexer|
    :query candidates from index;
    |Engine|
    while (more candidates?) is (yes)
        |Engine|
        :get candidate record from candidate list;
        |Klassifier|
        :predict candidate class;
        |Engine|
        if (is candidate a match?) then (yes)
            |Engine|
            :save candidate as match;
        else (no)
            |Engine|
            :discard candidate;
        endif
    endwhile (no)
endwhile (no)
|Engine|
:pass results to user;
stop
```

In der Query-Phase (siehe @fig:query_phase) erhält die Engine von einem
Query-Parser eine Menge von Anfragedatensätzen. Nachdem diese vorverarbeitet
wurden, wird jeder Datensatz einzeln dem Indexer übergeben. Dieser erzeugt für
den übergebenen Datensatz eine Kandidatenmenge möglicher Matches. Diese
Kandidaten werden dem Klassifikator übergeben. Das Modell des **Klassifikators**
wurde während der *Fit-Phase* von dem Fusion-Lerner trainiert und kann nun in
der *Query-Phase* genutzt werden, um die Kandidaten in Matches und Non-Matches
zu klassifizieren. Das Ergebnis der Klassifikation speichert die Engine
zwischen, bis alle Datensätze verarbeitet wurden. Abschließend werden die
gesammelten Ergebnisse an den Benutzer übergeben.

### Auswertung

Für die Entwicklung von Komponenten besitzt die Engine die Möglichkeit Metriken
zu messen und diese auszuwerten. Diese liefern ein wichtiges Indiz, wie gut eine
Komponente funktioniert. Des Weiteren ist es dadurch möglich das Zusammenspiel
der Komponenten untereinander zu bewerten, indem beispielsweise eine alternative
Komponente eingesetzt wird, um die Auswirkungen der neuen Komponente in den
Metriken zu überprüft werden. Von den Metriken, welche in @sec:measurements
beschrieben wurden, kann die Engine für das Blocking die Pairs Completeness,
Pairs Quality und Reduction Ratio aufzeichnen, sowie für den Klassifikator
Recall, Precision,F-measure und Average Precision messen. Des Weiteren werden
die Daten zum Zeichnen eines F-measure Graphen und einer Precision-Recall Kurve
bereitgestellt. Darüber hinaus kann die Engine messen, wie lange einzelne
Operationen einer Komponente benötigen. Beispielsweise wird gemessen, wie lange
es dauert einen Datensatz in den Index einzufügen bzw. zu einem Anfragedatensatz
die Kandidatenliste zu erhalten. Dadurch kann die Performanz, beispielsweise in
Anfragen pro Sekunde auf einer Testhardware angegeben werden. Alle Metriken
werden während der Query-Phase erhoben und können nach jeder Anfrage abgefragt
werden.
